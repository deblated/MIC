{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83bb15c0-dba9-4aaa-b5e9-75516184688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "X = wine.data[:, (0, 6)] # alcohol, flavanoids\n",
    "y = (wine.target == 2).astype(int) # class_2\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "y_pred = per_clf.predict([[13,  0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c088fd-9d0b-4fcd-897c-4e0c3bbb0e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe64846-34ea-42d7-b489-6c097573162a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [11, 15, 0, 4]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not class_2\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Class_2\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "plt.xlabel(\"Alcohol\", fontsize=14)\n",
    "plt.ylabel(\"Flavanoids\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051e4e75-4b55-4aa5-95cf-16c6573191f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7092fcde-3cfb-4fb7-8876-431c1d23bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b25888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99e74ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e6f010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be5c9f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2447633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(300, activation=\"relu\"),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55210ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "303200fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x21df261eb70>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x21df2516438>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x21dfa863d68>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x21dfa863e80>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "492adf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0281466 , -0.00043187, -0.01580833, ...,  0.04713748,\n",
       "         0.00302128, -0.06993003],\n",
       "       [ 0.02976022,  0.06845444, -0.06269031, ..., -0.06648135,\n",
       "        -0.07420857, -0.0658021 ],\n",
       "       [ 0.03411184,  0.0654536 ,  0.03726425, ..., -0.03393585,\n",
       "        -0.06848694, -0.02883022],\n",
       "       ...,\n",
       "       [ 0.06698991,  0.05225077, -0.02482817, ..., -0.037212  ,\n",
       "         0.01985958, -0.02976555],\n",
       "       [-0.04784364,  0.01609419, -0.06223211, ..., -0.03680152,\n",
       "        -0.03527   ,  0.06977244],\n",
       "       [-0.0705869 , -0.03991923,  0.02835238, ..., -0.02794292,\n",
       "        -0.01348174,  0.05101146]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[1].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09762409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2036ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "855740b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff8d6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer=\"sgd\",\n",
    "            metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af58284c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.7167 - accuracy: 0.7634 - val_loss: 0.5134 - val_accuracy: 0.8260\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.4902 - accuracy: 0.8293 - val_loss: 0.4391 - val_accuracy: 0.8516\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 7s 123us/sample - loss: 0.4456 - accuracy: 0.8428 - val_loss: 0.4303 - val_accuracy: 0.8544\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 7s 133us/sample - loss: 0.4185 - accuracy: 0.8529 - val_loss: 0.4018 - val_accuracy: 0.8588\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 7s 132us/sample - loss: 0.3974 - accuracy: 0.8592 - val_loss: 0.3804 - val_accuracy: 0.8718\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 7s 132us/sample - loss: 0.3817 - accuracy: 0.8650 - val_loss: 0.3811 - val_accuracy: 0.8642\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 7s 133us/sample - loss: 0.3682 - accuracy: 0.8692 - val_loss: 0.3645 - val_accuracy: 0.8734\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.3566 - accuracy: 0.8732 - val_loss: 0.4530 - val_accuracy: 0.8294\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.3462 - accuracy: 0.8756 - val_loss: 0.3463 - val_accuracy: 0.8766\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.3367 - accuracy: 0.8806 - val_loss: 0.3393 - val_accuracy: 0.8774\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 8s 138us/sample - loss: 0.3272 - accuracy: 0.8823 - val_loss: 0.3625 - val_accuracy: 0.8728\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 7s 124us/sample - loss: 0.3195 - accuracy: 0.8850 - val_loss: 0.3345 - val_accuracy: 0.8792\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 8s 143us/sample - loss: 0.3129 - accuracy: 0.8874 - val_loss: 0.3279 - val_accuracy: 0.8794\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 7s 125us/sample - loss: 0.3065 - accuracy: 0.8897 - val_loss: 0.3269 - val_accuracy: 0.8806\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 8s 139us/sample - loss: 0.3000 - accuracy: 0.8915 - val_loss: 0.3191 - val_accuracy: 0.8844\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 7s 131us/sample - loss: 0.2929 - accuracy: 0.8938 - val_loss: 0.3206 - val_accuracy: 0.8842\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 7s 131us/sample - loss: 0.2875 - accuracy: 0.8961 - val_loss: 0.3163 - val_accuracy: 0.8896\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.2825 - accuracy: 0.8974 - val_loss: 0.3370 - val_accuracy: 0.8796\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.2778 - accuracy: 0.8990 - val_loss: 0.3194 - val_accuracy: 0.8862\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.2723 - accuracy: 0.9012 - val_loss: 0.3074 - val_accuracy: 0.8892\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 7s 124us/sample - loss: 0.2664 - accuracy: 0.9035 - val_loss: 0.3206 - val_accuracy: 0.8880\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.2626 - accuracy: 0.9045 - val_loss: 0.3174 - val_accuracy: 0.8856\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.2577 - accuracy: 0.9072 - val_loss: 0.3096 - val_accuracy: 0.8882\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 8s 142us/sample - loss: 0.2536 - accuracy: 0.9079 - val_loss: 0.3254 - val_accuracy: 0.8794\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 7s 125us/sample - loss: 0.2484 - accuracy: 0.9095 - val_loss: 0.3038 - val_accuracy: 0.8892\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 9s 158us/sample - loss: 0.2461 - accuracy: 0.9107 - val_loss: 0.3071 - val_accuracy: 0.8886\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.2411 - accuracy: 0.9125 - val_loss: 0.3069 - val_accuracy: 0.8922\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 8s 138us/sample - loss: 0.2373 - accuracy: 0.9141 - val_loss: 0.3109 - val_accuracy: 0.8882\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.2341 - accuracy: 0.9155 - val_loss: 0.2905 - val_accuracy: 0.8964\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.2294 - accuracy: 0.9167 - val_loss: 0.2986 - val_accuracy: 0.8922\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "696081a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e7a0661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 94us/sample - loss: 65.7689 - accuracy: 0.8468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[65.76892659015655, 0.8468]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec0bc327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad4c2bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfe7e87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64b3301f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83582c8e",
   "metadata": {},
   "source": [
    "## Building a Regression MLP Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a82056c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40513</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>90.16</td>\n",
       "      <td>28.9</td>\n",
       "      <td>smokes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13861</th>\n",
       "      <td>Female</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>233.29</td>\n",
       "      <td>48.9</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12857</th>\n",
       "      <td>Male</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>73.57</td>\n",
       "      <td>28.0</td>\n",
       "      <td>smokes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38673</th>\n",
       "      <td>Female</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.63</td>\n",
       "      <td>32.8</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71673</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>110.85</td>\n",
       "      <td>24.1</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67432</th>\n",
       "      <td>Female</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>97.43</td>\n",
       "      <td>26.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62861</th>\n",
       "      <td>Female</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>67.29</td>\n",
       "      <td>24.6</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36857</th>\n",
       "      <td>Male</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>162.14</td>\n",
       "      <td>32.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32240</th>\n",
       "      <td>Female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>93.55</td>\n",
       "      <td>41.6</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>91.02</td>\n",
       "      <td>32.9</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9722 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "id                                                                             \n",
       "40513  Female  21.0             0              0           No        Private   \n",
       "13861  Female  52.0             1              0          Yes  Self-employed   \n",
       "12857    Male  55.0             0              0          Yes  Self-employed   \n",
       "38673  Female  51.0             0              0          Yes        Private   \n",
       "71673  Female  79.0             0              0          Yes        Private   \n",
       "...       ...   ...           ...            ...          ...            ...   \n",
       "67432  Female  60.0             0              0          Yes        Private   \n",
       "62861  Female  78.0             0              0          Yes        Private   \n",
       "36857    Male  77.0             0              0          Yes  Self-employed   \n",
       "32240  Female  27.0             0              0           No        Private   \n",
       "2182   Female  80.0             1              0          Yes  Self-employed   \n",
       "\n",
       "      Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
       "id                                                                      \n",
       "40513          Urban              90.16  28.9           smokes       0  \n",
       "13861          Urban             233.29  48.9     never smoked       1  \n",
       "12857          Rural              73.57  28.0           smokes       0  \n",
       "38673          Rural             105.63  32.8     never smoked       0  \n",
       "71673          Urban             110.85  24.1  formerly smoked       1  \n",
       "...              ...                ...   ...              ...     ...  \n",
       "67432          Urban              97.43  26.4           smokes       1  \n",
       "62861          Urban              67.29  24.6     never smoked       1  \n",
       "36857          Rural             162.14  32.6  formerly smoked       1  \n",
       "32240          Urban              93.55  41.6     never smoked       0  \n",
       "2182           Rural              91.02  32.9  formerly smoked       1  \n",
       "\n",
       "[9722 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "stroke = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "stroke_class_0 = stroke[stroke['stroke'] == 0]\n",
    "stroke_class_1 = stroke[stroke['stroke'] == 1]\n",
    "\n",
    "stroke_class_1_upsampled = resample(stroke_class_1,\n",
    "                                    replace=True, \n",
    "                                    n_samples=len(stroke_class_0), \n",
    "                                    random_state=42)  \n",
    "\n",
    "stroke_upsampled = pd.concat([stroke_class_0, stroke_class_1_upsampled])\n",
    "stroke = stroke_upsampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "stroke = stroke.set_index(\"id\")\n",
    "\n",
    "stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fda74d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"cat_encoder\", OrdinalEncoder()),\n",
    "    ])\n",
    "\n",
    "\n",
    "num_attribs = [\"age\",\"avg_glucose_level\",\"bmi\"]\n",
    "cat_attribs = [\"gender\",\"hypertension\",\"heart_disease\",\"smoking_status\", \"work_type\"]\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f24d3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(stroke[\"stroke\"].values)\n",
    "X = stroke.drop(\"stroke\", axis=1)\n",
    "X = preprocess_pipeline.fit_transform(X[num_attribs + cat_attribs])\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf6bfb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5468 samples, validate on 1823 samples\n",
      "Epoch 1/20\n",
      "5468/5468 [==============================] - 1s 145us/sample - loss: 0.1982 - val_loss: 0.1971\n",
      "Epoch 2/20\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1843 - val_loss: 0.1918\n",
      "Epoch 3/20\n",
      "5468/5468 [==============================] - 0s 69us/sample - loss: 0.1803 - val_loss: 0.1881\n",
      "Epoch 4/20\n",
      "5468/5468 [==============================] - 0s 67us/sample - loss: 0.1777 - val_loss: 0.1864\n",
      "Epoch 5/20\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1759 - val_loss: 0.1842\n",
      "Epoch 6/20\n",
      "5468/5468 [==============================] - 0s 70us/sample - loss: 0.1744 - val_loss: 0.1832\n",
      "Epoch 7/20\n",
      "5468/5468 [==============================] - 0s 64us/sample - loss: 0.1731 - val_loss: 0.1817\n",
      "Epoch 8/20\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1719 - val_loss: 0.1806\n",
      "Epoch 9/20\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1709 - val_loss: 0.1798\n",
      "Epoch 10/20\n",
      "5468/5468 [==============================] - 0s 65us/sample - loss: 0.1701 - val_loss: 0.1789\n",
      "Epoch 11/20\n",
      "5468/5468 [==============================] - 0s 69us/sample - loss: 0.1693 - val_loss: 0.1784\n",
      "Epoch 12/20\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1686 - val_loss: 0.1775\n",
      "Epoch 13/20\n",
      "5468/5468 [==============================] - 0s 65us/sample - loss: 0.1680 - val_loss: 0.1770\n",
      "Epoch 14/20\n",
      "5468/5468 [==============================] - 0s 71us/sample - loss: 0.1674 - val_loss: 0.1767\n",
      "Epoch 15/20\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1668 - val_loss: 0.1761\n",
      "Epoch 16/20\n",
      "5468/5468 [==============================] - 0s 69us/sample - loss: 0.1663 - val_loss: 0.1753\n",
      "Epoch 17/20\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1658 - val_loss: 0.1749\n",
      "Epoch 18/20\n",
      "5468/5468 [==============================] - 0s 69us/sample - loss: 0.1654 - val_loss: 0.1746\n",
      "Epoch 19/20\n",
      "5468/5468 [==============================] - 0s 70us/sample - loss: 0.1649 - val_loss: 0.1743\n",
      "Epoch 20/20\n",
      "5468/5468 [==============================] - 0s 71us/sample - loss: 0.1645 - val_loss: 0.1745\n",
      "2431/2431 [==============================] - 0s 32us/sample - loss: 0.1651\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c977b2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAW9klEQVR4nO3df4wc533f8fd3d+9ISkeFshgzsqTakq3EpZCoERnJTh2XTNqAEoKoLeTUcqC4rg1CgFk0fxiIgABugPzlGu6PuI4F1xFsB04YpHEcNVbqFAFVowkUSHIlWT8iiZZli6YkVrZk6iQeebv77R8zd7dc7t4t7/bu1k/eL2CwM/M8M/PdueHn2Z29W0ZmIkn64dfY7AIkSeNhoEtSIQx0SSqEgS5JhTDQJakQBrokFWLFQI+IuyLiREQ8OqQ9IuJ3IuJoRDwSEdeNv0xJ0kpGeYX+OeDAMu03AlfX00Hg02svS5J0vlYM9Mz8GvD9ZbrcDHwhK/cBOyLi0nEVKEkaTWsM+7gMeK5n+Vi97vn+jhFxkOpVPNu2bdtzxRVXrOqA3W6XRmNyb/9Pen0w+TVa39pY39pMcn1PPfXUS5n5owMbM3PFCXgL8OiQtq8A7+pZ/itgz0r73LNnT67WkSNHVr3tRpj0+jInv0brWxvrW5tJrg94IIfk6jiGoGNA70vty4HjY9ivJOk8jCPQ7wZ+rf5tl3cAP8jMc263SJLW14r30CPiD4F9wM6IOAb8e2AKIDPvBO4BbgKOAq8DH1ivYiVJw60Y6Jl56wrtCXx4bBVJklZlMj/GlSSdNwNdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiFGCvSIOBART0bE0Yi4Y0D7j0TE/4iIhyPisYj4wPhLlSQtZ8VAj4gm8CngRmA3cGtE7O7r9mHg8cy8FtgHfCIipsdcqyRpGaO8Qr8eOJqZz2TmGeAwcHNfnwS2R0QAM8D3gfZYK5UkLSsyc/kOEbcABzLzQ/XybcANmXmop8924G7g7cB24F9l5lcG7OsgcBBg165dew4fPryqomdnZ5mZmVnVthth0uuDya/R+tbG+tZmkuvbv3//g5m5d2BjZi47Ae8BPtuzfBvwyb4+twD/CQjgbcC3gIuW2++ePXtytY4cObLqbTfCpNeXOfk1Wt/aWN/aTHJ9wAM5JFdHueVyDLiiZ/ly4Hhfnw8AX6qPd7QO9LePNNxIksZilEC/H7g6Iq6sP+h8L9XtlV7fAX4BICJ2AT8BPDPOQiVJy2ut1CEz2xFxCPgq0ATuyszHIuL2uv1O4LeBz0XEN6huu/xGZr60jnVLkvqsGOgAmXkPcE/fujt75o8Dvzje0iRJ58O/FJWkQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUiJECPSIORMSTEXE0Iu4Y0mdfRDwUEY9FxP8eb5mSpJW0VuoQEU3gU8A/A44B90fE3Zn5eE+fHcDvAgcy8zsR8cZ1qleSNMQor9CvB45m5jOZeQY4DNzc1+d9wJcy8zsAmXlivGVKklYSmbl8h4hbqF55f6hevg24ITMP9fT5z8AUcA2wHfgvmfmFAfs6CBwE2LVr157Dhw+vqujZ2VlmZmZWte1GmPT6YPJrtL61sb61meT69u/f/2Bm7h3YmJnLTsB7gM/2LN8GfLKvz38F7gMuBHYCTwM/vtx+9+zZk6t15MiRVW+7ESa9vszJr9H61sb61maS6wMeyCG5uuI9dKr75lf0LF8OHB/Q56XMfA14LSK+BlwLPDXKiCNJWrtR7qHfD1wdEVdGxDTwXuDuvj5/BvxcRLQi4gLgBuCJ8ZYqSVrOiq/QM7MdEYeArwJN4K7MfCwibq/b78zMJyLifwKPAF2qWzSPrmfhkqSzjXLLhcy8B7inb92dfcsfBz4+vtIkSefDvxSVpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKMVKgR8SBiHgyIo5GxB3L9PuZiOhExC3jK1GSNIoVAz0imsCngBuB3cCtEbF7SL+PAV8dd5GSpJWN8gr9euBoZj6TmWeAw8DNA/r9W+BPgBNjrE+SNKLIzOU7VLdPDmTmh+rl24AbMvNQT5/LgD8Afh74PeDPM/O/D9jXQeAgwK5du/YcPnx4VUXPzs4yMzOzqm03wqTXB5Nfo/WtjfWtzSTXt3///gczc+/AxsxcdgLeA3y2Z/k24JN9ff4YeEc9/znglpX2u2fPnlytI0eOrHrbjTDp9WVOfo3WtzbWtzaTXB/wQA7J1dYIA8Ix4Iqe5cuB43199gKHIwJgJ3BTRLQz88sj7F+SNAajBPr9wNURcSXwXeC9wPt6O2TmlQvzEfE5qlsuXx5fmZKklawY6JnZjohDVL+90gTuyszHIuL2uv3Oda5RkjSCUV6hk5n3APf0rRsY5Jn5r9deliTpfPmXopJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKMVKgR8SBiHgyIo5GxB0D2n81Ih6pp7+JiGvHX6okaTkrBnpENIFPATcCu4FbI2J3X7dvAf8kM38K+G3gM+MuVJK0vFFeoV8PHM3MZzLzDHAYuLm3Q2b+TWa+XC/eB1w+3jKXzM13ONXO9dq9JP3QiszlwzEibgEOZOaH6uXbgBsy89CQ/h8B3r7Qv6/tIHAQYNeuXXsOHz583gW/9MyD/MNnP8/rjRnarRlyy0VMbdvO1gsuorVtO+2p7bRb25mfqqZ2a4ZstM77OGsxOzvLzMzMhh7zfE16jda3Nta3NpNc3/79+x/MzL2D2kZJuhiwbuAoEBH7gQ8C7xrUnpmfob4ds3fv3ty3b98Ihz/bdy/u8vKJr/AG5mid/i4Xzj7BjtlZWtEdvtH0dth2MVxwcfW47WKYnoEt2+vHmZ7lC3vWbV9qm56BxmifId97772s5rltpEmv0frWxvrWZtLrG2aUQD8GXNGzfDlwvL9TRPwU8Fngxsz83njKO9dl1/48T7/cWDzZJ+fm+frxkzz93HG+fewYL774Aie//yIz3VfZEbPsbL7GVc0zXNaYY1f7dXa8+gO2vfIcjTOvwZnZahrV1IV14F8IrS3QnILmdD1NQaNavub7r8BLv1+vb53dZ3F+Glpbq/2c8zhoXf3YrNtj0Dgr6e+zUQL9fuDqiLgS+C7wXuB9vR0i4h8AXwJuy8ynxl7lMi7aOsX1V13C9VddAvwkAGfaXY6emOXx50/y+PGTfPH5H/D48ZOcnGsvbjfdarB9S4uZbQ12bmmzc3qeS6bmuXjqNDuap9nROM1FjdNsb8xxAXNcyCm25Sm2dk+xpfs6zWxXE20a3XkanXk48zp0znDB66/A8RPQnYfOPHTO1I/1fHbW/sSjCY1m/diq3j00Wj3Lve3NnrZq+ulXX4dnd/YMRFPnN99onX3chan3eL11nNVeb7f4HPrmG022zP0/OHl8YNu52/nbtxKMEOiZ2Y6IQ8BXgSZwV2Y+FhG31+13Ah8FLgF+N6pXju1h93g2wnSrwe43XcTuN10Ee6p1mcmxl0/x+PMnOXpilpNz88zOtXntdJvZ021emWtz7FSb2Veqda/OtTndXuY2Tp9mI9jaarB1qgmdeXY0L2DrVJOtW5psnWqwbarJlqkmW1tNtrWSbc0OF8Q8W6PNtkabLcyzNappC/NM5zzTcYZp2kznGabyDNN5hlY936BLM7s0o0sjOzTo1I/dsx7pdqDbrgaR7tJy97X5an7+VD3wtKvBZrn5HP18rNU7ofp4fVS9A9xi8DcGrKsHgKgnYmk+Yulx4Pql/teePAnf2Xn2ABqNnkHs7AH03IG299gxpJZYpk8MmF/a5tLjT8MD3xrQPuw5LzcN6XPO+ez/GQwftFvzs3DqlWXqW+75aZgVPxRdL3v37s0HHnhgVdtu1P2tM+3uYuAvTnNtXj3dZm6+w+n5DnPzXebmO8y1l+affe44Oy750XPWz9X9T7c7nGl3OdPpMt9JOt31+RlEwFSjQasZtBrBdKtBq16ePz3H9pkLaTWibm8szk81GzQbZ69rNYKpBkxHhy2NDtORtKLLdHRpRYepyGpqdGhFlym6tKJLiw7NSFrRoUW3njrVQESXViRNujRImrE0SD337W9x5ZuvoEnSiC6N7Nb9qoEq6BJU6xvZhcX1SWSHyHpAyy6R3XpA6y4NbGQ1QGUXsmcehqw/u/8rL3+PHRdtrwbLhYFymQG0Wm5XNXTbPfvLs/evEcTZIT90MBjUZ7m2pe3nTp9m69Zt9fLCMXsGF6D6meWQeQavh2r5Zz4I7/7I6p59xJo+FP17a7rVYLo1zcUXTp/Xdvfe+z327btu5P6dbjLfqQO+XYX8UuB3OdPuLrXXbe1Ol/luMt/u0u5W69t1+3y3S7tePlM/tutjzHeqtuMvvMAbds5U/eq2Tjdpd5LX2m3a9Xy7212ar/fT7laDUKdbtVf1DxuUFm6HNM/rHMJl8PR5bjKsgqjeQTWimqp5aDSCZsTS48K6ejl6tlvcvhE0A149fZKL2zuqfTeDRiuIqNoaUc83WNymUe+/Wbc1oreNxfYAmg2qwY2gEUkjkladOU269TGyfqR6t7awD5JmI3n2mWd421uvqpern8LCNkG1zyZJgyQiq4GxHjwDqvl6oG3QrbZZnDr18sK7wWowqvZRLQcLg2o1CC8MrI16/bef/RZXvuXNVPHYrR+rayjq40VmHZ31MtTrunW/hbDsfewuBeg5bb2D54C2xe3h5ReOc+muHxu+/UKo9wb8SPP1RXnJ28Zzcfcx0CdAsxE0G83qds0Gqd7l7BnrPrt12HezDv3OUuC3FweApNPt0umy2NbpaVvYx/99+GGuueYnlwaPrLZr1+9ougmdrPp3c2Fdvb7eT6deXpqv13ep+/Zs113a31nb1cuZC/PV+lONKky7XWh3utW+srq1V+2XxW26meRCvfWxFo7fXdyGxXoyz27v9jy30c3AUyfG+vNd0jtIT61yH2+FJ8dQSbA4QEZENRj1LteD5MKgGvT25+x1DQiqtrlTp7jgtQsW2xsL+xqwLT2D8WI7sfiGIFja98I+fulNl/Ira3/65zDQNTaNRjDdGM89zu7xFvt27xrLvtZDNSC+c8OPuzRIcM5AkfVA0cnk//z1X/POd/7s2QPK4sCwMGjQt9w7mJw90HSzuo2wMJBmX9+Fbfu36d/fQr1PPvkkb7v6x0k4Z1+9y8ngfS8s97Z3e9fV5ygZVBdANbAmC8dcGowTeOGF0+x840X1cx5QH0v77H0OC8db3KYLSbe647a4Hcy1x/CLEQMY6NIPkYjqM42V7NjSYNdFWzegotW59/Vn2PeON292GUNVA/bot00nhb/vJUmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIUYK9Ig4EBFPRsTRiLhjQHtExO/U7Y9ExHXjL1WStJwVAz0imsCngBuB3cCtEbG7r9uNwNX1dBD49JjrlCStYJRX6NcDRzPzmcw8AxwGbu7rczPwhazcB+yIiEvHXKskaRmtEfpcBjzXs3wMuGGEPpcBz/d2ioiDVK/gAWYj4snzqnbJTuClVW67ESa9Ppj8Gq1vbaxvbSa5vjcPaxgl0GPAulxFHzLzM8BnRjjm8gVFPJCZe9e6n/Uy6fXB5NdofWtjfWsz6fUNM8otl2PAFT3LlwPHV9FHkrSORgn0+4GrI+LKiJgG3gvc3dfnbuDX6t92eQfwg8x8vn9HkqT1s+Itl8xsR8Qh4KtAE7grMx+LiNvr9juBe4CbgKPA68AH1q9kYAy3bdbZpNcHk1+j9a2N9a3NpNc3UGSec6tbkvRDyL8UlaRCGOiSVIiJDvRJ/sqBiLgiIo5ExBMR8VhE/LsBffZFxA8i4qF6+uhG1Vcf/9mI+EZ97AcGtG/m+fuJnvPyUEScjIhf7+uz4ecvIu6KiBMR8WjPujdExP+KiKfrx4uHbLvs9bqO9X08Iv6u/hn+aUTsGLLtstfDOtb3WxHx3Z6f401Dtt2s8/dHPbU9GxEPDdl23c/fmmXmRE5UH8B+E7gKmAYeBnb39bkJ+Auq34N/B/C3G1jfpcB19fx24KkB9e0D/nwTz+GzwM5l2jft/A34Wb8AvHmzzx/wbuA64NGedf8BuKOevwP42JDnsOz1uo71/SLQquc/Nqi+Ua6Hdazvt4CPjHANbMr562v/BPDRzTp/a50m+RX6RH/lQGY+n5lfr+dfBZ6g+uvYHyaT8pUNvwB8MzO/vQnHPktmfg34ft/qm4HP1/OfB/75gE1HuV7Xpb7M/MvMbNeL91H9HcimGHL+RrFp529BRATwK8Afjvu4G2WSA33Y1wmcb591FxFvAX4a+NsBze+MiIcj4i8i4pqNrYwE/jIiHqy/dqHfRJw/qr9tGPaPaDPP34JdWf9dRf34xgF9JuVc/huqd12DrHQ9rKdD9S2hu4bcspqE8/dzwIuZ+fSQ9s08fyOZ5EAf21cOrKeImAH+BPj1zDzZ1/x1qtsI1wKfBL68kbUB/zgzr6P6NswPR8S7+9on4fxNA78M/PGA5s0+f+djEs7lbwJt4ItDuqx0PayXTwNvBf4R1fc7fWJAn00/f8CtLP/qfLPO38gmOdAn/isHImKKKsy/mJlf6m/PzJOZOVvP3wNMRcTOjaovM4/XjyeAP6V6W9trEr6y4Ubg65n5Yn/DZp+/Hi8u3IqqH08M6LPZ1+L7gV8CfjXrG779Rrge1kVmvpiZnczsAv9tyHE3+/y1gH8J/NGwPpt1/s7HJAf6RH/lQH2/7feAJzLzPw7p82N1PyLieqrz/b0Nqu/CiNi+ME/1wdmjfd0m4Ssbhr4q2szz1+du4P31/PuBPxvQZ5TrdV1ExAHgN4BfzszXh/QZ5XpYr/p6P5f5F0OOu2nnr/ZPgb/LzGODGjfz/J2Xzf5UdrmJ6rcwnqL69Ps363W3A7fX80H1n298E/gGsHcDa3sX1VvCR4CH6ummvvoOAY9RfWJ/H/CzG1jfVfVxH65rmKjzVx//AqqA/pGedZt6/qgGl+eBeapXjR8ELgH+Cni6fnxD3fdNwD3LXa8bVN9RqvvPC9fhnf31DbseNqi+36+vr0eoQvrSSTp/9frPLVx3PX03/PytdfJP/yWpEJN8y0WSdB4MdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklSI/w9WhnjEORUVjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9570178",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb3274f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a87c84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5468 samples, validate on 1823 samples\n",
      "Epoch 1/20\n",
      "5468/5468 [==============================] - 1s 174us/sample - loss: 0.4554 - val_loss: 0.3322\n",
      "Epoch 2/20\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.2749 - val_loss: 0.2466\n",
      "Epoch 3/20\n",
      "5468/5468 [==============================] - 0s 77us/sample - loss: 0.2172 - val_loss: 0.2125\n",
      "Epoch 4/20\n",
      "5468/5468 [==============================] - 0s 79us/sample - loss: 0.1929 - val_loss: 0.1971\n",
      "Epoch 5/20\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1816 - val_loss: 0.1897\n",
      "Epoch 6/20\n",
      "5468/5468 [==============================] - 1s 99us/sample - loss: 0.1760 - val_loss: 0.1857\n",
      "Epoch 7/20\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1728 - val_loss: 0.1838\n",
      "Epoch 8/20\n",
      "5468/5468 [==============================] - 1s 105us/sample - loss: 0.1707 - val_loss: 0.1817\n",
      "Epoch 9/20\n",
      "5468/5468 [==============================] - 1s 100us/sample - loss: 0.1691 - val_loss: 0.1801\n",
      "Epoch 10/20\n",
      "5468/5468 [==============================] - 1s 96us/sample - loss: 0.1678 - val_loss: 0.1788\n",
      "Epoch 11/20\n",
      "5468/5468 [==============================] - 1s 96us/sample - loss: 0.1667 - val_loss: 0.1780\n",
      "Epoch 12/20\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.1658 - val_loss: 0.1771\n",
      "Epoch 13/20\n",
      "5468/5468 [==============================] - 0s 79us/sample - loss: 0.1650 - val_loss: 0.1757\n",
      "Epoch 14/20\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1642 - val_loss: 0.1752\n",
      "Epoch 15/20\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.1634 - val_loss: 0.1741\n",
      "Epoch 16/20\n",
      "5468/5468 [==============================] - 0s 80us/sample - loss: 0.1630 - val_loss: 0.1735\n",
      "Epoch 17/20\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1624 - val_loss: 0.1730\n",
      "Epoch 18/20\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1618 - val_loss: 0.1723\n",
      "Epoch 19/20\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1613 - val_loss: 0.1718\n",
      "Epoch 20/20\n",
      "5468/5468 [==============================] - 0s 82us/sample - loss: 0.1609 - val_loss: 0.1718\n",
      "2431/2431 [==============================] - 0s 37us/sample - loss: 0.1641\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f068ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79b136d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5468 samples, validate on 1823 samples\n",
      "Epoch 1/20\n",
      "5468/5468 [==============================] - 1s 179us/sample - loss: 0.3455 - val_loss: 0.2696\n",
      "Epoch 2/20\n",
      "5468/5468 [==============================] - 0s 80us/sample - loss: 0.2313 - val_loss: 0.2168\n",
      "Epoch 3/20\n",
      "5468/5468 [==============================] - 0s 82us/sample - loss: 0.1985 - val_loss: 0.1986\n",
      "Epoch 4/20\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1857 - val_loss: 0.1902\n",
      "Epoch 5/20\n",
      "5468/5468 [==============================] - 0s 82us/sample - loss: 0.1792 - val_loss: 0.1857\n",
      "Epoch 6/20\n",
      "5468/5468 [==============================] - 0s 77us/sample - loss: 0.1754 - val_loss: 0.1822\n",
      "Epoch 7/20\n",
      "5468/5468 [==============================] - 0s 77us/sample - loss: 0.1728 - val_loss: 0.1803\n",
      "Epoch 8/20\n",
      "5468/5468 [==============================] - 0s 80us/sample - loss: 0.1710 - val_loss: 0.1781\n",
      "Epoch 9/20\n",
      "5468/5468 [==============================] - 0s 83us/sample - loss: 0.1694 - val_loss: 0.1765\n",
      "Epoch 10/20\n",
      "5468/5468 [==============================] - 0s 80us/sample - loss: 0.1684 - val_loss: 0.1755\n",
      "Epoch 11/20\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1674 - val_loss: 0.1742\n",
      "Epoch 12/20\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1665 - val_loss: 0.1733\n",
      "Epoch 13/20\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1659 - val_loss: 0.1727\n",
      "Epoch 14/20\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1652 - val_loss: 0.1723\n",
      "Epoch 15/20\n",
      "5468/5468 [==============================] - 0s 83us/sample - loss: 0.1647 - val_loss: 0.1717\n",
      "Epoch 16/20\n",
      "5468/5468 [==============================] - 0s 80us/sample - loss: 0.1643 - val_loss: 0.1713\n",
      "Epoch 17/20\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1639 - val_loss: 0.1707\n",
      "Epoch 18/20\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.1635 - val_loss: 0.1702\n",
      "Epoch 19/20\n",
      "5468/5468 [==============================] - 1s 102us/sample - loss: 0.1631 - val_loss: 0.1700\n",
      "Epoch 20/20\n",
      "5468/5468 [==============================] - 1s 99us/sample - loss: 0.1628 - val_loss: 0.1692\n",
      "2431/2431 [==============================] - 0s 41us/sample - loss: 0.1642\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38f222dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39d9113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b374921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5468 samples, validate on 1823 samples\n",
      "Epoch 1/20\n",
      "5468/5468 [==============================] - 2s 356us/sample - loss: 0.2472 - main_output_loss: 0.2427 - aux_output_loss: 0.2872 - val_loss: 0.2394 - val_main_output_loss: 0.2333 - val_aux_output_loss: 0.2939\n",
      "Epoch 2/20\n",
      "5468/5468 [==============================] - 1s 105us/sample - loss: 0.2188 - main_output_loss: 0.2116 - aux_output_loss: 0.2836 - val_loss: 0.2201 - val_main_output_loss: 0.2122 - val_aux_output_loss: 0.2908\n",
      "Epoch 3/20\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.2043 - main_output_loss: 0.1959 - aux_output_loss: 0.2809 - val_loss: 0.2088 - val_main_output_loss: 0.2000 - val_aux_output_loss: 0.2884\n",
      "Epoch 4/20\n",
      "5468/5468 [==============================] - 1s 98us/sample - loss: 0.1957 - main_output_loss: 0.1865 - aux_output_loss: 0.2789 - val_loss: 0.2016 - val_main_output_loss: 0.1922 - val_aux_output_loss: 0.2863\n",
      "Epoch 5/20\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1901 - main_output_loss: 0.1804 - aux_output_loss: 0.2771 - val_loss: 0.1968 - val_main_output_loss: 0.1870 - val_aux_output_loss: 0.2847\n",
      "Epoch 6/20\n",
      "5468/5468 [==============================] - 1s 97us/sample - loss: 0.1861 - main_output_loss: 0.1761 - aux_output_loss: 0.2757 - val_loss: 0.1931 - val_main_output_loss: 0.1831 - val_aux_output_loss: 0.2831\n",
      "Epoch 7/20\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.1830 - main_output_loss: 0.1729 - aux_output_loss: 0.2744 - val_loss: 0.1903 - val_main_output_loss: 0.1802 - val_aux_output_loss: 0.2816\n",
      "Epoch 8/20\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1808 - main_output_loss: 0.1705 - aux_output_loss: 0.2731 - val_loss: 0.1882 - val_main_output_loss: 0.1780 - val_aux_output_loss: 0.2802\n",
      "Epoch 9/20\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.1790 - main_output_loss: 0.1687 - aux_output_loss: 0.2718 - val_loss: 0.1864 - val_main_output_loss: 0.1761 - val_aux_output_loss: 0.2788\n",
      "Epoch 10/20\n",
      "5468/5468 [==============================] - 1s 95us/sample - loss: 0.1775 - main_output_loss: 0.1672 - aux_output_loss: 0.2707 - val_loss: 0.1849 - val_main_output_loss: 0.1746 - val_aux_output_loss: 0.2775\n",
      "Epoch 11/20\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1764 - main_output_loss: 0.1661 - aux_output_loss: 0.2697 - val_loss: 0.1838 - val_main_output_loss: 0.1735 - val_aux_output_loss: 0.2764\n",
      "Epoch 12/20\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1754 - main_output_loss: 0.1651 - aux_output_loss: 0.2687 - val_loss: 0.1826 - val_main_output_loss: 0.1723 - val_aux_output_loss: 0.2754\n",
      "Epoch 13/20\n",
      "5468/5468 [==============================] - 1s 91us/sample - loss: 0.1746 - main_output_loss: 0.1642 - aux_output_loss: 0.2678 - val_loss: 0.1816 - val_main_output_loss: 0.1713 - val_aux_output_loss: 0.2744\n",
      "Epoch 14/20\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.1738 - main_output_loss: 0.1635 - aux_output_loss: 0.2670 - val_loss: 0.1808 - val_main_output_loss: 0.1705 - val_aux_output_loss: 0.2735\n",
      "Epoch 15/20\n",
      "5468/5468 [==============================] - 1s 97us/sample - loss: 0.1731 - main_output_loss: 0.1627 - aux_output_loss: 0.2662 - val_loss: 0.1800 - val_main_output_loss: 0.1697 - val_aux_output_loss: 0.2726\n",
      "Epoch 16/20\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1726 - main_output_loss: 0.1623 - aux_output_loss: 0.2653 - val_loss: 0.1797 - val_main_output_loss: 0.1694 - val_aux_output_loss: 0.2718\n",
      "Epoch 17/20\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1721 - main_output_loss: 0.1618 - aux_output_loss: 0.2646 - val_loss: 0.1789 - val_main_output_loss: 0.1687 - val_aux_output_loss: 0.2710\n",
      "Epoch 18/20\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1717 - main_output_loss: 0.1614 - aux_output_loss: 0.2639 - val_loss: 0.1785 - val_main_output_loss: 0.1683 - val_aux_output_loss: 0.2703\n",
      "Epoch 19/20\n",
      "5468/5468 [==============================] - 1s 102us/sample - loss: 0.1713 - main_output_loss: 0.1611 - aux_output_loss: 0.2631 - val_loss: 0.1782 - val_main_output_loss: 0.1680 - val_aux_output_loss: 0.2696\n",
      "Epoch 20/20\n",
      "5468/5468 [==============================] - 1s 93us/sample - loss: 0.1710 - main_output_loss: 0.1608 - aux_output_loss: 0.2625 - val_loss: 0.1778 - val_main_output_loss: 0.1676 - val_aux_output_loss: 0.2689\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cbe0eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 41us/sample - loss: 0.1734 - main_output_loss: 0.1626 - aux_output_loss: 0.2702\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "[X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a04b49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac85e7fd",
   "metadata": {},
   "source": [
    "## Using the Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a8033ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac6fe3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5468 samples, validate on 1823 samples\n",
      "Epoch 1/10\n",
      "5468/5468 [==============================] - 1s 245us/sample - loss: 0.4173 - output_1_loss: 0.4268 - output_2_loss: 0.3302 - val_loss: 0.2227 - val_output_1_loss: 0.2112 - val_output_2_loss: 0.3270\n",
      "Epoch 2/10\n",
      "5468/5468 [==============================] - 1s 107us/sample - loss: 0.2134 - output_1_loss: 0.2005 - output_2_loss: 0.3291 - val_loss: 0.2093 - val_output_1_loss: 0.1972 - val_output_2_loss: 0.3182\n",
      "Epoch 3/10\n",
      "5468/5468 [==============================] - 1s 108us/sample - loss: 0.2035 - output_1_loss: 0.1905 - output_2_loss: 0.3206 - val_loss: 0.2033 - val_output_1_loss: 0.1911 - val_output_2_loss: 0.3126\n",
      "Epoch 4/10\n",
      "5468/5468 [==============================] - 1s 110us/sample - loss: 0.1977 - output_1_loss: 0.1846 - output_2_loss: 0.3153 - val_loss: 0.1994 - val_output_1_loss: 0.1872 - val_output_2_loss: 0.3089\n",
      "Epoch 5/10\n",
      "5468/5468 [==============================] - 1s 108us/sample - loss: 0.1938 - output_1_loss: 0.1808 - output_2_loss: 0.3115 - val_loss: 0.1965 - val_output_1_loss: 0.1843 - val_output_2_loss: 0.3060\n",
      "Epoch 6/10\n",
      "5468/5468 [==============================] - 1s 105us/sample - loss: 0.1910 - output_1_loss: 0.1779 - output_2_loss: 0.3084 - val_loss: 0.1943 - val_output_1_loss: 0.1821 - val_output_2_loss: 0.3035\n",
      "Epoch 7/10\n",
      "5468/5468 [==============================] - 1s 113us/sample - loss: 0.1887 - output_1_loss: 0.1757 - output_2_loss: 0.3059 - val_loss: 0.1924 - val_output_1_loss: 0.1803 - val_output_2_loss: 0.3012\n",
      "Epoch 8/10\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1869 - output_1_loss: 0.1739 - output_2_loss: 0.3033 - val_loss: 0.1909 - val_output_1_loss: 0.1789 - val_output_2_loss: 0.2993\n",
      "Epoch 9/10\n",
      "5468/5468 [==============================] - 1s 97us/sample - loss: 0.1853 - output_1_loss: 0.1724 - output_2_loss: 0.3011 - val_loss: 0.1894 - val_output_1_loss: 0.1775 - val_output_2_loss: 0.2973\n",
      "Epoch 10/10\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1840 - output_1_loss: 0.1712 - output_2_loss: 0.2991 - val_loss: 0.1882 - val_output_1_loss: 0.1763 - val_output_2_loss: 0.2956\n",
      "2431/2431 [==============================] - 0s 39us/sample - loss: 0.1871 - output_1_loss: 0.1736 - output_2_loss: 0.3084\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10, \n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d55b1",
   "metadata": {},
   "source": [
    "## Saving and Restoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac305527",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3483370",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "975bf6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f49122df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15aa31f",
   "metadata": {},
   "source": [
    "## Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "761c6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94aec5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73b83178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5468 samples\n",
      "Epoch 1/10\n",
      "5468/5468 [==============================] - 1s 128us/sample - loss: 0.4313\n",
      "Epoch 2/10\n",
      "5468/5468 [==============================] - 0s 64us/sample - loss: 0.2829\n",
      "Epoch 3/10\n",
      "5468/5468 [==============================] - 0s 64us/sample - loss: 0.2271\n",
      "Epoch 4/10\n",
      "5468/5468 [==============================] - 0s 63us/sample - loss: 0.2032\n",
      "Epoch 5/10\n",
      "5468/5468 [==============================] - 0s 59us/sample - loss: 0.1917\n",
      "Epoch 6/10\n",
      "5468/5468 [==============================] - 0s 63us/sample - loss: 0.1858\n",
      "Epoch 7/10\n",
      "5468/5468 [==============================] - 0s 62us/sample - loss: 0.1822\n",
      "Epoch 8/10\n",
      "5468/5468 [==============================] - 0s 65us/sample - loss: 0.1800\n",
      "Epoch 9/10\n",
      "5468/5468 [==============================] - 0s 62us/sample - loss: 0.1781\n",
      "Epoch 10/10\n",
      "5468/5468 [==============================] - 0s 62us/sample - loss: 0.1766\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "779d3e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5468 samples, validate on 1823 samples\n",
      "Epoch 1/10\n",
      "5468/5468 [==============================] - 1s 98us/sample - loss: 0.1755 - val_loss: 0.1792\n",
      "Epoch 2/10\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1743 - val_loss: 0.1784\n",
      "Epoch 3/10\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1731 - val_loss: 0.1770\n",
      "Epoch 4/10\n",
      "5468/5468 [==============================] - 0s 77us/sample - loss: 0.1721 - val_loss: 0.1768\n",
      "Epoch 5/10\n",
      "5468/5468 [==============================] - 0s 82us/sample - loss: 0.1713 - val_loss: 0.1755\n",
      "Epoch 6/10\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1704 - val_loss: 0.1748\n",
      "Epoch 7/10\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1697 - val_loss: 0.1738\n",
      "Epoch 8/10\n",
      "5468/5468 [==============================] - 0s 77us/sample - loss: 0.1690 - val_loss: 0.1731\n",
      "Epoch 9/10\n",
      "5468/5468 [==============================] - 0s 77us/sample - loss: 0.1683 - val_loss: 0.1727\n",
      "Epoch 10/10\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1678 - val_loss: 0.1723\n",
      "2431/2431 [==============================] - 0s 61us/sample - loss: 0.1675\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") \n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a6d16bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5468 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "5468/5468 [==============================] - 1s 114us/sample - loss: 0.1673 - val_loss: 0.1713\n",
      "Epoch 2/100\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1667 - val_loss: 0.1710\n",
      "Epoch 3/100\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1661 - val_loss: 0.1715\n",
      "Epoch 4/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1659 - val_loss: 0.1704\n",
      "Epoch 5/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1654 - val_loss: 0.1698\n",
      "Epoch 6/100\n",
      "5468/5468 [==============================] - 1s 103us/sample - loss: 0.1650 - val_loss: 0.1693\n",
      "Epoch 7/100\n",
      "5468/5468 [==============================] - 1s 95us/sample - loss: 0.1646 - val_loss: 0.1691\n",
      "Epoch 8/100\n",
      "5468/5468 [==============================] - 1s 93us/sample - loss: 0.1641 - val_loss: 0.1689\n",
      "Epoch 9/100\n",
      "5468/5468 [==============================] - 1s 97us/sample - loss: 0.1638 - val_loss: 0.1684\n",
      "Epoch 10/100\n",
      "5468/5468 [==============================] - 0s 88us/sample - loss: 0.1633 - val_loss: 0.1680\n",
      "Epoch 11/100\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1630 - val_loss: 0.1681\n",
      "Epoch 12/100\n",
      "5468/5468 [==============================] - 0s 74us/sample - loss: 0.1627 - val_loss: 0.1670\n",
      "Epoch 13/100\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1624 - val_loss: 0.1669\n",
      "Epoch 14/100\n",
      "5468/5468 [==============================] - 0s 79us/sample - loss: 0.1621 - val_loss: 0.1667\n",
      "Epoch 15/100\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.1618 - val_loss: 0.1666\n",
      "Epoch 16/100\n",
      "5468/5468 [==============================] - 0s 79us/sample - loss: 0.1615 - val_loss: 0.1661\n",
      "Epoch 17/100\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1612 - val_loss: 0.1664\n",
      "Epoch 18/100\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1609 - val_loss: 0.1658\n",
      "Epoch 19/100\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1607 - val_loss: 0.1654\n",
      "Epoch 20/100\n",
      "5468/5468 [==============================] - 0s 80us/sample - loss: 0.1604 - val_loss: 0.1653\n",
      "Epoch 21/100\n",
      "5468/5468 [==============================] - 0s 79us/sample - loss: 0.1601 - val_loss: 0.1652\n",
      "Epoch 22/100\n",
      "5468/5468 [==============================] - 0s 79us/sample - loss: 0.1599 - val_loss: 0.1648\n",
      "Epoch 23/100\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1596 - val_loss: 0.1645\n",
      "Epoch 24/100\n",
      "5468/5468 [==============================] - 1s 98us/sample - loss: 0.1594 - val_loss: 0.1643\n",
      "Epoch 25/100\n",
      "5468/5468 [==============================] - 0s 79us/sample - loss: 0.1591 - val_loss: 0.1639\n",
      "Epoch 26/100\n",
      "5468/5468 [==============================] - 0s 74us/sample - loss: 0.1590 - val_loss: 0.1642\n",
      "Epoch 27/100\n",
      "5468/5468 [==============================] - 0s 79us/sample - loss: 0.1587 - val_loss: 0.1637\n",
      "Epoch 28/100\n",
      "5468/5468 [==============================] - 0s 74us/sample - loss: 0.1585 - val_loss: 0.1637\n",
      "Epoch 29/100\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1583 - val_loss: 0.1641\n",
      "Epoch 30/100\n",
      "5468/5468 [==============================] - 0s 83us/sample - loss: 0.1582 - val_loss: 0.1631\n",
      "Epoch 31/100\n",
      "5468/5468 [==============================] - 0s 80us/sample - loss: 0.1579 - val_loss: 0.1630\n",
      "Epoch 32/100\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1577 - val_loss: 0.1626\n",
      "Epoch 33/100\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1575 - val_loss: 0.1626\n",
      "Epoch 34/100\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1573 - val_loss: 0.1622\n",
      "Epoch 35/100\n",
      "5468/5468 [==============================] - 1s 95us/sample - loss: 0.1572 - val_loss: 0.1620\n",
      "Epoch 36/100\n",
      "5468/5468 [==============================] - 0s 88us/sample - loss: 0.1570 - val_loss: 0.1619\n",
      "Epoch 37/100\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1568 - val_loss: 0.1626\n",
      "Epoch 38/100\n",
      "5468/5468 [==============================] - 0s 82us/sample - loss: 0.1567 - val_loss: 0.1620\n",
      "Epoch 39/100\n",
      "5468/5468 [==============================] - 1s 96us/sample - loss: 0.1565 - val_loss: 0.1614\n",
      "Epoch 40/100\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1564 - val_loss: 0.1617\n",
      "Epoch 41/100\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1562 - val_loss: 0.1616\n",
      "Epoch 42/100\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.1561 - val_loss: 0.1614\n",
      "Epoch 43/100\n",
      "5468/5468 [==============================] - 1s 93us/sample - loss: 0.1559 - val_loss: 0.1609\n",
      "Epoch 44/100\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1558 - val_loss: 0.1609\n",
      "Epoch 45/100\n",
      "5468/5468 [==============================] - 1s 100us/sample - loss: 0.1556 - val_loss: 0.1606\n",
      "Epoch 46/100\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1555 - val_loss: 0.1609\n",
      "Epoch 47/100\n",
      "5468/5468 [==============================] - 0s 74us/sample - loss: 0.1554 - val_loss: 0.1608\n",
      "Epoch 48/100\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1553 - val_loss: 0.1604\n",
      "Epoch 49/100\n",
      "5468/5468 [==============================] - 0s 80us/sample - loss: 0.1551 - val_loss: 0.1601\n",
      "Epoch 50/100\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1550 - val_loss: 0.1602\n",
      "Epoch 51/100\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1549 - val_loss: 0.1599\n",
      "Epoch 52/100\n",
      "5468/5468 [==============================] - 0s 74us/sample - loss: 0.1548 - val_loss: 0.1601\n",
      "Epoch 53/100\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1547 - val_loss: 0.1600\n",
      "Epoch 54/100\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1545 - val_loss: 0.1597\n",
      "Epoch 55/100\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1544 - val_loss: 0.1598\n",
      "Epoch 56/100\n",
      "5468/5468 [==============================] - 0s 74us/sample - loss: 0.1542 - val_loss: 0.1603\n",
      "Epoch 57/100\n",
      "5468/5468 [==============================] - 0s 72us/sample - loss: 0.1542 - val_loss: 0.1598\n",
      "Epoch 58/100\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1541 - val_loss: 0.1596\n",
      "Epoch 59/100\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1539 - val_loss: 0.1593\n",
      "Epoch 60/100\n",
      "5468/5468 [==============================] - 0s 77us/sample - loss: 0.1538 - val_loss: 0.1594\n",
      "Epoch 61/100\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1537 - val_loss: 0.1589\n",
      "Epoch 62/100\n",
      "5468/5468 [==============================] - 0s 73us/sample - loss: 0.1537 - val_loss: 0.1592\n",
      "Epoch 63/100\n",
      "5468/5468 [==============================] - 0s 80us/sample - loss: 0.1536 - val_loss: 0.1589\n",
      "Epoch 64/100\n",
      "5468/5468 [==============================] - 0s 72us/sample - loss: 0.1534 - val_loss: 0.1592\n",
      "Epoch 65/100\n",
      "5468/5468 [==============================] - 0s 79us/sample - loss: 0.1533 - val_loss: 0.1587\n",
      "Epoch 66/100\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1532 - val_loss: 0.1590\n",
      "Epoch 67/100\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1532 - val_loss: 0.1586\n",
      "Epoch 68/100\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1530 - val_loss: 0.1588\n",
      "Epoch 69/100\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1530 - val_loss: 0.1583\n",
      "Epoch 70/100\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1529 - val_loss: 0.1582\n",
      "Epoch 71/100\n",
      "5468/5468 [==============================] - 0s 83us/sample - loss: 0.1528 - val_loss: 0.1581\n",
      "Epoch 72/100\n",
      "5468/5468 [==============================] - 0s 80us/sample - loss: 0.1527 - val_loss: 0.1580\n",
      "Epoch 73/100\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1526 - val_loss: 0.1579\n",
      "Epoch 74/100\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1525 - val_loss: 0.1579\n",
      "Epoch 75/100\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1524 - val_loss: 0.1582\n",
      "Epoch 76/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1522 - val_loss: 0.1580\n",
      "Epoch 77/100\n",
      "5468/5468 [==============================] - 1s 204us/sample - loss: 0.1522 - val_loss: 0.1578\n",
      "Epoch 78/100\n",
      "5468/5468 [==============================] - 1s 145us/sample - loss: 0.1522 - val_loss: 0.1577\n",
      "Epoch 79/100\n",
      "5468/5468 [==============================] - 0s 77us/sample - loss: 0.1520 - val_loss: 0.1578\n",
      "Epoch 80/100\n",
      "5468/5468 [==============================] - 0s 83us/sample - loss: 0.1520 - val_loss: 0.1575\n",
      "Epoch 81/100\n",
      "5468/5468 [==============================] - 0s 88us/sample - loss: 0.1519 - val_loss: 0.1574\n",
      "Epoch 82/100\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1518 - val_loss: 0.1572\n",
      "Epoch 83/100\n",
      "5468/5468 [==============================] - 0s 67us/sample - loss: 0.1517 - val_loss: 0.1575\n",
      "Epoch 84/100\n",
      "5468/5468 [==============================] - 0s 67us/sample - loss: 0.1516 - val_loss: 0.1576\n",
      "Epoch 85/100\n",
      "5468/5468 [==============================] - 0s 69us/sample - loss: 0.1516 - val_loss: 0.1572\n",
      "Epoch 86/100\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1515 - val_loss: 0.1569\n",
      "Epoch 87/100\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1514 - val_loss: 0.1573\n",
      "Epoch 88/100\n",
      "5468/5468 [==============================] - 0s 71us/sample - loss: 0.1514 - val_loss: 0.1572\n",
      "Epoch 89/100\n",
      "5468/5468 [==============================] - 0s 83us/sample - loss: 0.1513 - val_loss: 0.1568\n",
      "Epoch 90/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1512 - val_loss: 0.1566\n",
      "Epoch 91/100\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1511 - val_loss: 0.1567\n",
      "Epoch 92/100\n",
      "5468/5468 [==============================] - 0s 77us/sample - loss: 0.1510 - val_loss: 0.1569\n",
      "Epoch 93/100\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1510 - val_loss: 0.1567\n",
      "Epoch 94/100\n",
      "5468/5468 [==============================] - 0s 87us/sample - loss: 0.1509 - val_loss: 0.1566\n",
      "Epoch 95/100\n",
      "5468/5468 [==============================] - 1s 93us/sample - loss: 0.1508 - val_loss: 0.1564\n",
      "Epoch 96/100\n",
      "5468/5468 [==============================] - 1s 99us/sample - loss: 0.1507 - val_loss: 0.1567\n",
      "Epoch 97/100\n",
      "5468/5468 [==============================] - 1s 101us/sample - loss: 0.1506 - val_loss: 0.1564\n",
      "Epoch 98/100\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.1506 - val_loss: 0.1565\n",
      "Epoch 99/100\n",
      "5468/5468 [==============================] - 0s 83us/sample - loss: 0.1505 - val_loss: 0.1564\n",
      "Epoch 100/100\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1504 - val_loss: 0.1561\n",
      "2431/2431 [==============================] - 0s 44us/sample - loss: 0.1513\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09b5b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "932767d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5468 samples, validate on 1823 samples\n",
      "4672/5468 [========================>.....] - ETA: 0s - loss: 0.1517\n",
      "val/train: 1.04\n",
      "5468/5468 [==============================] - 0s 87us/sample - loss: 0.1504 - val_loss: 0.1561\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82e7766",
   "metadata": {},
   "source": [
    "## Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7e91221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0decbb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf5251ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "665fb977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5468 samples, validate on 1823 samples\n",
      "Epoch 1/30\n",
      "5468/5468 [==============================] - 1s 175us/sample - loss: 0.2725 - val_loss: 0.2419\n",
      "Epoch 2/30\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.2264 - val_loss: 0.2152\n",
      "Epoch 3/30\n",
      "5468/5468 [==============================] - 1s 96us/sample - loss: 0.2047 - val_loss: 0.2007\n",
      "Epoch 4/30\n",
      "5468/5468 [==============================] - 1s 102us/sample - loss: 0.1922 - val_loss: 0.1922\n",
      "Epoch 5/30\n",
      "5468/5468 [==============================] - 1s 102us/sample - loss: 0.1846 - val_loss: 0.1868\n",
      "Epoch 6/30\n",
      "5468/5468 [==============================] - 1s 105us/sample - loss: 0.1797 - val_loss: 0.1832\n",
      "Epoch 7/30\n",
      "5468/5468 [==============================] - 1s 109us/sample - loss: 0.1763 - val_loss: 0.1805\n",
      "Epoch 8/30\n",
      "5468/5468 [==============================] - 1s 130us/sample - loss: 0.1738 - val_loss: 0.1785\n",
      "Epoch 9/30\n",
      "5468/5468 [==============================] - 1s 121us/sample - loss: 0.1720 - val_loss: 0.1769\n",
      "Epoch 10/30\n",
      "5468/5468 [==============================] - 1s 97us/sample - loss: 0.1706 - val_loss: 0.1758\n",
      "Epoch 11/30\n",
      "5468/5468 [==============================] - 0s 87us/sample - loss: 0.1695 - val_loss: 0.1748\n",
      "Epoch 12/30\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1684 - val_loss: 0.1744\n",
      "Epoch 13/30\n",
      "5468/5468 [==============================] - 0s 88us/sample - loss: 0.1676 - val_loss: 0.1733\n",
      "Epoch 14/30\n",
      "5468/5468 [==============================] - 0s 83us/sample - loss: 0.1669 - val_loss: 0.1725\n",
      "Epoch 15/30\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.1663 - val_loss: 0.1719\n",
      "Epoch 16/30\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1656 - val_loss: 0.1715\n",
      "Epoch 17/30\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.1650 - val_loss: 0.1710\n",
      "Epoch 18/30\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.1644 - val_loss: 0.1702\n",
      "Epoch 19/30\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1639 - val_loss: 0.1697\n",
      "Epoch 20/30\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1635 - val_loss: 0.1694\n",
      "Epoch 21/30\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1631 - val_loss: 0.1689\n",
      "Epoch 22/30\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1627 - val_loss: 0.1687\n",
      "Epoch 23/30\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.1623 - val_loss: 0.1683\n",
      "Epoch 24/30\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1619 - val_loss: 0.1679\n",
      "Epoch 25/30\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1615 - val_loss: 0.1678\n",
      "Epoch 26/30\n",
      "5468/5468 [==============================] - 0s 83us/sample - loss: 0.1613 - val_loss: 0.1673\n",
      "Epoch 27/30\n",
      "5468/5468 [==============================] - 0s 88us/sample - loss: 0.1610 - val_loss: 0.1671\n",
      "Epoch 28/30\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1607 - val_loss: 0.1667\n",
      "Epoch 29/30\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1604 - val_loss: 0.1664\n",
      "Epoch 30/30\n",
      "5468/5468 [==============================] - 0s 82us/sample - loss: 0.1602 - val_loss: 0.1663\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32512efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20408), started 1 day, 21:46:05 ago. (Use '!kill 20408' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4e09c148fdc69957\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4e09c148fdc69957\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03b22f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2024_04_23-21_22_54'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34a95525",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a5fda6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5468 samples, validate on 1823 samples\n",
      "Epoch 1/30\n",
      "5468/5468 [==============================] - 1s 202us/sample - loss: 0.1735 - val_loss: 0.1638\n",
      "Epoch 2/30\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1574 - val_loss: 0.1621\n",
      "Epoch 3/30\n",
      "5468/5468 [==============================] - 1s 108us/sample - loss: 0.1565 - val_loss: 0.1572\n",
      "Epoch 4/30\n",
      "5468/5468 [==============================] - 1s 108us/sample - loss: 0.1515 - val_loss: 0.1543\n",
      "Epoch 5/30\n",
      "5468/5468 [==============================] - 1s 106us/sample - loss: 0.1506 - val_loss: 0.1721\n",
      "Epoch 6/30\n",
      "5468/5468 [==============================] - 1s 109us/sample - loss: 0.1489 - val_loss: 0.1515\n",
      "Epoch 7/30\n",
      "5468/5468 [==============================] - 1s 107us/sample - loss: 0.1476 - val_loss: 0.1503\n",
      "Epoch 8/30\n",
      "5468/5468 [==============================] - 1s 119us/sample - loss: 0.1465 - val_loss: 0.1551\n",
      "Epoch 9/30\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1455 - val_loss: 0.1494\n",
      "Epoch 10/30\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1430 - val_loss: 0.1526\n",
      "Epoch 11/30\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.1424 - val_loss: 0.1474\n",
      "Epoch 12/30\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1414 - val_loss: 0.1456\n",
      "Epoch 13/30\n",
      "5468/5468 [==============================] - 0s 88us/sample - loss: 0.1418 - val_loss: 0.1472\n",
      "Epoch 14/30\n",
      "5468/5468 [==============================] - 0s 88us/sample - loss: 0.1402 - val_loss: 0.1452\n",
      "Epoch 15/30\n",
      "5468/5468 [==============================] - 0s 87us/sample - loss: 0.1397 - val_loss: 0.1463\n",
      "Epoch 16/30\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1386 - val_loss: 0.1501\n",
      "Epoch 17/30\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1381 - val_loss: 0.1588\n",
      "Epoch 18/30\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1374 - val_loss: 0.1447\n",
      "Epoch 19/30\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1366 - val_loss: 0.1430\n",
      "Epoch 20/30\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1362 - val_loss: 0.1478\n",
      "Epoch 21/30\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1347 - val_loss: 0.1592\n",
      "Epoch 22/30\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1352 - val_loss: 0.1433\n",
      "Epoch 23/30\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1340 - val_loss: 0.1418\n",
      "Epoch 24/30\n",
      "5468/5468 [==============================] - 1s 102us/sample - loss: 0.1333 - val_loss: 0.1441\n",
      "Epoch 25/30\n",
      "5468/5468 [==============================] - 0s 87us/sample - loss: 0.1322 - val_loss: 0.1443\n",
      "Epoch 26/30\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1309 - val_loss: 0.1400\n",
      "Epoch 27/30\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1312 - val_loss: 0.1388\n",
      "Epoch 28/30\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1293 - val_loss: 0.1358\n",
      "Epoch 29/30\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1292 - val_loss: 0.1377\n",
      "Epoch 30/30\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.1291 - val_loss: 0.1407\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc755c0",
   "metadata": {},
   "source": [
    "## Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "763fb4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8150d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c78e542a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5468 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "5468/5468 [==============================] - 1s 143us/sample - loss: 0.2880 - val_loss: 0.2040\n",
      "Epoch 2/100\n",
      "5468/5468 [==============================] - 0s 71us/sample - loss: 0.1856 - val_loss: 0.1871\n",
      "Epoch 3/100\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1751 - val_loss: 0.1796\n",
      "Epoch 4/100\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1699 - val_loss: 0.1753\n",
      "Epoch 5/100\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1663 - val_loss: 0.1718\n",
      "Epoch 6/100\n",
      "5468/5468 [==============================] - 1s 95us/sample - loss: 0.1638 - val_loss: 0.1693\n",
      "Epoch 7/100\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1622 - val_loss: 0.1670\n",
      "Epoch 8/100\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1609 - val_loss: 0.1656\n",
      "Epoch 9/100\n",
      "5468/5468 [==============================] - 0s 82us/sample - loss: 0.1600 - val_loss: 0.1652\n",
      "Epoch 10/100\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.1590 - val_loss: 0.1644\n",
      "Epoch 11/100\n",
      "5468/5468 [==============================] - 0s 73us/sample - loss: 0.1586 - val_loss: 0.1636\n",
      "Epoch 12/100\n",
      "5468/5468 [==============================] - 0s 67us/sample - loss: 0.1580 - val_loss: 0.1626\n",
      "Epoch 13/100\n",
      "5468/5468 [==============================] - 0s 64us/sample - loss: 0.1578 - val_loss: 0.1623\n",
      "Epoch 14/100\n",
      "5468/5468 [==============================] - 0s 70us/sample - loss: 0.1572 - val_loss: 0.1625\n",
      "Epoch 15/100\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1570 - val_loss: 0.1617\n",
      "Epoch 16/100\n",
      "5468/5468 [==============================] - 0s 67us/sample - loss: 0.1566 - val_loss: 0.1618\n",
      "Epoch 17/100\n",
      "5468/5468 [==============================] - 0s 72us/sample - loss: 0.1564 - val_loss: 0.1610\n",
      "Epoch 18/100\n",
      "5468/5468 [==============================] - 0s 66us/sample - loss: 0.1559 - val_loss: 0.1606\n",
      "Epoch 19/100\n",
      "5468/5468 [==============================] - 0s 67us/sample - loss: 0.1557 - val_loss: 0.1606\n",
      "Epoch 20/100\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1553 - val_loss: 0.1602\n",
      "Epoch 21/100\n",
      "5468/5468 [==============================] - 0s 67us/sample - loss: 0.1552 - val_loss: 0.1604\n",
      "Epoch 22/100\n",
      "5468/5468 [==============================] - 0s 69us/sample - loss: 0.1549 - val_loss: 0.1601\n",
      "Epoch 23/100\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1549 - val_loss: 0.1600\n",
      "Epoch 24/100\n",
      "5468/5468 [==============================] - 0s 67us/sample - loss: 0.1546 - val_loss: 0.1599\n",
      "Epoch 25/100\n",
      "5468/5468 [==============================] - 0s 69us/sample - loss: 0.1543 - val_loss: 0.1597\n",
      "Epoch 26/100\n",
      "5468/5468 [==============================] - 0s 74us/sample - loss: 0.1542 - val_loss: 0.1593\n",
      "Epoch 27/100\n",
      "5468/5468 [==============================] - 0s 66us/sample - loss: 0.1540 - val_loss: 0.1592\n",
      "Epoch 28/100\n",
      "5468/5468 [==============================] - 0s 71us/sample - loss: 0.1539 - val_loss: 0.1591\n",
      "Epoch 29/100\n",
      "5468/5468 [==============================] - 0s 67us/sample - loss: 0.1536 - val_loss: 0.1587\n",
      "Epoch 30/100\n",
      "5468/5468 [==============================] - 0s 66us/sample - loss: 0.1534 - val_loss: 0.1584\n",
      "Epoch 31/100\n",
      "5468/5468 [==============================] - 0s 74us/sample - loss: 0.1533 - val_loss: 0.1583\n",
      "Epoch 32/100\n",
      "5468/5468 [==============================] - 0s 69us/sample - loss: 0.1532 - val_loss: 0.1582\n",
      "Epoch 33/100\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1530 - val_loss: 0.1589\n",
      "Epoch 34/100\n",
      "5468/5468 [==============================] - 0s 79us/sample - loss: 0.1527 - val_loss: 0.1579\n",
      "Epoch 35/100\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1525 - val_loss: 0.1590\n",
      "Epoch 36/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1524 - val_loss: 0.1579\n",
      "Epoch 37/100\n",
      "5468/5468 [==============================] - 1s 97us/sample - loss: 0.1523 - val_loss: 0.1581\n",
      "Epoch 38/100\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1521 - val_loss: 0.1584\n",
      "Epoch 39/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1519 - val_loss: 0.1575\n",
      "Epoch 40/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1519 - val_loss: 0.1582\n",
      "Epoch 41/100\n",
      "5468/5468 [==============================] - 0s 87us/sample - loss: 0.1519 - val_loss: 0.1580\n",
      "Epoch 42/100\n",
      "5468/5468 [==============================] - 1s 107us/sample - loss: 0.1515 - val_loss: 0.1571\n",
      "Epoch 43/100\n",
      "5468/5468 [==============================] - 0s 83us/sample - loss: 0.1515 - val_loss: 0.1579\n",
      "Epoch 44/100\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.1513 - val_loss: 0.1581\n",
      "Epoch 45/100\n",
      "5468/5468 [==============================] - 1s 111us/sample - loss: 0.1513 - val_loss: 0.1591\n",
      "Epoch 46/100\n",
      "5468/5468 [==============================] - 1s 114us/sample - loss: 0.1511 - val_loss: 0.1567\n",
      "Epoch 47/100\n",
      "5468/5468 [==============================] - 1s 112us/sample - loss: 0.1509 - val_loss: 0.1583\n",
      "Epoch 48/100\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1510 - val_loss: 0.1565\n",
      "Epoch 49/100\n",
      "5468/5468 [==============================] - 0s 88us/sample - loss: 0.1508 - val_loss: 0.1570\n",
      "Epoch 50/100\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.1508 - val_loss: 0.1563\n",
      "Epoch 51/100\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.1506 - val_loss: 0.1562\n",
      "Epoch 52/100\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.1505 - val_loss: 0.1565\n",
      "Epoch 53/100\n",
      "5468/5468 [==============================] - 1s 96us/sample - loss: 0.1505 - val_loss: 0.1563\n",
      "Epoch 54/100\n",
      "5468/5468 [==============================] - 0s 72us/sample - loss: 0.1504 - val_loss: 0.1568\n",
      "Epoch 55/100\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1504 - val_loss: 0.1560\n",
      "Epoch 56/100\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1502 - val_loss: 0.1559\n",
      "Epoch 57/100\n",
      "5468/5468 [==============================] - 0s 71us/sample - loss: 0.1502 - val_loss: 0.1562\n",
      "Epoch 58/100\n",
      "5468/5468 [==============================] - 0s 72us/sample - loss: 0.1499 - val_loss: 0.1587\n",
      "Epoch 59/100\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1500 - val_loss: 0.1557\n",
      "Epoch 60/100\n",
      "5468/5468 [==============================] - 0s 87us/sample - loss: 0.1498 - val_loss: 0.1557\n",
      "Epoch 61/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1497 - val_loss: 0.1573\n",
      "Epoch 62/100\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1498 - val_loss: 0.1556\n",
      "Epoch 63/100\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1496 - val_loss: 0.1558\n",
      "Epoch 64/100\n",
      "5468/5468 [==============================] - 0s 69us/sample - loss: 0.1495 - val_loss: 0.1557\n",
      "Epoch 65/100\n",
      "5468/5468 [==============================] - 1s 117us/sample - loss: 0.1496 - val_loss: 0.1555\n",
      "Epoch 66/100\n",
      "5468/5468 [==============================] - 0s 64us/sample - loss: 0.1495 - val_loss: 0.1557\n",
      "Epoch 67/100\n",
      "5468/5468 [==============================] - 0s 76us/sample - loss: 0.1493 - val_loss: 0.1558\n",
      "Epoch 68/100\n",
      "5468/5468 [==============================] - 0s 73us/sample - loss: 0.1493 - val_loss: 0.1559\n",
      "Epoch 69/100\n",
      "5468/5468 [==============================] - 0s 84us/sample - loss: 0.1490 - val_loss: 0.1554\n",
      "Epoch 70/100\n",
      "5468/5468 [==============================] - 0s 79us/sample - loss: 0.1492 - val_loss: 0.1552\n",
      "Epoch 71/100\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.1491 - val_loss: 0.1565\n",
      "Epoch 72/100\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1490 - val_loss: 0.1552\n",
      "Epoch 73/100\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.1490 - val_loss: 0.1549\n",
      "Epoch 74/100\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1488 - val_loss: 0.1549\n",
      "Epoch 75/100\n",
      "5468/5468 [==============================] - 1s 97us/sample - loss: 0.1488 - val_loss: 0.1550\n",
      "Epoch 76/100\n",
      "5468/5468 [==============================] - 0s 82us/sample - loss: 0.1489 - val_loss: 0.1552\n",
      "Epoch 77/100\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1487 - val_loss: 0.1547\n",
      "Epoch 78/100\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1486 - val_loss: 0.1558\n",
      "Epoch 79/100\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1487 - val_loss: 0.1550\n",
      "Epoch 80/100\n",
      "5468/5468 [==============================] - 1s 97us/sample - loss: 0.1485 - val_loss: 0.1549\n",
      "Epoch 81/100\n",
      "5468/5468 [==============================] - 0s 87us/sample - loss: 0.1486 - val_loss: 0.1546\n",
      "Epoch 82/100\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1484 - val_loss: 0.1552\n",
      "Epoch 83/100\n",
      "5468/5468 [==============================] - 0s 74us/sample - loss: 0.1483 - val_loss: 0.1546\n",
      "Epoch 84/100\n",
      "5468/5468 [==============================] - 0s 72us/sample - loss: 0.1481 - val_loss: 0.1546\n",
      "Epoch 85/100\n",
      "5468/5468 [==============================] - 0s 67us/sample - loss: 0.1480 - val_loss: 0.1548\n",
      "Epoch 86/100\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.1481 - val_loss: 0.1549\n",
      "Epoch 87/100\n",
      "5468/5468 [==============================] - 0s 71us/sample - loss: 0.1481 - val_loss: 0.1553\n",
      "Epoch 88/100\n",
      "5468/5468 [==============================] - 0s 70us/sample - loss: 0.1481 - val_loss: 0.1541\n",
      "Epoch 89/100\n",
      "5468/5468 [==============================] - 0s 75us/sample - loss: 0.1478 - val_loss: 0.1542\n",
      "Epoch 90/100\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1479 - val_loss: 0.1541\n",
      "Epoch 91/100\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1479 - val_loss: 0.1544\n",
      "Epoch 92/100\n",
      "5468/5468 [==============================] - 0s 69us/sample - loss: 0.1478 - val_loss: 0.1549\n",
      "Epoch 93/100\n",
      "5468/5468 [==============================] - 0s 73us/sample - loss: 0.1479 - val_loss: 0.1540\n",
      "Epoch 94/100\n",
      "5468/5468 [==============================] - 0s 72us/sample - loss: 0.1478 - val_loss: 0.1540\n",
      "Epoch 95/100\n",
      "5468/5468 [==============================] - 0s 71us/sample - loss: 0.1476 - val_loss: 0.1548\n",
      "Epoch 96/100\n",
      "5468/5468 [==============================] - 0s 67us/sample - loss: 0.1477 - val_loss: 0.1538\n",
      "Epoch 97/100\n",
      "5468/5468 [==============================] - 0s 69us/sample - loss: 0.1476 - val_loss: 0.1544\n",
      "Epoch 98/100\n",
      "5468/5468 [==============================] - 0s 72us/sample - loss: 0.1475 - val_loss: 0.1541\n",
      "Epoch 99/100\n",
      "5468/5468 [==============================] - 0s 68us/sample - loss: 0.1475 - val_loss: 0.1547\n",
      "Epoch 100/100\n",
      "5468/5468 [==============================] - 0s 71us/sample - loss: 0.1474 - val_loss: 0.1537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21dfc14e198>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff01cbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 47us/sample - loss: 0.1518\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "625f97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "337b0641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 201us/sample - loss: 0.2395 - val_loss: 0.1744\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1608 - val_loss: 0.1672\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1563 - val_loss: 0.1650\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1542 - val_loss: 0.1622\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1524 - val_loss: 0.1608\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1515 - val_loss: 0.1597\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1501 - val_loss: 0.1581\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1501 - val_loss: 0.1585\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1483 - val_loss: 0.1578\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1480 - val_loss: 0.1567\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1471 - val_loss: 0.1566\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1470 - val_loss: 0.1562\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1456 - val_loss: 0.1552\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1456 - val_loss: 0.1566\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1454 - val_loss: 0.1572\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1440 - val_loss: 0.1594\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1445 - val_loss: 0.1541\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1445 - val_loss: 0.1548\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1439 - val_loss: 0.1611\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1442 - val_loss: 0.1544\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1429 - val_loss: 0.1549\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1428 - val_loss: 0.1524\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1429 - val_loss: 0.1570\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1423 - val_loss: 0.1558\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1427 - val_loss: 0.1521\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1427 - val_loss: 0.1543\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1417 - val_loss: 0.1551\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1408 - val_loss: 0.1516\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1410 - val_loss: 0.1528\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1414 - val_loss: 0.1567\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1417 - val_loss: 0.1509\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1401 - val_loss: 0.1520\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1403 - val_loss: 0.1505\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1402 - val_loss: 0.1504\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1401 - val_loss: 0.1541\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1402 - val_loss: 0.1493\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1395 - val_loss: 0.1497\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1397 - val_loss: 0.1498\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1391 - val_loss: 0.1499\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1400 - val_loss: 0.1491\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1385 - val_loss: 0.1495\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1382 - val_loss: 0.1492\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1385 - val_loss: 0.1486\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1379 - val_loss: 0.1511\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1383 - val_loss: 0.1506\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1385 - val_loss: 0.1476\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1377 - val_loss: 0.1483\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1375 - val_loss: 0.1482\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1369 - val_loss: 0.1491\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1373 - val_loss: 0.1473\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1367 - val_loss: 0.1481\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1371 - val_loss: 0.1476\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1373 - val_loss: 0.1476\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1368 - val_loss: 0.1478\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1361 - val_loss: 0.1471\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1367 - val_loss: 0.1519\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1365 - val_loss: 0.1488\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1363 - val_loss: 0.1469\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1364 - val_loss: 0.1481\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1356 - val_loss: 0.1479\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1360 - val_loss: 0.1463\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1355 - val_loss: 0.1468\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1363 - val_loss: 0.1458\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1354 - val_loss: 0.1465\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1349 - val_loss: 0.1453\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1354 - val_loss: 0.1446\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1353 - val_loss: 0.1460\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1342 - val_loss: 0.1447\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1344 - val_loss: 0.1454\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1345 - val_loss: 0.1441\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1345 - val_loss: 0.1456\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1348 - val_loss: 0.1447\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1331 - val_loss: 0.1509\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1345 - val_loss: 0.1454\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1340 - val_loss: 0.1443\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1337 - val_loss: 0.1465\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1334 - val_loss: 0.1441\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1334 - val_loss: 0.1434\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1332 - val_loss: 0.1442\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1337 - val_loss: 0.1434\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1325 - val_loss: 0.1449\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1323 - val_loss: 0.1441\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1329 - val_loss: 0.1438\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1332 - val_loss: 0.1431\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1331 - val_loss: 0.1448\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1322 - val_loss: 0.1441\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1321 - val_loss: 0.1436\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1322 - val_loss: 0.1465\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1317 - val_loss: 0.1429\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1310 - val_loss: 0.1436\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1317 - val_loss: 0.1422\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1320 - val_loss: 0.1447\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1314 - val_loss: 0.1428\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1306 - val_loss: 0.1417\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1311 - val_loss: 0.1482\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1305 - val_loss: 0.1439\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1306 - val_loss: 0.1423\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1308 - val_loss: 0.1452\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1303 - val_loss: 0.1471\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1307 - val_loss: 0.1419\n",
      "1823/1823 [==============================] - 0s 32us/sample - loss: 0.1446\n",
      "[CV] END learning_rate=0.013877510826065143, n_hidden=1, n_neurons=71; total time=  30.4s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 219us/sample - loss: 0.1821 - val_loss: 0.1777\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1662 - val_loss: 0.1736\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1615 - val_loss: 0.1667\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1589 - val_loss: 0.1684\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1567 - val_loss: 0.1639\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1548 - val_loss: 0.1652\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1539 - val_loss: 0.1634\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1535 - val_loss: 0.1602\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1523 - val_loss: 0.1607\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1518 - val_loss: 0.1590\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1509 - val_loss: 0.1583\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1503 - val_loss: 0.1620\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1500 - val_loss: 0.1601\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1493 - val_loss: 0.1585\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1488 - val_loss: 0.1566\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1482 - val_loss: 0.1571\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1482 - val_loss: 0.1585\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1473 - val_loss: 0.1559\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1469 - val_loss: 0.1547\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1467 - val_loss: 0.1552\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1456 - val_loss: 0.1551\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1457 - val_loss: 0.1548\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1455 - val_loss: 0.1545\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1451 - val_loss: 0.1540\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1448 - val_loss: 0.1538\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1447 - val_loss: 0.1534\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1442 - val_loss: 0.1531\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1442 - val_loss: 0.1530\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1426 - val_loss: 0.1525\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1428 - val_loss: 0.1559\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1433 - val_loss: 0.1531\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1427 - val_loss: 0.1526\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1422 - val_loss: 0.1522\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1424 - val_loss: 0.1517\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1420 - val_loss: 0.1523\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1415 - val_loss: 0.1530\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1417 - val_loss: 0.1521\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1411 - val_loss: 0.1511\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1407 - val_loss: 0.1509\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1411 - val_loss: 0.1506\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1407 - val_loss: 0.1535\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1406 - val_loss: 0.1509\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1402 - val_loss: 0.1497\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1401 - val_loss: 0.1505\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1398 - val_loss: 0.1495\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1402 - val_loss: 0.1492\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1395 - val_loss: 0.1492\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1395 - val_loss: 0.1488\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1384 - val_loss: 0.1503\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1386 - val_loss: 0.1502\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1384 - val_loss: 0.1483\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1383 - val_loss: 0.1483\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1378 - val_loss: 0.1493\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1374 - val_loss: 0.1539\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1378 - val_loss: 0.1488\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1372 - val_loss: 0.1485\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1372 - val_loss: 0.1497\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1367 - val_loss: 0.1516\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1369 - val_loss: 0.1486\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1368 - val_loss: 0.1476\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1365 - val_loss: 0.1594\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1363 - val_loss: 0.1473\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1359 - val_loss: 0.1520\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1362 - val_loss: 0.1482\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1358 - val_loss: 0.1477\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1359 - val_loss: 0.1470\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1356 - val_loss: 0.1498\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1355 - val_loss: 0.1465\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1346 - val_loss: 0.1462\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1353 - val_loss: 0.1462\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1347 - val_loss: 0.1454\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1344 - val_loss: 0.1458\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1347 - val_loss: 0.1460\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1340 - val_loss: 0.1459\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1343 - val_loss: 0.1455\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1336 - val_loss: 0.1458\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1344 - val_loss: 0.1449\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1340 - val_loss: 0.1452\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1337 - val_loss: 0.1447\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1341 - val_loss: 0.1516\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1335 - val_loss: 0.1443\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1330 - val_loss: 0.1441\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1326 - val_loss: 0.1476\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1326 - val_loss: 0.1439\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1327 - val_loss: 0.1459\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1319 - val_loss: 0.1450\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1321 - val_loss: 0.1448\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1317 - val_loss: 0.1435\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1322 - val_loss: 0.1431\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1319 - val_loss: 0.1430\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1322 - val_loss: 0.1428\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1320 - val_loss: 0.1434\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1316 - val_loss: 0.1441\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1314 - val_loss: 0.1416\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1314 - val_loss: 0.1420\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1313 - val_loss: 0.1423\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1311 - val_loss: 0.1410\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1316 - val_loss: 0.1440\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1307 - val_loss: 0.1425\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1301 - val_loss: 0.1428\n",
      "1823/1823 [==============================] - 0s 28us/sample - loss: 0.1331\n",
      "[CV] END learning_rate=0.013877510826065143, n_hidden=1, n_neurons=71; total time=  30.4s\n",
      "Train on 3646 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3646/3646 [==============================] - 1s 186us/sample - loss: 0.2060 - val_loss: 0.1792\n",
      "Epoch 2/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1689 - val_loss: 0.1681\n",
      "Epoch 3/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1625 - val_loss: 0.1635\n",
      "Epoch 4/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1590 - val_loss: 0.1641\n",
      "Epoch 5/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1572 - val_loss: 0.1629\n",
      "Epoch 6/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1556 - val_loss: 0.1612\n",
      "Epoch 7/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1547 - val_loss: 0.1587\n",
      "Epoch 8/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1536 - val_loss: 0.1596\n",
      "Epoch 9/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1532 - val_loss: 0.1582\n",
      "Epoch 10/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1529 - val_loss: 0.1577\n",
      "Epoch 11/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1526 - val_loss: 0.1573\n",
      "Epoch 12/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1520 - val_loss: 0.1589\n",
      "Epoch 13/100\n",
      "3646/3646 [==============================] - 0s 90us/sample - loss: 0.1517 - val_loss: 0.1579\n",
      "Epoch 14/100\n",
      "3646/3646 [==============================] - ETA: 0s - loss: 0.149 - 0s 78us/sample - loss: 0.1506 - val_loss: 0.1563\n",
      "Epoch 15/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1504 - val_loss: 0.1605\n",
      "Epoch 16/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1504 - val_loss: 0.1581\n",
      "Epoch 17/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1494 - val_loss: 0.1576\n",
      "Epoch 18/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1493 - val_loss: 0.1598\n",
      "Epoch 19/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1497 - val_loss: 0.1559\n",
      "Epoch 20/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1488 - val_loss: 0.1556\n",
      "Epoch 21/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1487 - val_loss: 0.1571\n",
      "Epoch 22/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1482 - val_loss: 0.1562\n",
      "Epoch 23/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1474 - val_loss: 0.1571\n",
      "Epoch 24/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1473 - val_loss: 0.1549\n",
      "Epoch 25/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1472 - val_loss: 0.1556\n",
      "Epoch 26/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1465 - val_loss: 0.1562\n",
      "Epoch 27/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1472 - val_loss: 0.1551\n",
      "Epoch 28/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1467 - val_loss: 0.1549\n",
      "Epoch 29/100\n",
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1457 - val_loss: 0.1566\n",
      "Epoch 30/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1464 - val_loss: 0.1536\n",
      "Epoch 31/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1464 - val_loss: 0.1552\n",
      "Epoch 32/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1454 - val_loss: 0.1545\n",
      "Epoch 33/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1457 - val_loss: 0.1538\n",
      "Epoch 34/100\n",
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1455 - val_loss: 0.1565\n",
      "Epoch 35/100\n",
      "3646/3646 [==============================] - 0s 98us/sample - loss: 0.1448 - val_loss: 0.1551\n",
      "Epoch 36/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1454 - val_loss: 0.1587\n",
      "Epoch 37/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1445 - val_loss: 0.1558\n",
      "Epoch 38/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1444 - val_loss: 0.1525\n",
      "Epoch 39/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1444 - val_loss: 0.1531\n",
      "Epoch 40/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1444 - val_loss: 0.1522\n",
      "Epoch 41/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1442 - val_loss: 0.1530\n",
      "Epoch 42/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1441 - val_loss: 0.1545\n",
      "Epoch 43/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1437 - val_loss: 0.1526\n",
      "Epoch 44/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1438 - val_loss: 0.1516\n",
      "Epoch 45/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1428 - val_loss: 0.1517\n",
      "Epoch 46/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1427 - val_loss: 0.1516\n",
      "Epoch 47/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1429 - val_loss: 0.1522\n",
      "Epoch 48/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1428 - val_loss: 0.1532\n",
      "Epoch 49/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1421 - val_loss: 0.1536\n",
      "Epoch 50/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1424 - val_loss: 0.1513\n",
      "Epoch 51/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1422 - val_loss: 0.1516\n",
      "Epoch 52/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1421 - val_loss: 0.1511\n",
      "Epoch 53/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1414 - val_loss: 0.1515\n",
      "Epoch 54/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1417 - val_loss: 0.1515\n",
      "Epoch 55/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1412 - val_loss: 0.1506\n",
      "Epoch 56/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1407 - val_loss: 0.1520\n",
      "Epoch 57/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1414 - val_loss: 0.1502\n",
      "Epoch 58/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.1408 - val_loss: 0.1535\n",
      "Epoch 59/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1414 - val_loss: 0.1500\n",
      "Epoch 60/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1405 - val_loss: 0.1504\n",
      "Epoch 61/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1403 - val_loss: 0.1518\n",
      "Epoch 62/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1399 - val_loss: 0.1503\n",
      "Epoch 63/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1402 - val_loss: 0.1506\n",
      "Epoch 64/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1408 - val_loss: 0.1496\n",
      "Epoch 65/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1393 - val_loss: 0.1536\n",
      "Epoch 66/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1400 - val_loss: 0.1523\n",
      "Epoch 67/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1404 - val_loss: 0.1502\n",
      "Epoch 68/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1390 - val_loss: 0.1517\n",
      "Epoch 69/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1393 - val_loss: 0.1496\n",
      "Epoch 70/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1390 - val_loss: 0.1500\n",
      "Epoch 71/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1387 - val_loss: 0.1497\n",
      "Epoch 72/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1383 - val_loss: 0.1505\n",
      "Epoch 73/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1383 - val_loss: 0.1507\n",
      "Epoch 74/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1384 - val_loss: 0.1504\n",
      "Epoch 75/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1379 - val_loss: 0.1490\n",
      "Epoch 76/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1380 - val_loss: 0.1484\n",
      "Epoch 77/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1374 - val_loss: 0.1521\n",
      "Epoch 78/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1372 - val_loss: 0.1515\n",
      "Epoch 79/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1372 - val_loss: 0.1495\n",
      "Epoch 80/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1371 - val_loss: 0.1482\n",
      "Epoch 81/100\n",
      "3646/3646 [==============================] - 0s 98us/sample - loss: 0.1373 - val_loss: 0.1481\n",
      "Epoch 82/100\n",
      "3646/3646 [==============================] - 0s 93us/sample - loss: 0.1368 - val_loss: 0.1475\n",
      "Epoch 83/100\n",
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1360 - val_loss: 0.1478\n",
      "Epoch 84/100\n",
      "3646/3646 [==============================] - 0s 97us/sample - loss: 0.1364 - val_loss: 0.1479\n",
      "Epoch 85/100\n",
      "3646/3646 [==============================] - 0s 103us/sample - loss: 0.1362 - val_loss: 0.1466\n",
      "Epoch 86/100\n",
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1357 - val_loss: 0.1480\n",
      "Epoch 87/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1356 - val_loss: 0.1478\n",
      "Epoch 88/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1354 - val_loss: 0.1515\n",
      "Epoch 89/100\n",
      "3646/3646 [==============================] - 0s 99us/sample - loss: 0.1354 - val_loss: 0.1468\n",
      "Epoch 90/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1361 - val_loss: 0.1469\n",
      "Epoch 91/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1351 - val_loss: 0.1470\n",
      "Epoch 92/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1351 - val_loss: 0.1471\n",
      "Epoch 93/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1347 - val_loss: 0.1465\n",
      "Epoch 94/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1343 - val_loss: 0.1470\n",
      "Epoch 95/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1341 - val_loss: 0.1465\n",
      "Epoch 96/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1342 - val_loss: 0.1452\n",
      "Epoch 97/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1332 - val_loss: 0.1454\n",
      "Epoch 98/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1343 - val_loss: 0.1464\n",
      "Epoch 99/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1339 - val_loss: 0.1442\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1335 - val_loss: 0.1467\n",
      "1822/1822 [==============================] - 0s 35us/sample - loss: 0.1361\n",
      "[CV] END learning_rate=0.013877510826065143, n_hidden=1, n_neurons=71; total time=  30.8s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 245us/sample - loss: 0.3999 - val_loss: 0.3209\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.2878 - val_loss: 0.2584\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.2368 - val_loss: 0.2269\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.2101 - val_loss: 0.2102\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1952 - val_loss: 0.1999\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1862 - val_loss: 0.1938\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1803 - val_loss: 0.1896\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1764 - val_loss: 0.1867\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1734 - val_loss: 0.1851\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1713 - val_loss: 0.1827\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1695 - val_loss: 0.1813\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1682 - val_loss: 0.1801\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1669 - val_loss: 0.1790\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1659 - val_loss: 0.1779\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1649 - val_loss: 0.1768\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1642 - val_loss: 0.1761\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1634 - val_loss: 0.1753\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1627 - val_loss: 0.1746\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1621 - val_loss: 0.1741\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1614 - val_loss: 0.1741\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1610 - val_loss: 0.1729\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1605 - val_loss: 0.1724\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1600 - val_loss: 0.1722\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1595 - val_loss: 0.1720\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1592 - val_loss: 0.1712\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1588 - val_loss: 0.1706\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1584 - val_loss: 0.1702\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1581 - val_loss: 0.1702\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1577 - val_loss: 0.1695\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1575 - val_loss: 0.1693\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1571 - val_loss: 0.1691\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1569 - val_loss: 0.1688\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1565 - val_loss: 0.1685\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1563 - val_loss: 0.1684\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1561 - val_loss: 0.1679\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1558 - val_loss: 0.1678\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 1s 151us/sample - loss: 0.1556 - val_loss: 0.1674\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1554 - val_loss: 0.1672\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1552 - val_loss: 0.1670\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1550 - val_loss: 0.1668\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1547 - val_loss: 0.1670\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1546 - val_loss: 0.1667\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1544 - val_loss: 0.1664\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1542 - val_loss: 0.1661\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1541 - val_loss: 0.1661\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1539 - val_loss: 0.1659\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1535 - val_loss: 0.1663\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1536 - val_loss: 0.1656\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1534 - val_loss: 0.1653\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1533 - val_loss: 0.1654\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1531 - val_loss: 0.1650\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1529 - val_loss: 0.1651\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1528 - val_loss: 0.1648\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1526 - val_loss: 0.1647\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1525 - val_loss: 0.1646\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1523 - val_loss: 0.1644\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1522 - val_loss: 0.1643\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1521 - val_loss: 0.1643\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1519 - val_loss: 0.1641\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1518 - val_loss: 0.1641\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1516 - val_loss: 0.1638\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1516 - val_loss: 0.1636\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1514 - val_loss: 0.1635\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1513 - val_loss: 0.1636\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1512 - val_loss: 0.1636\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1511 - val_loss: 0.1635\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1509 - val_loss: 0.1632\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1508 - val_loss: 0.1635\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1507 - val_loss: 0.1630\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1507 - val_loss: 0.1630\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1505 - val_loss: 0.1631\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1504 - val_loss: 0.1628\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1503 - val_loss: 0.1628\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1502 - val_loss: 0.1626\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1501 - val_loss: 0.1625\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1501 - val_loss: 0.1626\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1500 - val_loss: 0.1627\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1499 - val_loss: 0.1623\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1498 - val_loss: 0.1625\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1497 - val_loss: 0.1624\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1496 - val_loss: 0.1624\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 118us/sample - loss: 0.1496 - val_loss: 0.1621\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 112us/sample - loss: 0.1495 - val_loss: 0.1620\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1494 - val_loss: 0.1620\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1493 - val_loss: 0.1619\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1493 - val_loss: 0.1620\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1491 - val_loss: 0.1618\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1490 - val_loss: 0.1621\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1490 - val_loss: 0.1617\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1489 - val_loss: 0.1617\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1488 - val_loss: 0.1617\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1488 - val_loss: 0.1616\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1488 - val_loss: 0.1615\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1487 - val_loss: 0.1615\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1486 - val_loss: 0.1616\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1486 - val_loss: 0.1615\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1485 - val_loss: 0.1614\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1484 - val_loss: 0.1614\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1484 - val_loss: 0.1613\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1483 - val_loss: 0.1611\n",
      "1823/1823 [==============================] - 0s 36us/sample - loss: 0.1603\n",
      "[CV] END learning_rate=0.0011285740259814796, n_hidden=1, n_neurons=64; total time=  31.0s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 191us/sample - loss: 0.4109 - val_loss: 0.2968\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.2453 - val_loss: 0.2215\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.2007 - val_loss: 0.1981\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1859 - val_loss: 0.1894\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1797 - val_loss: 0.1849\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1763 - val_loss: 0.1823\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1740 - val_loss: 0.1800\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1722 - val_loss: 0.1783\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1708 - val_loss: 0.1768\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1695 - val_loss: 0.1755\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1683 - val_loss: 0.1744\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1673 - val_loss: 0.1731\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1665 - val_loss: 0.1721\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1657 - val_loss: 0.1714\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1648 - val_loss: 0.1708\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1642 - val_loss: 0.1698\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1636 - val_loss: 0.1692\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1630 - val_loss: 0.1686\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1624 - val_loss: 0.1679\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1620 - val_loss: 0.1675\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1615 - val_loss: 0.1669\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1611 - val_loss: 0.1664\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1607 - val_loss: 0.1660\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1603 - val_loss: 0.1657\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1600 - val_loss: 0.1653\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1597 - val_loss: 0.1651\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1592 - val_loss: 0.1646\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1590 - val_loss: 0.1645\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1587 - val_loss: 0.1641\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1584 - val_loss: 0.1639\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1581 - val_loss: 0.1636\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1579 - val_loss: 0.1634\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1577 - val_loss: 0.1632\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1574 - val_loss: 0.1630\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1573 - val_loss: 0.1629\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1571 - val_loss: 0.1626\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1568 - val_loss: 0.1624\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1567 - val_loss: 0.1624\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1565 - val_loss: 0.1626\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1561 - val_loss: 0.1620\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1562 - val_loss: 0.1619\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1560 - val_loss: 0.1618\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1557 - val_loss: 0.1616\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1557 - val_loss: 0.1615\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1555 - val_loss: 0.1614\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1553 - val_loss: 0.1612\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1552 - val_loss: 0.1614\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1551 - val_loss: 0.1611\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1547 - val_loss: 0.1619\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1550 - val_loss: 0.1611\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1547 - val_loss: 0.1608\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1547 - val_loss: 0.1607\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1545 - val_loss: 0.1607\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1544 - val_loss: 0.1608\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1543 - val_loss: 0.1606\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1542 - val_loss: 0.1604\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1541 - val_loss: 0.1603\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - ETA: 0s - loss: 0.154 - 0s 96us/sample - loss: 0.1540 - val_loss: 0.1603\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1539 - val_loss: 0.1606\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1539 - val_loss: 0.1604\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1538 - val_loss: 0.1602\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1537 - val_loss: 0.1601\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1536 - val_loss: 0.1601\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1534 - val_loss: 0.1601\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1533 - val_loss: 0.1598\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1533 - val_loss: 0.1597\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1532 - val_loss: 0.1597\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1531 - val_loss: 0.1599\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1531 - val_loss: 0.1597\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1530 - val_loss: 0.1595\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1527 - val_loss: 0.1602\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1529 - val_loss: 0.1595\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1528 - val_loss: 0.1594\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1526 - val_loss: 0.1593\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1527 - val_loss: 0.1592\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1526 - val_loss: 0.1594\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1525 - val_loss: 0.1592\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1525 - val_loss: 0.1592\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1523 - val_loss: 0.1590\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1523 - val_loss: 0.1590\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1522 - val_loss: 0.1592\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1522 - val_loss: 0.1589\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1521 - val_loss: 0.1590\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1520 - val_loss: 0.1591\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1520 - val_loss: 0.1588\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1520 - val_loss: 0.1587\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1518 - val_loss: 0.1590\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1518 - val_loss: 0.1587\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1518 - val_loss: 0.1586\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1517 - val_loss: 0.1587\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1516 - val_loss: 0.1585\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1515 - val_loss: 0.1586\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1516 - val_loss: 0.1586\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1513 - val_loss: 0.1584\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1514 - val_loss: 0.1586\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1513 - val_loss: 0.1584\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1511 - val_loss: 0.1583\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1512 - val_loss: 0.1582\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1511 - val_loss: 0.1581\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1511 - val_loss: 0.1583\n",
      "1823/1823 [==============================] - 0s 29us/sample - loss: 0.1518\n",
      "[CV] END learning_rate=0.0011285740259814796, n_hidden=1, n_neurons=64; total time=  30.7s\n",
      "Train on 3646 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3646/3646 [==============================] - 1s 190us/sample - loss: 0.3576 - val_loss: 0.2681\n",
      "Epoch 2/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.2354 - val_loss: 0.2414\n",
      "Epoch 3/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.2160 - val_loss: 0.2253\n",
      "Epoch 4/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.2042 - val_loss: 0.2153\n",
      "Epoch 5/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1967 - val_loss: 0.2077\n",
      "Epoch 6/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1912 - val_loss: 0.2024\n",
      "Epoch 7/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1872 - val_loss: 0.1980\n",
      "Epoch 8/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1839 - val_loss: 0.1943\n",
      "Epoch 9/100\n",
      "3646/3646 [==============================] - 0s 73us/sample - loss: 0.1812 - val_loss: 0.1916\n",
      "Epoch 10/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1789 - val_loss: 0.1893\n",
      "Epoch 11/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1770 - val_loss: 0.1867\n",
      "Epoch 12/100\n",
      "3646/3646 [==============================] - 0s 73us/sample - loss: 0.1752 - val_loss: 0.1844\n",
      "Epoch 13/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1737 - val_loss: 0.1828\n",
      "Epoch 14/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1723 - val_loss: 0.1813\n",
      "Epoch 15/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1711 - val_loss: 0.1797\n",
      "Epoch 16/100\n",
      "3646/3646 [==============================] - 0s 72us/sample - loss: 0.1698 - val_loss: 0.1782\n",
      "Epoch 17/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1691 - val_loss: 0.1773\n",
      "Epoch 18/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1681 - val_loss: 0.1763\n",
      "Epoch 19/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1673 - val_loss: 0.1755\n",
      "Epoch 20/100\n",
      "3646/3646 [==============================] - 0s 73us/sample - loss: 0.1666 - val_loss: 0.1751\n",
      "Epoch 21/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1660 - val_loss: 0.1737\n",
      "Epoch 22/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1653 - val_loss: 0.1729\n",
      "Epoch 23/100\n",
      "3646/3646 [==============================] - 0s 72us/sample - loss: 0.1648 - val_loss: 0.1727\n",
      "Epoch 24/100\n",
      "3646/3646 [==============================] - 0s 72us/sample - loss: 0.1644 - val_loss: 0.1722\n",
      "Epoch 25/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1638 - val_loss: 0.1713\n",
      "Epoch 26/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1634 - val_loss: 0.1710\n",
      "Epoch 27/100\n",
      "3646/3646 [==============================] - 0s 72us/sample - loss: 0.1630 - val_loss: 0.1704\n",
      "Epoch 28/100\n",
      "3646/3646 [==============================] - 0s 73us/sample - loss: 0.1625 - val_loss: 0.1705\n",
      "Epoch 29/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1621 - val_loss: 0.1702\n",
      "Epoch 30/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1618 - val_loss: 0.1690\n",
      "Epoch 31/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1614 - val_loss: 0.1688\n",
      "Epoch 32/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1611 - val_loss: 0.1685\n",
      "Epoch 33/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1608 - val_loss: 0.1685\n",
      "Epoch 34/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1606 - val_loss: 0.1680\n",
      "Epoch 35/100\n",
      "3646/3646 [==============================] - 0s 73us/sample - loss: 0.1603 - val_loss: 0.1677\n",
      "Epoch 36/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1600 - val_loss: 0.1673\n",
      "Epoch 37/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1598 - val_loss: 0.1674\n",
      "Epoch 38/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1596 - val_loss: 0.1670\n",
      "Epoch 39/100\n",
      "3646/3646 [==============================] - 0s 90us/sample - loss: 0.1593 - val_loss: 0.1670\n",
      "Epoch 40/100\n",
      "3646/3646 [==============================] - 0s 90us/sample - loss: 0.1591 - val_loss: 0.1666\n",
      "Epoch 41/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.1589 - val_loss: 0.1663\n",
      "Epoch 42/100\n",
      "3646/3646 [==============================] - 0s 93us/sample - loss: 0.1587 - val_loss: 0.1660\n",
      "Epoch 43/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1586 - val_loss: 0.1660\n",
      "Epoch 44/100\n",
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1584 - val_loss: 0.1658\n",
      "Epoch 45/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1582 - val_loss: 0.1657\n",
      "Epoch 46/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1580 - val_loss: 0.1658\n",
      "Epoch 47/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1579 - val_loss: 0.1656\n",
      "Epoch 48/100\n",
      "3646/3646 [==============================] - 0s 117us/sample - loss: 0.1577 - val_loss: 0.1652\n",
      "Epoch 49/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1575 - val_loss: 0.1652\n",
      "Epoch 50/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1574 - val_loss: 0.1651\n",
      "Epoch 51/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1572 - val_loss: 0.1650\n",
      "Epoch 52/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1571 - val_loss: 0.1649\n",
      "Epoch 53/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1570 - val_loss: 0.1648\n",
      "Epoch 54/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1568 - val_loss: 0.1648\n",
      "Epoch 55/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1567 - val_loss: 0.1651\n",
      "Epoch 56/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1566 - val_loss: 0.1649\n",
      "Epoch 57/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1565 - val_loss: 0.1643\n",
      "Epoch 58/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1564 - val_loss: 0.1642\n",
      "Epoch 59/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1563 - val_loss: 0.1642\n",
      "Epoch 60/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1562 - val_loss: 0.1640\n",
      "Epoch 61/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1560 - val_loss: 0.1641\n",
      "Epoch 62/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1558 - val_loss: 0.1640\n",
      "Epoch 63/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1557 - val_loss: 0.1637\n",
      "Epoch 64/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1557 - val_loss: 0.1636\n",
      "Epoch 65/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1555 - val_loss: 0.1634\n",
      "Epoch 66/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1555 - val_loss: 0.1636\n",
      "Epoch 67/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1554 - val_loss: 0.1634\n",
      "Epoch 68/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1553 - val_loss: 0.1637\n",
      "Epoch 69/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1552 - val_loss: 0.1635\n",
      "Epoch 70/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1551 - val_loss: 0.1634\n",
      "Epoch 71/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1550 - val_loss: 0.1632\n",
      "Epoch 72/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1549 - val_loss: 0.1633\n",
      "Epoch 73/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1548 - val_loss: 0.1630\n",
      "Epoch 74/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1547 - val_loss: 0.1628\n",
      "Epoch 75/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1547 - val_loss: 0.1630\n",
      "Epoch 76/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1546 - val_loss: 0.1632\n",
      "Epoch 77/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1545 - val_loss: 0.1628\n",
      "Epoch 78/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1544 - val_loss: 0.1626\n",
      "Epoch 79/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1543 - val_loss: 0.1627\n",
      "Epoch 80/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1542 - val_loss: 0.1628\n",
      "Epoch 81/100\n",
      "3646/3646 [==============================] - 0s 71us/sample - loss: 0.1542 - val_loss: 0.1627\n",
      "Epoch 82/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1541 - val_loss: 0.1629\n",
      "Epoch 83/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1541 - val_loss: 0.1625\n",
      "Epoch 84/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1539 - val_loss: 0.1622\n",
      "Epoch 85/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1539 - val_loss: 0.1623\n",
      "Epoch 86/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1538 - val_loss: 0.1625\n",
      "Epoch 87/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1537 - val_loss: 0.1621\n",
      "Epoch 88/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1537 - val_loss: 0.1622\n",
      "Epoch 89/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1536 - val_loss: 0.1625\n",
      "Epoch 90/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1535 - val_loss: 0.1622\n",
      "Epoch 91/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1533 - val_loss: 0.1621\n",
      "Epoch 92/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1534 - val_loss: 0.1619\n",
      "Epoch 93/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1533 - val_loss: 0.1621\n",
      "Epoch 94/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.1533 - val_loss: 0.1619\n",
      "Epoch 95/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1532 - val_loss: 0.1623\n",
      "Epoch 96/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1532 - val_loss: 0.1619\n",
      "Epoch 97/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1531 - val_loss: 0.1618\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1530 - val_loss: 0.1623\n",
      "Epoch 99/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.1530 - val_loss: 0.1617\n",
      "Epoch 100/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1529 - val_loss: 0.1615\n",
      "1822/1822 [==============================] - 0s 49us/sample - loss: 0.1503\n",
      "[CV] END learning_rate=0.0011285740259814796, n_hidden=1, n_neurons=64; total time=  30.2s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 252us/sample - loss: 0.2495 - val_loss: 0.2039\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1823 - val_loss: 0.1804\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1669 - val_loss: 0.1715\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1604 - val_loss: 0.1678\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1575 - val_loss: 0.1660\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1559 - val_loss: 0.1644\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1548 - val_loss: 0.1636\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1540 - val_loss: 0.1658\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1533 - val_loss: 0.1627\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1526 - val_loss: 0.1627\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1517 - val_loss: 0.1620\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1517 - val_loss: 0.1611\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1513 - val_loss: 0.1607\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1507 - val_loss: 0.1604\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1505 - val_loss: 0.1605\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1499 - val_loss: 0.1599\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1497 - val_loss: 0.1596\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1493 - val_loss: 0.1599\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1489 - val_loss: 0.1598\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1487 - val_loss: 0.1589\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1485 - val_loss: 0.1590\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1480 - val_loss: 0.1583\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1477 - val_loss: 0.1581\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1475 - val_loss: 0.1580\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1473 - val_loss: 0.1583\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1470 - val_loss: 0.1575\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1470 - val_loss: 0.1574\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1466 - val_loss: 0.1574\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1463 - val_loss: 0.1583\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1462 - val_loss: 0.1570\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1454 - val_loss: 0.1573\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1457 - val_loss: 0.1566\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1454 - val_loss: 0.1564\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1455 - val_loss: 0.1569\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1451 - val_loss: 0.1566\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1449 - val_loss: 0.1558\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1447 - val_loss: 0.1558\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1445 - val_loss: 0.1555\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1442 - val_loss: 0.1554\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1442 - val_loss: 0.1567\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1441 - val_loss: 0.1553\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1437 - val_loss: 0.1550\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1436 - val_loss: 0.1550\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1433 - val_loss: 0.1554\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1434 - val_loss: 0.1545\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 129us/sample - loss: 0.1430 - val_loss: 0.1569\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1428 - val_loss: 0.1543\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1427 - val_loss: 0.1542\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1427 - val_loss: 0.1551\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1425 - val_loss: 0.1540\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1421 - val_loss: 0.1540\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - ETA: 0s - loss: 0.142 - 0s 91us/sample - loss: 0.1422 - val_loss: 0.1538\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1418 - val_loss: 0.1538\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1419 - val_loss: 0.1536\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1418 - val_loss: 0.1550\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1416 - val_loss: 0.1545\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1416 - val_loss: 0.1535\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1412 - val_loss: 0.1536\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1413 - val_loss: 0.1537\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1409 - val_loss: 0.1535\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1408 - val_loss: 0.1541\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1409 - val_loss: 0.1530\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1407 - val_loss: 0.1529\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1405 - val_loss: 0.1548\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1404 - val_loss: 0.1528\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1403 - val_loss: 0.1531\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1399 - val_loss: 0.1535\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1399 - val_loss: 0.1526\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1399 - val_loss: 0.1530\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1398 - val_loss: 0.1524\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1398 - val_loss: 0.1525\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1397 - val_loss: 0.1523\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1396 - val_loss: 0.1522\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1393 - val_loss: 0.1521\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1391 - val_loss: 0.1519\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1389 - val_loss: 0.1524\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1389 - val_loss: 0.1527\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1390 - val_loss: 0.1528\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1387 - val_loss: 0.1516\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1386 - val_loss: 0.1528\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1386 - val_loss: 0.1516\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1384 - val_loss: 0.1514\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1381 - val_loss: 0.1522\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1382 - val_loss: 0.1514\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1379 - val_loss: 0.1514\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1379 - val_loss: 0.1511\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1377 - val_loss: 0.1530\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1376 - val_loss: 0.1510\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1376 - val_loss: 0.1519\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1376 - val_loss: 0.1515\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1374 - val_loss: 0.1518\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1372 - val_loss: 0.1508\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1369 - val_loss: 0.1530\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1372 - val_loss: 0.1508\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1366 - val_loss: 0.1511\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1369 - val_loss: 0.1504\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1366 - val_loss: 0.1502\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1366 - val_loss: 0.1513\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1364 - val_loss: 0.1502\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1363 - val_loss: 0.1501\n",
      "1823/1823 [==============================] - 0s 41us/sample - loss: 0.1502\n",
      "[CV] END learning_rate=0.003503069654796154, n_hidden=3, n_neurons=57; total time=  34.8s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 231us/sample - loss: 0.2657 - val_loss: 0.2101\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1898 - val_loss: 0.1915\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1776 - val_loss: 0.1824\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1717 - val_loss: 0.1773\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1679 - val_loss: 0.1737\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1651 - val_loss: 0.1713\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1633 - val_loss: 0.1699\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1615 - val_loss: 0.1680\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1603 - val_loss: 0.1670\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1589 - val_loss: 0.1657\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1579 - val_loss: 0.1647\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1569 - val_loss: 0.1655\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1561 - val_loss: 0.1638\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1554 - val_loss: 0.1626\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1549 - val_loss: 0.1624\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1541 - val_loss: 0.1616\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1532 - val_loss: 0.1648\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1530 - val_loss: 0.1606\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1524 - val_loss: 0.1608\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1518 - val_loss: 0.1598\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1516 - val_loss: 0.1600\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1508 - val_loss: 0.1592\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1505 - val_loss: 0.1590\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1501 - val_loss: 0.1587\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1497 - val_loss: 0.1588\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1494 - val_loss: 0.1583\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1492 - val_loss: 0.1581\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1490 - val_loss: 0.1580\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1485 - val_loss: 0.1576\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 131us/sample - loss: 0.1485 - val_loss: 0.1573\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 135us/sample - loss: 0.1480 - val_loss: 0.1572\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 133us/sample - loss: 0.1477 - val_loss: 0.1576\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 1s 142us/sample - loss: 0.1474 - val_loss: 0.1577\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.1473 - val_loss: 0.1566\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 119us/sample - loss: 0.1470 - val_loss: 0.1565\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 126us/sample - loss: 0.1465 - val_loss: 0.1564\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1464 - val_loss: 0.1572\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1459 - val_loss: 0.1560\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1458 - val_loss: 0.1560\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1456 - val_loss: 0.1561\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1452 - val_loss: 0.1578\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1452 - val_loss: 0.1559\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1446 - val_loss: 0.1550\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1446 - val_loss: 0.1559\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1443 - val_loss: 0.1564\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1442 - val_loss: 0.1552\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1438 - val_loss: 0.1547\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1436 - val_loss: 0.1552\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1435 - val_loss: 0.1540\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1430 - val_loss: 0.1563\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1431 - val_loss: 0.1536\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1431 - val_loss: 0.1542\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1427 - val_loss: 0.1534\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1423 - val_loss: 0.1534\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 112us/sample - loss: 0.1424 - val_loss: 0.1532\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.1419 - val_loss: 0.1539\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1418 - val_loss: 0.1529\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1416 - val_loss: 0.1537\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1414 - val_loss: 0.1530\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1412 - val_loss: 0.1540\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1412 - val_loss: 0.1525\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1410 - val_loss: 0.1532\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1405 - val_loss: 0.1520\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1402 - val_loss: 0.1543\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1403 - val_loss: 0.1524\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1398 - val_loss: 0.1518\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 116us/sample - loss: 0.1400 - val_loss: 0.1514\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1397 - val_loss: 0.1519\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1397 - val_loss: 0.1524\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1396 - val_loss: 0.1512\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1392 - val_loss: 0.1521\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1392 - val_loss: 0.1513\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 124us/sample - loss: 0.1387 - val_loss: 0.1528\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1387 - val_loss: 0.1513\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1384 - val_loss: 0.1504\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1382 - val_loss: 0.1503\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1382 - val_loss: 0.1501\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 1s 155us/sample - loss: 0.1377 - val_loss: 0.1518\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 117us/sample - loss: 0.1379 - val_loss: 0.1505\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 1s 252us/sample - loss: 0.1374 - val_loss: 0.1497\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 136us/sample - loss: 0.1375 - val_loss: 0.1498\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 118us/sample - loss: 0.1375 - val_loss: 0.1502\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 1s 152us/sample - loss: 0.1372 - val_loss: 0.1494\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1367 - val_loss: 0.1514\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1370 - val_loss: 0.1500\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1367 - val_loss: 0.1488\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1366 - val_loss: 0.1489\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1364 - val_loss: 0.1488\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 1s 190us/sample - loss: 0.1363 - val_loss: 0.1485\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 1s 183us/sample - loss: 0.1363 - val_loss: 0.1492\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1360 - val_loss: 0.1514\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1361 - val_loss: 0.1484\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1357 - val_loss: 0.1482\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1353 - val_loss: 0.1489\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 130us/sample - loss: 0.1354 - val_loss: 0.1487\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1352 - val_loss: 0.1484\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1353 - val_loss: 0.1476\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1350 - val_loss: 0.1476\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1349 - val_loss: 0.1482\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1345 - val_loss: 0.1484\n",
      "1823/1823 [==============================] - 0s 45us/sample - loss: 0.1387\n",
      "[CV] END learning_rate=0.003503069654796154, n_hidden=3, n_neurons=57; total time=  38.4s\n",
      "Train on 3646 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3646/3646 [==============================] - 1s 337us/sample - loss: 0.2546 - val_loss: 0.2233\n",
      "Epoch 2/100\n",
      "3646/3646 [==============================] - 0s 124us/sample - loss: 0.2034 - val_loss: 0.1955\n",
      "Epoch 3/100\n",
      "3646/3646 [==============================] - 0s 127us/sample - loss: 0.1843 - val_loss: 0.1841\n",
      "Epoch 4/100\n",
      "3646/3646 [==============================] - 0s 130us/sample - loss: 0.1746 - val_loss: 0.1749\n",
      "Epoch 5/100\n",
      "3646/3646 [==============================] - 1s 147us/sample - loss: 0.1692 - val_loss: 0.1716\n",
      "Epoch 6/100\n",
      "3646/3646 [==============================] - 0s 119us/sample - loss: 0.1661 - val_loss: 0.1682\n",
      "Epoch 7/100\n",
      "3646/3646 [==============================] - 1s 143us/sample - loss: 0.1637 - val_loss: 0.1662\n",
      "Epoch 8/100\n",
      "3646/3646 [==============================] - 0s 121us/sample - loss: 0.1621 - val_loss: 0.1646\n",
      "Epoch 9/100\n",
      "3646/3646 [==============================] - 0s 128us/sample - loss: 0.1609 - val_loss: 0.1634\n",
      "Epoch 10/100\n",
      "3646/3646 [==============================] - 0s 98us/sample - loss: 0.1600 - val_loss: 0.1625\n",
      "Epoch 11/100\n",
      "3646/3646 [==============================] - 0s 118us/sample - loss: 0.1591 - val_loss: 0.1619\n",
      "Epoch 12/100\n",
      "3646/3646 [==============================] - 0s 131us/sample - loss: 0.1581 - val_loss: 0.1619\n",
      "Epoch 13/100\n",
      "3646/3646 [==============================] - 0s 118us/sample - loss: 0.1576 - val_loss: 0.1614\n",
      "Epoch 14/100\n",
      "3646/3646 [==============================] - 1s 146us/sample - loss: 0.1570 - val_loss: 0.1607\n",
      "Epoch 15/100\n",
      "3646/3646 [==============================] - 0s 110us/sample - loss: 0.1564 - val_loss: 0.1600\n",
      "Epoch 16/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1559 - val_loss: 0.1594\n",
      "Epoch 17/100\n",
      "3646/3646 [==============================] - 0s 97us/sample - loss: 0.1554 - val_loss: 0.1595\n",
      "Epoch 18/100\n",
      "3646/3646 [==============================] - 0s 99us/sample - loss: 0.1548 - val_loss: 0.1591\n",
      "Epoch 19/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1545 - val_loss: 0.1585\n",
      "Epoch 20/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.1541 - val_loss: 0.1582\n",
      "Epoch 21/100\n",
      "3646/3646 [==============================] - 0s 93us/sample - loss: 0.1539 - val_loss: 0.1576\n",
      "Epoch 22/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1534 - val_loss: 0.1574\n",
      "Epoch 23/100\n",
      "3646/3646 [==============================] - 0s 104us/sample - loss: 0.1529 - val_loss: 0.1570\n",
      "Epoch 24/100\n",
      "3646/3646 [==============================] - 0s 120us/sample - loss: 0.1528 - val_loss: 0.1569\n",
      "Epoch 25/100\n",
      "3646/3646 [==============================] - 0s 109us/sample - loss: 0.1525 - val_loss: 0.1570\n",
      "Epoch 26/100\n",
      "3646/3646 [==============================] - 0s 104us/sample - loss: 0.1520 - val_loss: 0.1567\n",
      "Epoch 27/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1519 - val_loss: 0.1563\n",
      "Epoch 28/100\n",
      "3646/3646 [==============================] - 0s 113us/sample - loss: 0.1516 - val_loss: 0.1566\n",
      "Epoch 29/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1510 - val_loss: 0.1568\n",
      "Epoch 30/100\n",
      "3646/3646 [==============================] - 0s 90us/sample - loss: 0.1511 - val_loss: 0.1558\n",
      "Epoch 31/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1508 - val_loss: 0.1554\n",
      "Epoch 32/100\n",
      "3646/3646 [==============================] - 0s 99us/sample - loss: 0.1503 - val_loss: 0.1566\n",
      "Epoch 33/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.1505 - val_loss: 0.1551\n",
      "Epoch 34/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1497 - val_loss: 0.1549\n",
      "Epoch 35/100\n",
      "3646/3646 [==============================] - 0s 119us/sample - loss: 0.1497 - val_loss: 0.1547\n",
      "Epoch 36/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1497 - val_loss: 0.1547\n",
      "Epoch 37/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.1496 - val_loss: 0.1548\n",
      "Epoch 38/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1494 - val_loss: 0.1544\n",
      "Epoch 39/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1489 - val_loss: 0.1543\n",
      "Epoch 40/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1489 - val_loss: 0.1543\n",
      "Epoch 41/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1485 - val_loss: 0.1541\n",
      "Epoch 42/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1485 - val_loss: 0.1545\n",
      "Epoch 43/100\n",
      "3646/3646 [==============================] - 0s 104us/sample - loss: 0.1482 - val_loss: 0.1540\n",
      "Epoch 44/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1481 - val_loss: 0.1543\n",
      "Epoch 45/100\n",
      "3646/3646 [==============================] - 0s 101us/sample - loss: 0.1480 - val_loss: 0.1533\n",
      "Epoch 46/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1476 - val_loss: 0.1531\n",
      "Epoch 47/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1474 - val_loss: 0.1536\n",
      "Epoch 48/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1473 - val_loss: 0.1529\n",
      "Epoch 49/100\n",
      "3646/3646 [==============================] - 0s 99us/sample - loss: 0.1469 - val_loss: 0.1526\n",
      "Epoch 50/100\n",
      "3646/3646 [==============================] - 0s 99us/sample - loss: 0.1469 - val_loss: 0.1528\n",
      "Epoch 51/100\n",
      "3646/3646 [==============================] - 0s 107us/sample - loss: 0.1466 - val_loss: 0.1529\n",
      "Epoch 52/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1466 - val_loss: 0.1528\n",
      "Epoch 53/100\n",
      "3646/3646 [==============================] - 0s 107us/sample - loss: 0.1463 - val_loss: 0.1533\n",
      "Epoch 54/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1461 - val_loss: 0.1522\n",
      "Epoch 55/100\n",
      "3646/3646 [==============================] - 0s 99us/sample - loss: 0.1460 - val_loss: 0.1522\n",
      "Epoch 56/100\n",
      "3646/3646 [==============================] - 0s 103us/sample - loss: 0.1457 - val_loss: 0.1523\n",
      "Epoch 57/100\n",
      "3646/3646 [==============================] - 0s 113us/sample - loss: 0.1457 - val_loss: 0.1525\n",
      "Epoch 58/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1453 - val_loss: 0.1523\n",
      "Epoch 59/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1453 - val_loss: 0.1513\n",
      "Epoch 60/100\n",
      "3646/3646 [==============================] - 0s 113us/sample - loss: 0.1449 - val_loss: 0.1512\n",
      "Epoch 61/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1449 - val_loss: 0.1511\n",
      "Epoch 62/100\n",
      "3646/3646 [==============================] - 0s 101us/sample - loss: 0.1449 - val_loss: 0.1513\n",
      "Epoch 63/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1447 - val_loss: 0.1510\n",
      "Epoch 64/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1443 - val_loss: 0.1515\n",
      "Epoch 65/100\n",
      "3646/3646 [==============================] - 0s 114us/sample - loss: 0.1443 - val_loss: 0.1505\n",
      "Epoch 66/100\n",
      "3646/3646 [==============================] - 0s 97us/sample - loss: 0.1443 - val_loss: 0.1507\n",
      "Epoch 67/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1438 - val_loss: 0.1513\n",
      "Epoch 68/100\n",
      "3646/3646 [==============================] - 0s 112us/sample - loss: 0.1440 - val_loss: 0.1512\n",
      "Epoch 69/100\n",
      "3646/3646 [==============================] - 0s 131us/sample - loss: 0.1437 - val_loss: 0.1512\n",
      "Epoch 70/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1437 - val_loss: 0.1511\n",
      "Epoch 71/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1436 - val_loss: 0.1502\n",
      "Epoch 72/100\n",
      "3646/3646 [==============================] - 0s 114us/sample - loss: 0.1433 - val_loss: 0.1499\n",
      "Epoch 73/100\n",
      "3646/3646 [==============================] - 0s 124us/sample - loss: 0.1432 - val_loss: 0.1497\n",
      "Epoch 74/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1431 - val_loss: 0.1497\n",
      "Epoch 75/100\n",
      "3646/3646 [==============================] - 0s 110us/sample - loss: 0.1428 - val_loss: 0.1495\n",
      "Epoch 76/100\n",
      "3646/3646 [==============================] - 0s 122us/sample - loss: 0.1427 - val_loss: 0.1494\n",
      "Epoch 77/100\n",
      "3646/3646 [==============================] - 0s 104us/sample - loss: 0.1426 - val_loss: 0.1493\n",
      "Epoch 78/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1424 - val_loss: 0.1492\n",
      "Epoch 79/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1424 - val_loss: 0.1490\n",
      "Epoch 80/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1423 - val_loss: 0.1500\n",
      "Epoch 81/100\n",
      "3646/3646 [==============================] - 0s 107us/sample - loss: 0.1419 - val_loss: 0.1492\n",
      "Epoch 82/100\n",
      "3646/3646 [==============================] - 0s 123us/sample - loss: 0.1418 - val_loss: 0.1492\n",
      "Epoch 83/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.1419 - val_loss: 0.1486\n",
      "Epoch 84/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1416 - val_loss: 0.1485\n",
      "Epoch 85/100\n",
      "3646/3646 [==============================] - 0s 108us/sample - loss: 0.1415 - val_loss: 0.1482\n",
      "Epoch 86/100\n",
      "3646/3646 [==============================] - 0s 104us/sample - loss: 0.1415 - val_loss: 0.1481\n",
      "Epoch 87/100\n",
      "3646/3646 [==============================] - 0s 121us/sample - loss: 0.1412 - val_loss: 0.1481\n",
      "Epoch 88/100\n",
      "3646/3646 [==============================] - 0s 111us/sample - loss: 0.1411 - val_loss: 0.1484\n",
      "Epoch 89/100\n",
      "3646/3646 [==============================] - 0s 105us/sample - loss: 0.1409 - val_loss: 0.1479\n",
      "Epoch 90/100\n",
      "3646/3646 [==============================] - 1s 195us/sample - loss: 0.1406 - val_loss: 0.1481\n",
      "Epoch 91/100\n",
      "3646/3646 [==============================] - 0s 131us/sample - loss: 0.1407 - val_loss: 0.1495\n",
      "Epoch 92/100\n",
      "3646/3646 [==============================] - 0s 130us/sample - loss: 0.1407 - val_loss: 0.1477\n",
      "Epoch 93/100\n",
      "3646/3646 [==============================] - 0s 116us/sample - loss: 0.1402 - val_loss: 0.1485\n",
      "Epoch 94/100\n",
      "3646/3646 [==============================] - 0s 113us/sample - loss: 0.1401 - val_loss: 0.1475\n",
      "Epoch 95/100\n",
      "3646/3646 [==============================] - 1s 139us/sample - loss: 0.1399 - val_loss: 0.1477\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3646/3646 [==============================] - 0s 119us/sample - loss: 0.1399 - val_loss: 0.1473\n",
      "Epoch 97/100\n",
      "3646/3646 [==============================] - 0s 124us/sample - loss: 0.1399 - val_loss: 0.1476\n",
      "Epoch 98/100\n",
      "3646/3646 [==============================] - 0s 117us/sample - loss: 0.1397 - val_loss: 0.1475\n",
      "Epoch 99/100\n",
      "3646/3646 [==============================] - 0s 109us/sample - loss: 0.1396 - val_loss: 0.1468\n",
      "Epoch 100/100\n",
      "3646/3646 [==============================] - 0s 102us/sample - loss: 0.1394 - val_loss: 0.1470\n",
      "1822/1822 [==============================] - 0s 42us/sample - loss: 0.1376\n",
      "[CV] END learning_rate=0.003503069654796154, n_hidden=3, n_neurons=57; total time=  40.1s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 378us/sample - loss: 0.1762 - val_loss: 0.1702\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 1s 150us/sample - loss: 0.1557 - val_loss: 0.1639\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 128us/sample - loss: 0.1523 - val_loss: 0.1616\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1501 - val_loss: 0.1609\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1479 - val_loss: 0.1591\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1464 - val_loss: 0.1599\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1448 - val_loss: 0.1588\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 1s 183us/sample - loss: 0.1443 - val_loss: 0.1548\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 1s 143us/sample - loss: 0.1429 - val_loss: 0.1553\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1413 - val_loss: 0.1534\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1405 - val_loss: 0.1529\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 133us/sample - loss: 0.1397 - val_loss: 0.1514\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1390 - val_loss: 0.1522\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1378 - val_loss: 0.1511\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1366 - val_loss: 0.1523\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1361 - val_loss: 0.1501\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1351 - val_loss: 0.1555\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1340 - val_loss: 0.1507\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1343 - val_loss: 0.1467\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1331 - val_loss: 0.1485\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1327 - val_loss: 0.1467\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 123us/sample - loss: 0.1328 - val_loss: 0.1515\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1314 - val_loss: 0.1486\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1322 - val_loss: 0.1450\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1297 - val_loss: 0.1445\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 1s 151us/sample - loss: 0.1300 - val_loss: 0.1437\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 112us/sample - loss: 0.1285 - val_loss: 0.1434\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 1s 142us/sample - loss: 0.1284 - val_loss: 0.1514\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 121us/sample - loss: 0.1278 - val_loss: 0.1412\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - ETA: 0s - loss: 0.127 - 1s 155us/sample - loss: 0.1273 - val_loss: 0.1434\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 1s 168us/sample - loss: 0.1271 - val_loss: 0.1423\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 129us/sample - loss: 0.1264 - val_loss: 0.1505\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 112us/sample - loss: 0.1258 - val_loss: 0.1494\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 130us/sample - loss: 0.1250 - val_loss: 0.1425\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1238 - val_loss: 0.1411\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 1s 138us/sample - loss: 0.1236 - val_loss: 0.1413\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.1229 - val_loss: 0.1391\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1233 - val_loss: 0.1432\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1225 - val_loss: 0.1408\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 135us/sample - loss: 0.1213 - val_loss: 0.1375\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1225 - val_loss: 0.1379\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1202 - val_loss: 0.1391\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1189 - val_loss: 0.1384\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 128us/sample - loss: 0.1200 - val_loss: 0.1402\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 127us/sample - loss: 0.1189 - val_loss: 0.1437\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1195 - val_loss: 0.1379\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 1s 149us/sample - loss: 0.1194 - val_loss: 0.1343\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 1s 143us/sample - loss: 0.1180 - val_loss: 0.1337\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 130us/sample - loss: 0.1190 - val_loss: 0.1489\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 1s 140us/sample - loss: 0.1171 - val_loss: 0.1362\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 133us/sample - loss: 0.1186 - val_loss: 0.1313\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1170 - val_loss: 0.1360\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1152 - val_loss: 0.1342\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 124us/sample - loss: 0.1146 - val_loss: 0.1326\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1155 - val_loss: 0.1364\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 1s 183us/sample - loss: 0.1142 - val_loss: 0.1312\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 124us/sample - loss: 0.1137 - val_loss: 0.1268\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1134 - val_loss: 0.1340\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1113 - val_loss: 0.1353\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 126us/sample - loss: 0.1123 - val_loss: 0.1408\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 1s 140us/sample - loss: 0.1098 - val_loss: 0.1332\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 1s 172us/sample - loss: 0.1108 - val_loss: 0.1301\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 1s 212us/sample - loss: 0.1132 - val_loss: 0.1286\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 1s 266us/sample - loss: 0.1101 - val_loss: 0.1386\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 1s 164us/sample - loss: 0.1097 - val_loss: 0.1386\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 1s 144us/sample - loss: 0.1091 - val_loss: 0.1336\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 1s 201us/sample - loss: 0.1133 - val_loss: 0.1231\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 1s 236us/sample - loss: 0.1087 - val_loss: 0.1244\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 1s 159us/sample - loss: 0.1095 - val_loss: 0.1225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 118us/sample - loss: 0.1080 - val_loss: 0.1262\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 117us/sample - loss: 0.1083 - val_loss: 0.1225\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1054 - val_loss: 0.1274\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 126us/sample - loss: 0.1066 - val_loss: 0.1255\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 1s 195us/sample - loss: 0.1045 - val_loss: 0.1222\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 1s 141us/sample - loss: 0.1064 - val_loss: 0.1199\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1047 - val_loss: 0.1221\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1037 - val_loss: 0.1255\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1025 - val_loss: 0.1462\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.1033 - val_loss: 0.1402\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1055 - val_loss: 0.1214\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1025 - val_loss: 0.1226\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1028 - val_loss: 0.1171\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1029 - val_loss: 0.1180\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1023 - val_loss: 0.1394\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.0999 - val_loss: 0.1254\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1029 - val_loss: 0.1202\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1021 - val_loss: 0.1181\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 1s 200us/sample - loss: 0.0993 - val_loss: 0.1153\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 1s 152us/sample - loss: 0.0985 - val_loss: 0.1139\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 1s 138us/sample - loss: 0.0987 - val_loss: 0.1156\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 119us/sample - loss: 0.0946 - val_loss: 0.1206\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 1s 265us/sample - loss: 0.0983 - val_loss: 0.1140\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 1s 287us/sample - loss: 0.0956 - val_loss: 0.1146\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 1s 334us/sample - loss: 0.0965 - val_loss: 0.1251\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 1s 234us/sample - loss: 0.0967 - val_loss: 0.1160\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 1s 218us/sample - loss: 0.0943 - val_loss: 0.1132\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 1s 208us/sample - loss: 0.0974 - val_loss: 0.1111\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 1s 163us/sample - loss: 0.0965 - val_loss: 0.1148\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 1s 250us/sample - loss: 0.0940 - val_loss: 0.1149\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 1s 200us/sample - loss: 0.0944 - val_loss: 0.1204\n",
      "1823/1823 [==============================] - 0s 66us/sample - loss: 0.1195\n",
      "[CV] END learning_rate=0.017926272076224836, n_hidden=3, n_neurons=99; total time=  51.0s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 2s 413us/sample - loss: 0.1769 - val_loss: 0.1727\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1591 - val_loss: 0.1611\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1545 - val_loss: 0.1612\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1519 - val_loss: 0.1566\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1498 - val_loss: 0.1546\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1485 - val_loss: 0.1557\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1466 - val_loss: 0.1544\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 125us/sample - loss: 0.1462 - val_loss: 0.1517\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 130us/sample - loss: 0.1442 - val_loss: 0.1505\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1432 - val_loss: 0.1532\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 126us/sample - loss: 0.1427 - val_loss: 0.1500\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.1410 - val_loss: 0.1476\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 1s 170us/sample - loss: 0.1408 - val_loss: 0.1475\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 136us/sample - loss: 0.1395 - val_loss: 0.1478\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 1s 171us/sample - loss: 0.1389 - val_loss: 0.1467\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 137us/sample - loss: 0.1377 - val_loss: 0.1453\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 1s 231us/sample - loss: 0.1370 - val_loss: 0.1480\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 1s 234us/sample - loss: 0.1360 - val_loss: 0.1449\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 1s 193us/sample - loss: 0.1352 - val_loss: 0.1460\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 1s 226us/sample - loss: 0.1342 - val_loss: 0.1423\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 1s 207us/sample - loss: 0.1331 - val_loss: 0.1425\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 1s 225us/sample - loss: 0.1333 - val_loss: 0.1449\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 1s 211us/sample - loss: 0.1326 - val_loss: 0.1486\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 1s 159us/sample - loss: 0.1322 - val_loss: 0.1404\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 1s 143us/sample - loss: 0.1310 - val_loss: 0.1417\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 1s 138us/sample - loss: 0.1307 - val_loss: 0.1396\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 134us/sample - loss: 0.1292 - val_loss: 0.1384\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1285 - val_loss: 0.1438\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1275 - val_loss: 0.1394\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.1272 - val_loss: 0.1370\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 1s 183us/sample - loss: 0.1263 - val_loss: 0.1386\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1253 - val_loss: 0.1362\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1252 - val_loss: 0.1351\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1246 - val_loss: 0.1349\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1236 - val_loss: 0.1349\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1234 - val_loss: 0.1339\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1216 - val_loss: 0.1357\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1226 - val_loss: 0.1318\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 125us/sample - loss: 0.1216 - val_loss: 0.1303\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1195 - val_loss: 0.1297\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1194 - val_loss: 0.1328\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1180 - val_loss: 0.1324\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 117us/sample - loss: 0.1177 - val_loss: 0.1353\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 120us/sample - loss: 0.1163 - val_loss: 0.1287\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1168 - val_loss: 0.1265\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1161 - val_loss: 0.1272\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1148 - val_loss: 0.1308\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 120us/sample - loss: 0.1144 - val_loss: 0.1256\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 128us/sample - loss: 0.1138 - val_loss: 0.1256\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 1s 156us/sample - loss: 0.1135 - val_loss: 0.1301\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - ETA: 0s - loss: 0.112 - 0s 125us/sample - loss: 0.1133 - val_loss: 0.1258\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1128 - val_loss: 0.1239\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 1s 153us/sample - loss: 0.1122 - val_loss: 0.1238\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 131us/sample - loss: 0.1111 - val_loss: 0.1221\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 132us/sample - loss: 0.1101 - val_loss: 0.1225\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 127us/sample - loss: 0.1095 - val_loss: 0.1224\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1102 - val_loss: 0.1373\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1088 - val_loss: 0.1210\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 136us/sample - loss: 0.1099 - val_loss: 0.1206\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 112us/sample - loss: 0.1086 - val_loss: 0.1272\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 1s 144us/sample - loss: 0.1060 - val_loss: 0.1197\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 1s 158us/sample - loss: 0.1065 - val_loss: 0.1264\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 117us/sample - loss: 0.1053 - val_loss: 0.1188\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1054 - val_loss: 0.1249\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1037 - val_loss: 0.1170\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1031 - val_loss: 0.1174\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1022 - val_loss: 0.1160\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1046 - val_loss: 0.1215\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1021 - val_loss: 0.1155\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 120us/sample - loss: 0.1004 - val_loss: 0.1162\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1022 - val_loss: 0.1230\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1007 - val_loss: 0.1121\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.0996 - val_loss: 0.1139\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1003 - val_loss: 0.1107\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.0994 - val_loss: 0.1232\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.0968 - val_loss: 0.1204\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.0972 - val_loss: 0.1151\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.0969 - val_loss: 0.1136\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.0960 - val_loss: 0.1238\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - ETA: 0s - loss: 0.094 - 0s 124us/sample - loss: 0.0950 - val_loss: 0.1131\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 131us/sample - loss: 0.0938 - val_loss: 0.1172\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.0977 - val_loss: 0.1078\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 1s 142us/sample - loss: 0.0966 - val_loss: 0.1095\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.0930 - val_loss: 0.1074\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.0940 - val_loss: 0.1067\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 116us/sample - loss: 0.0932 - val_loss: 0.1235\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 1s 181us/sample - loss: 0.0910 - val_loss: 0.1066\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 129us/sample - loss: 0.0899 - val_loss: 0.1084\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 128us/sample - loss: 0.0945 - val_loss: 0.1057\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 128us/sample - loss: 0.0911 - val_loss: 0.1394\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 1s 165us/sample - loss: 0.0915 - val_loss: 0.1168\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 1s 152us/sample - loss: 0.0900 - val_loss: 0.1068\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.0913 - val_loss: 0.1139\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 137us/sample - loss: 0.0856 - val_loss: 0.1209\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.0878 - val_loss: 0.1121\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 123us/sample - loss: 0.0859 - val_loss: 0.1029\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.0891 - val_loss: 0.1290\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 126us/sample - loss: 0.0884 - val_loss: 0.1017\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 1s 138us/sample - loss: 0.0879 - val_loss: 0.1024\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.0883 - val_loss: 0.1036\n",
      "1823/1823 [==============================] - 0s 66us/sample - loss: 0.0959\n",
      "[CV] END learning_rate=0.017926272076224836, n_hidden=3, n_neurons=99; total time=  47.2s\n",
      "Train on 3646 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3646/3646 [==============================] - 1s 275us/sample - loss: 0.1930 - val_loss: 0.1726\n",
      "Epoch 2/100\n",
      "3646/3646 [==============================] - 0s 113us/sample - loss: 0.1636 - val_loss: 0.1619\n",
      "Epoch 3/100\n",
      "3646/3646 [==============================] - 1s 143us/sample - loss: 0.1564 - val_loss: 0.1608\n",
      "Epoch 4/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1529 - val_loss: 0.1558\n",
      "Epoch 5/100\n",
      "3646/3646 [==============================] - 0s 111us/sample - loss: 0.1500 - val_loss: 0.1580\n",
      "Epoch 6/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1487 - val_loss: 0.1524\n",
      "Epoch 7/100\n",
      "3646/3646 [==============================] - 0s 108us/sample - loss: 0.1471 - val_loss: 0.1523\n",
      "Epoch 8/100\n",
      "3646/3646 [==============================] - 0s 125us/sample - loss: 0.1460 - val_loss: 0.1535\n",
      "Epoch 9/100\n",
      "3646/3646 [==============================] - 0s 125us/sample - loss: 0.1450 - val_loss: 0.1500\n",
      "Epoch 10/100\n",
      "3646/3646 [==============================] - 0s 93us/sample - loss: 0.1429 - val_loss: 0.1495\n",
      "Epoch 11/100\n",
      "3646/3646 [==============================] - 0s 127us/sample - loss: 0.1424 - val_loss: 0.1507\n",
      "Epoch 12/100\n",
      "3646/3646 [==============================] - 0s 103us/sample - loss: 0.1407 - val_loss: 0.1485\n",
      "Epoch 13/100\n",
      "3646/3646 [==============================] - 0s 129us/sample - loss: 0.1406 - val_loss: 0.1486\n",
      "Epoch 14/100\n",
      "3646/3646 [==============================] - 0s 117us/sample - loss: 0.1393 - val_loss: 0.1458\n",
      "Epoch 15/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1382 - val_loss: 0.1541\n",
      "Epoch 16/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1376 - val_loss: 0.1449\n",
      "Epoch 17/100\n",
      "3646/3646 [==============================] - 0s 101us/sample - loss: 0.1371 - val_loss: 0.1443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1356 - val_loss: 0.1435\n",
      "Epoch 19/100\n",
      "3646/3646 [==============================] - 0s 110us/sample - loss: 0.1349 - val_loss: 0.1434\n",
      "Epoch 20/100\n",
      "3646/3646 [==============================] - 0s 118us/sample - loss: 0.1339 - val_loss: 0.1462\n",
      "Epoch 21/100\n",
      "3646/3646 [==============================] - 0s 108us/sample - loss: 0.1332 - val_loss: 0.1437\n",
      "Epoch 22/100\n",
      "3646/3646 [==============================] - 0s 104us/sample - loss: 0.1328 - val_loss: 0.1408\n",
      "Epoch 23/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1313 - val_loss: 0.1413\n",
      "Epoch 24/100\n",
      "3646/3646 [==============================] - 0s 103us/sample - loss: 0.1321 - val_loss: 0.1456\n",
      "Epoch 25/100\n",
      "3646/3646 [==============================] - 0s 104us/sample - loss: 0.1307 - val_loss: 0.1389\n",
      "Epoch 26/100\n",
      "3646/3646 [==============================] - 0s 111us/sample - loss: 0.1295 - val_loss: 0.1378\n",
      "Epoch 27/100\n",
      "3646/3646 [==============================] - 0s 109us/sample - loss: 0.1296 - val_loss: 0.1414\n",
      "Epoch 28/100\n",
      "3646/3646 [==============================] - 0s 111us/sample - loss: 0.1275 - val_loss: 0.1372\n",
      "Epoch 29/100\n",
      "3646/3646 [==============================] - 0s 107us/sample - loss: 0.1281 - val_loss: 0.1363\n",
      "Epoch 30/100\n",
      "3646/3646 [==============================] - 0s 122us/sample - loss: 0.1266 - val_loss: 0.1363\n",
      "Epoch 31/100\n",
      "3646/3646 [==============================] - 1s 146us/sample - loss: 0.1251 - val_loss: 0.1374\n",
      "Epoch 32/100\n",
      "3646/3646 [==============================] - 0s 120us/sample - loss: 0.1262 - val_loss: 0.1343\n",
      "Epoch 33/100\n",
      "3646/3646 [==============================] - 0s 114us/sample - loss: 0.1247 - val_loss: 0.1344\n",
      "Epoch 34/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1243 - val_loss: 0.1345\n",
      "Epoch 35/100\n",
      "3646/3646 [==============================] - 0s 124us/sample - loss: 0.1229 - val_loss: 0.1336\n",
      "Epoch 36/100\n",
      "3646/3646 [==============================] - 0s 109us/sample - loss: 0.1221 - val_loss: 0.1331\n",
      "Epoch 37/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1213 - val_loss: 0.1377\n",
      "Epoch 38/100\n",
      "3646/3646 [==============================] - 0s 93us/sample - loss: 0.1222 - val_loss: 0.1344\n",
      "Epoch 39/100\n",
      "3646/3646 [==============================] - 0s 129us/sample - loss: 0.1199 - val_loss: 0.1380\n",
      "Epoch 40/100\n",
      "3646/3646 [==============================] - 0s 119us/sample - loss: 0.1190 - val_loss: 0.1312\n",
      "Epoch 41/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1204 - val_loss: 0.1291\n",
      "Epoch 42/100\n",
      "3646/3646 [==============================] - 0s 127us/sample - loss: 0.1180 - val_loss: 0.1292\n",
      "Epoch 43/100\n",
      "3646/3646 [==============================] - 0s 118us/sample - loss: 0.1179 - val_loss: 0.1284\n",
      "Epoch 44/100\n",
      "3646/3646 [==============================] - 0s 113us/sample - loss: 0.1164 - val_loss: 0.1265\n",
      "Epoch 45/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1148 - val_loss: 0.1302\n",
      "Epoch 46/100\n",
      "3646/3646 [==============================] - 0s 129us/sample - loss: 0.1164 - val_loss: 0.1377\n",
      "Epoch 47/100\n",
      "3646/3646 [==============================] - 0s 131us/sample - loss: 0.1145 - val_loss: 0.1277\n",
      "Epoch 48/100\n",
      "3646/3646 [==============================] - 0s 108us/sample - loss: 0.1138 - val_loss: 0.1268\n",
      "Epoch 49/100\n",
      "3646/3646 [==============================] - 0s 121us/sample - loss: 0.1145 - val_loss: 0.1293\n",
      "Epoch 50/100\n",
      "3646/3646 [==============================] - 1s 141us/sample - loss: 0.1130 - val_loss: 0.1258\n",
      "Epoch 51/100\n",
      "3646/3646 [==============================] - 0s 109us/sample - loss: 0.1140 - val_loss: 0.1241\n",
      "Epoch 52/100\n",
      "3646/3646 [==============================] - 1s 139us/sample - loss: 0.1112 - val_loss: 0.1260\n",
      "Epoch 53/100\n",
      "3646/3646 [==============================] - 1s 204us/sample - loss: 0.1108 - val_loss: 0.1273\n",
      "Epoch 54/100\n",
      "3646/3646 [==============================] - 1s 208us/sample - loss: 0.1111 - val_loss: 0.1204\n",
      "Epoch 55/100\n",
      "3646/3646 [==============================] - 1s 281us/sample - loss: 0.1080 - val_loss: 0.1227\n",
      "Epoch 56/100\n",
      "3646/3646 [==============================] - 1s 200us/sample - loss: 0.1123 - val_loss: 0.1283\n",
      "Epoch 57/100\n",
      "3646/3646 [==============================] - 1s 202us/sample - loss: 0.1110 - val_loss: 0.1203\n",
      "Epoch 58/100\n",
      "3646/3646 [==============================] - 1s 150us/sample - loss: 0.1102 - val_loss: 0.1187\n",
      "Epoch 59/100\n",
      "3646/3646 [==============================] - 1s 190us/sample - loss: 0.1100 - val_loss: 0.1384\n",
      "Epoch 60/100\n",
      "3646/3646 [==============================] - 0s 128us/sample - loss: 0.1072 - val_loss: 0.1192\n",
      "Epoch 61/100\n",
      "3646/3646 [==============================] - ETA: 0s - loss: 0.106 - 1s 139us/sample - loss: 0.1066 - val_loss: 0.1252\n",
      "Epoch 62/100\n",
      "3646/3646 [==============================] - 1s 151us/sample - loss: 0.1072 - val_loss: 0.1221\n",
      "Epoch 63/100\n",
      "3646/3646 [==============================] - 1s 161us/sample - loss: 0.1064 - val_loss: 0.1165\n",
      "Epoch 64/100\n",
      "3646/3646 [==============================] - 0s 115us/sample - loss: 0.1075 - val_loss: 0.1260\n",
      "Epoch 65/100\n",
      "3646/3646 [==============================] - 0s 113us/sample - loss: 0.1053 - val_loss: 0.1166\n",
      "Epoch 66/100\n",
      "3646/3646 [==============================] - 1s 171us/sample - loss: 0.1027 - val_loss: 0.1164\n",
      "Epoch 67/100\n",
      "3646/3646 [==============================] - 1s 175us/sample - loss: 0.1027 - val_loss: 0.1175\n",
      "Epoch 68/100\n",
      "3646/3646 [==============================] - 1s 179us/sample - loss: 0.1025 - val_loss: 0.1179\n",
      "Epoch 69/100\n",
      "3646/3646 [==============================] - 0s 108us/sample - loss: 0.1013 - val_loss: 0.1175\n",
      "Epoch 70/100\n",
      "3646/3646 [==============================] - 0s 129us/sample - loss: 0.1029 - val_loss: 0.1129\n",
      "Epoch 71/100\n",
      "3646/3646 [==============================] - 0s 105us/sample - loss: 0.1032 - val_loss: 0.1236\n",
      "Epoch 72/100\n",
      "3646/3646 [==============================] - 0s 115us/sample - loss: 0.0991 - val_loss: 0.1123\n",
      "Epoch 73/100\n",
      "3646/3646 [==============================] - 0s 118us/sample - loss: 0.1004 - val_loss: 0.1120\n",
      "Epoch 74/100\n",
      "3646/3646 [==============================] - 0s 128us/sample - loss: 0.0995 - val_loss: 0.1156\n",
      "Epoch 75/100\n",
      "3646/3646 [==============================] - 1s 141us/sample - loss: 0.1032 - val_loss: 0.1539\n",
      "Epoch 76/100\n",
      "3646/3646 [==============================] - 1s 203us/sample - loss: 0.0994 - val_loss: 0.1129\n",
      "Epoch 77/100\n",
      "3646/3646 [==============================] - 1s 162us/sample - loss: 0.0958 - val_loss: 0.1262\n",
      "Epoch 78/100\n",
      "3646/3646 [==============================] - 1s 238us/sample - loss: 0.0973 - val_loss: 0.1191\n",
      "Epoch 79/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.0961 - val_loss: 0.1148\n",
      "Epoch 80/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.0962 - val_loss: 0.1135\n",
      "Epoch 81/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.0951 - val_loss: 0.1134\n",
      "Epoch 82/100\n",
      "3646/3646 [==============================] - 0s 121us/sample - loss: 0.0992 - val_loss: 0.1161\n",
      "Epoch 83/100\n",
      "3646/3646 [==============================] - 1s 147us/sample - loss: 0.0941 - val_loss: 0.1114\n",
      "Epoch 84/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.0942 - val_loss: 0.1106\n",
      "Epoch 85/100\n",
      "3646/3646 [==============================] - 1s 154us/sample - loss: 0.0931 - val_loss: 0.1134\n",
      "Epoch 86/100\n",
      "3646/3646 [==============================] - 0s 110us/sample - loss: 0.0931 - val_loss: 0.1096\n",
      "Epoch 87/100\n",
      "3646/3646 [==============================] - 1s 251us/sample - loss: 0.0938 - val_loss: 0.1120\n",
      "Epoch 88/100\n",
      "3646/3646 [==============================] - 2s 444us/sample - loss: 0.0936 - val_loss: 0.1080\n",
      "Epoch 89/100\n",
      "3646/3646 [==============================] - 1s 164us/sample - loss: 0.0924 - val_loss: 0.1101\n",
      "Epoch 90/100\n",
      "3646/3646 [==============================] - 1s 144us/sample - loss: 0.0949 - val_loss: 0.1053\n",
      "Epoch 91/100\n",
      "3646/3646 [==============================] - 1s 179us/sample - loss: 0.0898 - val_loss: 0.1167\n",
      "Epoch 92/100\n",
      "3646/3646 [==============================] - 0s 129us/sample - loss: 0.0871 - val_loss: 0.1031\n",
      "Epoch 93/100\n",
      "3646/3646 [==============================] - 1s 148us/sample - loss: 0.0945 - val_loss: 0.1079\n",
      "Epoch 94/100\n",
      "3646/3646 [==============================] - 0s 102us/sample - loss: 0.0895 - val_loss: 0.1165\n",
      "Epoch 95/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.0890 - val_loss: 0.1032\n",
      "Epoch 96/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.0898 - val_loss: 0.1056\n",
      "Epoch 97/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.0858 - val_loss: 0.1043\n",
      "Epoch 98/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.0848 - val_loss: 0.1034\n",
      "Epoch 99/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.0853 - val_loss: 0.1074\n",
      "Epoch 100/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.0896 - val_loss: 0.1205\n",
      "1822/1822 [==============================] - 0s 35us/sample - loss: 0.1150\n",
      "[CV] END learning_rate=0.017926272076224836, n_hidden=3, n_neurons=99; total time=  48.8s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 196us/sample - loss: 0.3084 - val_loss: 0.2775\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.2414 - val_loss: 0.2570\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.2267 - val_loss: 0.2441\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.2173 - val_loss: 0.2350\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.2105 - val_loss: 0.2281\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.2054 - val_loss: 0.2232\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.2012 - val_loss: 0.2183\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1978 - val_loss: 0.2147\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1949 - val_loss: 0.2110\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1921 - val_loss: 0.2083\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1897 - val_loss: 0.2054\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1876 - val_loss: 0.2028\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1855 - val_loss: 0.2005\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 136us/sample - loss: 0.1836 - val_loss: 0.1984\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 118us/sample - loss: 0.1819 - val_loss: 0.1966\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 116us/sample - loss: 0.1802 - val_loss: 0.1945\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1789 - val_loss: 0.1929\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1775 - val_loss: 0.1913\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1762 - val_loss: 0.1898\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1751 - val_loss: 0.1885\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1739 - val_loss: 0.1874\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1729 - val_loss: 0.1860\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1721 - val_loss: 0.1851\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 1s 183us/sample - loss: 0.1712 - val_loss: 0.1840\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1703 - val_loss: 0.1837\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 1s 141us/sample - loss: 0.1697 - val_loss: 0.1822\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1689 - val_loss: 0.1813\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 117us/sample - loss: 0.1683 - val_loss: 0.1808\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1677 - val_loss: 0.1800\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 116us/sample - loss: 0.1670 - val_loss: 0.1791\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 1s 137us/sample - loss: 0.1664 - val_loss: 0.1791\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1660 - val_loss: 0.1780\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.1654 - val_loss: 0.1773\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1648 - val_loss: 0.1768\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1646 - val_loss: 0.1763\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 117us/sample - loss: 0.1641 - val_loss: 0.1759\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1637 - val_loss: 0.1755\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1633 - val_loss: 0.1749\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1629 - val_loss: 0.1747\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1625 - val_loss: 0.1739\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1622 - val_loss: 0.1735\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1619 - val_loss: 0.1733\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1615 - val_loss: 0.1729\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1612 - val_loss: 0.1724\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 124us/sample - loss: 0.1608 - val_loss: 0.1726\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 115us/sample - loss: 0.1606 - val_loss: 0.1721\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1603 - val_loss: 0.1714\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1601 - val_loss: 0.1711\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1598 - val_loss: 0.1709\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1594 - val_loss: 0.1709\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1592 - val_loss: 0.1703\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1589 - val_loss: 0.1700\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1587 - val_loss: 0.1696\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1585 - val_loss: 0.1695\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1582 - val_loss: 0.1692\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1580 - val_loss: 0.1691\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1577 - val_loss: 0.1686\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1576 - val_loss: 0.1684\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1573 - val_loss: 0.1683\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1571 - val_loss: 0.1682\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1569 - val_loss: 0.1679\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1568 - val_loss: 0.1677\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1565 - val_loss: 0.1677\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1564 - val_loss: 0.1675\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1562 - val_loss: 0.1673\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1560 - val_loss: 0.1671\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1559 - val_loss: 0.1670\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 116us/sample - loss: 0.1556 - val_loss: 0.1675\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1556 - val_loss: 0.1665\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1553 - val_loss: 0.1662\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1552 - val_loss: 0.1663\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1551 - val_loss: 0.1658\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.1549 - val_loss: 0.1658\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 123us/sample - loss: 0.1548 - val_loss: 0.1655\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1546 - val_loss: 0.1653\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.1545 - val_loss: 0.1653\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1543 - val_loss: 0.1654\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 118us/sample - loss: 0.1542 - val_loss: 0.1648\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 1s 156us/sample - loss: 0.1541 - val_loss: 0.1649\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1539 - val_loss: 0.1647\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1537 - val_loss: 0.1643\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1537 - val_loss: 0.1643\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1535 - val_loss: 0.1645\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1534 - val_loss: 0.1640\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1533 - val_loss: 0.1639\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1532 - val_loss: 0.1638\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1530 - val_loss: 0.1642\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1530 - val_loss: 0.1636\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1528 - val_loss: 0.1635\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 118us/sample - loss: 0.1528 - val_loss: 0.1637\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1526 - val_loss: 0.1637\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1526 - val_loss: 0.1634\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1525 - val_loss: 0.1632\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1524 - val_loss: 0.1632\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1523 - val_loss: 0.1631\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.1522 - val_loss: 0.1633\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1522 - val_loss: 0.1628\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1520 - val_loss: 0.1631\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.1520 - val_loss: 0.1628\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1518 - val_loss: 0.1629\n",
      "1823/1823 [==============================] - 0s 73us/sample - loss: 0.1648\n",
      "[CV] END learning_rate=0.0008069828063751967, n_hidden=1, n_neurons=28; total time=  36.4s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 234us/sample - loss: 0.4442 - val_loss: 0.3855\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.3320 - val_loss: 0.3106\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.2742 - val_loss: 0.2690\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.2413 - val_loss: 0.2441\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.2217 - val_loss: 0.2287\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.2093 - val_loss: 0.2186\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.2010 - val_loss: 0.2117\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1952 - val_loss: 0.2065\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 120us/sample - loss: 0.1909 - val_loss: 0.2024\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1877 - val_loss: 0.1992\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1851 - val_loss: 0.1967\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1830 - val_loss: 0.1946\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 112us/sample - loss: 0.1812 - val_loss: 0.1927\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.1797 - val_loss: 0.1910\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1783 - val_loss: 0.1895\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 1s 138us/sample - loss: 0.1772 - val_loss: 0.1883\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1761 - val_loss: 0.1871\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1751 - val_loss: 0.1860\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1743 - val_loss: 0.1850\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1734 - val_loss: 0.1842\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1727 - val_loss: 0.1833\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 130us/sample - loss: 0.1720 - val_loss: 0.1825\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1714 - val_loss: 0.1818\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1708 - val_loss: 0.1813\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1702 - val_loss: 0.1807\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 124us/sample - loss: 0.1697 - val_loss: 0.1799\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1692 - val_loss: 0.1794\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1687 - val_loss: 0.1788\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1682 - val_loss: 0.1783\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1677 - val_loss: 0.1778\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1673 - val_loss: 0.1774\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1669 - val_loss: 0.1771\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1665 - val_loss: 0.1765\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1662 - val_loss: 0.1763\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1659 - val_loss: 0.1759\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1655 - val_loss: 0.1754\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1653 - val_loss: 0.1752\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1650 - val_loss: 0.1749\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1647 - val_loss: 0.1745\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1644 - val_loss: 0.1744\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1642 - val_loss: 0.1742\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1639 - val_loss: 0.1739\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1637 - val_loss: 0.1735\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1635 - val_loss: 0.1733\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1633 - val_loss: 0.1731\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1630 - val_loss: 0.1729\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1629 - val_loss: 0.1727\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1627 - val_loss: 0.1725\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1624 - val_loss: 0.1723\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1623 - val_loss: 0.1724\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1621 - val_loss: 0.1722\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1620 - val_loss: 0.1718\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1617 - val_loss: 0.1719\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1615 - val_loss: 0.1714\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1615 - val_loss: 0.1713\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1612 - val_loss: 0.1711\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1611 - val_loss: 0.1710\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1610 - val_loss: 0.1708\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1608 - val_loss: 0.1707\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 124us/sample - loss: 0.1607 - val_loss: 0.1705\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1605 - val_loss: 0.1703\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1604 - val_loss: 0.1702\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1603 - val_loss: 0.1702\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1600 - val_loss: 0.1699\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1600 - val_loss: 0.1699\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1599 - val_loss: 0.1698\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1598 - val_loss: 0.1696\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1597 - val_loss: 0.1695\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1596 - val_loss: 0.1696\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1594 - val_loss: 0.1692\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1593 - val_loss: 0.1691\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1593 - val_loss: 0.1692\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1592 - val_loss: 0.1691\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1591 - val_loss: 0.1690\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1589 - val_loss: 0.1689\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1589 - val_loss: 0.1687\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1588 - val_loss: 0.1688\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1587 - val_loss: 0.1685\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1586 - val_loss: 0.1684\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1585 - val_loss: 0.1683\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1584 - val_loss: 0.1685\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1584 - val_loss: 0.1683\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1583 - val_loss: 0.1682\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1582 - val_loss: 0.1685\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1582 - val_loss: 0.1680\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1579 - val_loss: 0.1683\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1580 - val_loss: 0.1679\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1579 - val_loss: 0.1677\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1578 - val_loss: 0.1677\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1577 - val_loss: 0.1675\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1576 - val_loss: 0.1674\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1577 - val_loss: 0.1674\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1575 - val_loss: 0.1676\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1574 - val_loss: 0.1674\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 126us/sample - loss: 0.1574 - val_loss: 0.1672\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1573 - val_loss: 0.1673\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1573 - val_loss: 0.1671\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 1s 144us/sample - loss: 0.1572 - val_loss: 0.1671\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 1s 139us/sample - loss: 0.1571 - val_loss: 0.1670\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 115us/sample - loss: 0.1571 - val_loss: 0.1669\n",
      "1823/1823 [==============================] - 0s 33us/sample - loss: 0.1589\n",
      "[CV] END learning_rate=0.0008069828063751967, n_hidden=1, n_neurons=28; total time=  33.0s\n",
      "Train on 3646 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3646/3646 [==============================] - 1s 309us/sample - loss: 0.5892 - val_loss: 0.3652\n",
      "Epoch 2/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.3406 - val_loss: 0.3141\n",
      "Epoch 3/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.2984 - val_loss: 0.2843\n",
      "Epoch 4/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.2721 - val_loss: 0.2650\n",
      "Epoch 5/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.2544 - val_loss: 0.2514\n",
      "Epoch 6/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.2417 - val_loss: 0.2417\n",
      "Epoch 7/100\n",
      "3646/3646 [==============================] - 0s 127us/sample - loss: 0.2321 - val_loss: 0.2337\n",
      "Epoch 8/100\n",
      "3646/3646 [==============================] - 0s 101us/sample - loss: 0.2246 - val_loss: 0.2277\n",
      "Epoch 9/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.2185 - val_loss: 0.2223\n",
      "Epoch 10/100\n",
      "3646/3646 [==============================] - 0s 104us/sample - loss: 0.2134 - val_loss: 0.2181\n",
      "Epoch 11/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.2092 - val_loss: 0.2143\n",
      "Epoch 12/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.2054 - val_loss: 0.2114\n",
      "Epoch 13/100\n",
      "3646/3646 [==============================] - 1s 183us/sample - loss: 0.2022 - val_loss: 0.2083\n",
      "Epoch 14/100\n",
      "3646/3646 [==============================] - 1s 185us/sample - loss: 0.1993 - val_loss: 0.2054\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3646/3646 [==============================] - 0s 102us/sample - loss: 0.1968 - val_loss: 0.2031\n",
      "Epoch 16/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1944 - val_loss: 0.2010\n",
      "Epoch 17/100\n",
      "3646/3646 [==============================] - 0s 70us/sample - loss: 0.1922 - val_loss: 0.1988\n",
      "Epoch 18/100\n",
      "3646/3646 [==============================] - 0s 70us/sample - loss: 0.1905 - val_loss: 0.1972\n",
      "Epoch 19/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1887 - val_loss: 0.1955\n",
      "Epoch 20/100\n",
      "3646/3646 [==============================] - 0s 68us/sample - loss: 0.1871 - val_loss: 0.1940\n",
      "Epoch 21/100\n",
      "3646/3646 [==============================] - 0s 69us/sample - loss: 0.1856 - val_loss: 0.1927\n",
      "Epoch 22/100\n",
      "3646/3646 [==============================] - 0s 73us/sample - loss: 0.1842 - val_loss: 0.1914\n",
      "Epoch 23/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1830 - val_loss: 0.1901\n",
      "Epoch 24/100\n",
      "3646/3646 [==============================] - 0s 70us/sample - loss: 0.1818 - val_loss: 0.1892\n",
      "Epoch 25/100\n",
      "3646/3646 [==============================] - 0s 71us/sample - loss: 0.1807 - val_loss: 0.1880\n",
      "Epoch 26/100\n",
      "3646/3646 [==============================] - 0s 71us/sample - loss: 0.1797 - val_loss: 0.1868\n",
      "Epoch 27/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1788 - val_loss: 0.1859\n",
      "Epoch 28/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1779 - val_loss: 0.1852\n",
      "Epoch 29/100\n",
      "3646/3646 [==============================] - 0s 71us/sample - loss: 0.1771 - val_loss: 0.1844\n",
      "Epoch 30/100\n",
      "3646/3646 [==============================] - 0s 70us/sample - loss: 0.1762 - val_loss: 0.1834\n",
      "Epoch 31/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1757 - val_loss: 0.1828\n",
      "Epoch 32/100\n",
      "3646/3646 [==============================] - 0s 70us/sample - loss: 0.1749 - val_loss: 0.1821\n",
      "Epoch 33/100\n",
      "3646/3646 [==============================] - 0s 73us/sample - loss: 0.1743 - val_loss: 0.1817\n",
      "Epoch 34/100\n",
      "3646/3646 [==============================] - 0s 69us/sample - loss: 0.1736 - val_loss: 0.1808\n",
      "Epoch 35/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1732 - val_loss: 0.1804\n",
      "Epoch 36/100\n",
      "3646/3646 [==============================] - 0s 67us/sample - loss: 0.1726 - val_loss: 0.1799\n",
      "Epoch 37/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1721 - val_loss: 0.1794\n",
      "Epoch 38/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1717 - val_loss: 0.1789\n",
      "Epoch 39/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1713 - val_loss: 0.1785\n",
      "Epoch 40/100\n",
      "3646/3646 [==============================] - 0s 72us/sample - loss: 0.1708 - val_loss: 0.1782\n",
      "Epoch 41/100\n",
      "3646/3646 [==============================] - 0s 71us/sample - loss: 0.1704 - val_loss: 0.1777\n",
      "Epoch 42/100\n",
      "3646/3646 [==============================] - 0s 71us/sample - loss: 0.1701 - val_loss: 0.1773\n",
      "Epoch 43/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1697 - val_loss: 0.1770\n",
      "Epoch 44/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1694 - val_loss: 0.1769\n",
      "Epoch 45/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1691 - val_loss: 0.1764\n",
      "Epoch 46/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1688 - val_loss: 0.1761\n",
      "Epoch 47/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1685 - val_loss: 0.1758\n",
      "Epoch 48/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1682 - val_loss: 0.1757\n",
      "Epoch 49/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1680 - val_loss: 0.1755\n",
      "Epoch 50/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1677 - val_loss: 0.1753\n",
      "Epoch 51/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1674 - val_loss: 0.1747\n",
      "Epoch 52/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1672 - val_loss: 0.1747\n",
      "Epoch 53/100\n",
      "3646/3646 [==============================] - 0s 93us/sample - loss: 0.1670 - val_loss: 0.1743\n",
      "Epoch 54/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1667 - val_loss: 0.1740\n",
      "Epoch 55/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1666 - val_loss: 0.1741\n",
      "Epoch 56/100\n",
      "3646/3646 [==============================] - 0s 69us/sample - loss: 0.1663 - val_loss: 0.1736\n",
      "Epoch 57/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1662 - val_loss: 0.1735\n",
      "Epoch 58/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1660 - val_loss: 0.1736\n",
      "Epoch 59/100\n",
      "3646/3646 [==============================] - 0s 124us/sample - loss: 0.1658 - val_loss: 0.1735\n",
      "Epoch 60/100\n",
      "3646/3646 [==============================] - 0s 112us/sample - loss: 0.1656 - val_loss: 0.1732\n",
      "Epoch 61/100\n",
      "3646/3646 [==============================] - 0s 102us/sample - loss: 0.1654 - val_loss: 0.1729\n",
      "Epoch 62/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1652 - val_loss: 0.1730\n",
      "Epoch 63/100\n",
      "3646/3646 [==============================] - 0s 112us/sample - loss: 0.1651 - val_loss: 0.1727\n",
      "Epoch 64/100\n",
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1649 - val_loss: 0.1725\n",
      "Epoch 65/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1647 - val_loss: 0.1726\n",
      "Epoch 66/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1646 - val_loss: 0.1721\n",
      "Epoch 67/100\n",
      "3646/3646 [==============================] - 0s 90us/sample - loss: 0.1644 - val_loss: 0.1724\n",
      "Epoch 68/100\n",
      "3646/3646 [==============================] - 0s 101us/sample - loss: 0.1643 - val_loss: 0.1719\n",
      "Epoch 69/100\n",
      "3646/3646 [==============================] - 0s 114us/sample - loss: 0.1641 - val_loss: 0.1717\n",
      "Epoch 70/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1640 - val_loss: 0.1718\n",
      "Epoch 71/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1639 - val_loss: 0.1716\n",
      "Epoch 72/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1637 - val_loss: 0.1714\n",
      "Epoch 73/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.1636 - val_loss: 0.1712\n",
      "Epoch 74/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1635 - val_loss: 0.1711\n",
      "Epoch 75/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1633 - val_loss: 0.1711\n",
      "Epoch 76/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.1632 - val_loss: 0.1708\n",
      "Epoch 77/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1631 - val_loss: 0.1707\n",
      "Epoch 78/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1629 - val_loss: 0.1705\n",
      "Epoch 79/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1627 - val_loss: 0.1709\n",
      "Epoch 80/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1627 - val_loss: 0.1705\n",
      "Epoch 81/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1626 - val_loss: 0.1703\n",
      "Epoch 82/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1624 - val_loss: 0.1703\n",
      "Epoch 83/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1623 - val_loss: 0.1702\n",
      "Epoch 84/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1622 - val_loss: 0.1700\n",
      "Epoch 85/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1621 - val_loss: 0.1700\n",
      "Epoch 86/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1620 - val_loss: 0.1700\n",
      "Epoch 87/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1619 - val_loss: 0.1698\n",
      "Epoch 88/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1618 - val_loss: 0.1697\n",
      "Epoch 89/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1617 - val_loss: 0.1697\n",
      "Epoch 90/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1616 - val_loss: 0.1695\n",
      "Epoch 91/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1615 - val_loss: 0.1695\n",
      "Epoch 92/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1615 - val_loss: 0.1695\n",
      "Epoch 93/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1613 - val_loss: 0.1692\n",
      "Epoch 94/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1613 - val_loss: 0.1693\n",
      "Epoch 95/100\n",
      "3646/3646 [==============================] - 0s 73us/sample - loss: 0.1612 - val_loss: 0.1692\n",
      "Epoch 96/100\n",
      "3646/3646 [==============================] - 0s 71us/sample - loss: 0.1611 - val_loss: 0.1693\n",
      "Epoch 97/100\n",
      "3646/3646 [==============================] - 0s 72us/sample - loss: 0.1610 - val_loss: 0.1692\n",
      "Epoch 98/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1609 - val_loss: 0.1689\n",
      "Epoch 99/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1608 - val_loss: 0.1691\n",
      "Epoch 100/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1608 - val_loss: 0.1689\n",
      "1822/1822 [==============================] - 0s 37us/sample - loss: 0.1540\n",
      "[CV] END learning_rate=0.0008069828063751967, n_hidden=1, n_neurons=28; total time=  32.3s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 372us/sample - loss: 0.7577 - val_loss: 0.5005\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 52us/sample - loss: 0.4145 - val_loss: 0.3578\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 61us/sample - loss: 0.3111 - val_loss: 0.3022\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.2671 - val_loss: 0.2743\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.2433 - val_loss: 0.2567\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 66us/sample - loss: 0.2281 - val_loss: 0.2439\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.2168 - val_loss: 0.2335\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.2080 - val_loss: 0.2249\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.2007 - val_loss: 0.2173\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 64us/sample - loss: 0.1946 - val_loss: 0.2111\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 66us/sample - loss: 0.1895 - val_loss: 0.2051\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1851 - val_loss: 0.2006\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1812 - val_loss: 0.1961\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 63us/sample - loss: 0.1779 - val_loss: 0.1923\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1750 - val_loss: 0.1897\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 62us/sample - loss: 0.1727 - val_loss: 0.1868\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 56us/sample - loss: 0.1705 - val_loss: 0.1845\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 55us/sample - loss: 0.1686 - val_loss: 0.1822\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 48us/sample - loss: 0.1667 - val_loss: 0.1795\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 1s 170us/sample - loss: 0.1656 - val_loss: 0.1781\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 127us/sample - loss: 0.1642 - val_loss: 0.1767\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 54us/sample - loss: 0.1629 - val_loss: 0.1751\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 56us/sample - loss: 0.1621 - val_loss: 0.1739\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 48us/sample - loss: 0.1613 - val_loss: 0.1730\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 55us/sample - loss: 0.1606 - val_loss: 0.1724\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 61us/sample - loss: 0.1600 - val_loss: 0.1711\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 53us/sample - loss: 0.1593 - val_loss: 0.1708\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 54us/sample - loss: 0.1588 - val_loss: 0.1697\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 47us/sample - loss: 0.1585 - val_loss: 0.1698\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1581 - val_loss: 0.1691\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 54us/sample - loss: 0.1577 - val_loss: 0.1681\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 53us/sample - loss: 0.1575 - val_loss: 0.1681\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1572 - val_loss: 0.1677\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 64us/sample - loss: 0.1570 - val_loss: 0.1678\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 63us/sample - loss: 0.1567 - val_loss: 0.1673\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 66us/sample - loss: 0.1566 - val_loss: 0.1671\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 55us/sample - loss: 0.1563 - val_loss: 0.1666\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1561 - val_loss: 0.1677\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1561 - val_loss: 0.1663\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1559 - val_loss: 0.1661\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 58us/sample - loss: 0.1559 - val_loss: 0.1658\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 56us/sample - loss: 0.1559 - val_loss: 0.1663\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1558 - val_loss: 0.1662\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1557 - val_loss: 0.1655\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 62us/sample - loss: 0.1557 - val_loss: 0.1656\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 66us/sample - loss: 0.1554 - val_loss: 0.1666\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1557 - val_loss: 0.1655\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 65us/sample - loss: 0.1555 - val_loss: 0.1655\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 66us/sample - loss: 0.1555 - val_loss: 0.1651\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 63us/sample - loss: 0.1554 - val_loss: 0.1660\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 64us/sample - loss: 0.1555 - val_loss: 0.1656\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1555 - val_loss: 0.1658\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1553 - val_loss: 0.1654\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1554 - val_loss: 0.1654\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1553 - val_loss: 0.1651\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1553 - val_loss: 0.1653\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1553 - val_loss: 0.1655\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1554 - val_loss: 0.1653\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 67us/sample - loss: 0.1553 - val_loss: 0.1655\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1553 - val_loss: 0.1649\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1553 - val_loss: 0.1651\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1554 - val_loss: 0.1654\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1553 - val_loss: 0.1647\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 67us/sample - loss: 0.1553 - val_loss: 0.1649\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1553 - val_loss: 0.1654\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1551 - val_loss: 0.1657\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1554 - val_loss: 0.1653\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1552 - val_loss: 0.1658\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1553 - val_loss: 0.1653\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1553 - val_loss: 0.1657\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1553 - val_loss: 0.1650\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1551 - val_loss: 0.1646\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1553 - val_loss: 0.1651\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1551 - val_loss: 0.1651\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 125us/sample - loss: 0.1552 - val_loss: 0.1647\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1553 - val_loss: 0.1652\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 63us/sample - loss: 0.1553 - val_loss: 0.1653\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 130us/sample - loss: 0.1552 - val_loss: 0.1653\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1553 - val_loss: 0.1647\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 56us/sample - loss: 0.1553 - val_loss: 0.1650\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 61us/sample - loss: 0.1553 - val_loss: 0.1648\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1553 - val_loss: 0.1646\n",
      "1823/1823 [==============================] - 0s 25us/sample - loss: 0.1656\n",
      "[CV] END learning_rate=0.003003562846529704, n_hidden=0, n_neurons=31; total time=  23.2s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 158us/sample - loss: 0.9010 - val_loss: 0.4077\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.3210 - val_loss: 0.3212\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 66us/sample - loss: 0.2730 - val_loss: 0.2905\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.2511 - val_loss: 0.2702\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 56us/sample - loss: 0.2352 - val_loss: 0.2548\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 54us/sample - loss: 0.2234 - val_loss: 0.2409\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 60us/sample - loss: 0.2132 - val_loss: 0.2303\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 62us/sample - loss: 0.2052 - val_loss: 0.2210\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 65us/sample - loss: 0.1986 - val_loss: 0.2132\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 55us/sample - loss: 0.1928 - val_loss: 0.2068\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 54us/sample - loss: 0.1878 - val_loss: 0.2020\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 60us/sample - loss: 0.1838 - val_loss: 0.1967\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 55us/sample - loss: 0.1804 - val_loss: 0.1928\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 52us/sample - loss: 0.1776 - val_loss: 0.1894\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 67us/sample - loss: 0.1750 - val_loss: 0.1865\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.1729 - val_loss: 0.1837\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.1711 - val_loss: 0.1818\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 56us/sample - loss: 0.1695 - val_loss: 0.1793\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 55us/sample - loss: 0.1681 - val_loss: 0.1779\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 64us/sample - loss: 0.1669 - val_loss: 0.1763\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 60us/sample - loss: 0.1657 - val_loss: 0.1749\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1650 - val_loss: 0.1739\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1641 - val_loss: 0.1728\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.1635 - val_loss: 0.1718\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 61us/sample - loss: 0.1629 - val_loss: 0.1710\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1624 - val_loss: 0.1703\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 67us/sample - loss: 0.1621 - val_loss: 0.1697\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 54us/sample - loss: 0.1616 - val_loss: 0.1697\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 60us/sample - loss: 0.1613 - val_loss: 0.1688\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1610 - val_loss: 0.1683\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1607 - val_loss: 0.1681\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1605 - val_loss: 0.1676\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 52us/sample - loss: 0.1600 - val_loss: 0.1687\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 50us/sample - loss: 0.1603 - val_loss: 0.1672\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 56us/sample - loss: 0.1600 - val_loss: 0.1670\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 51us/sample - loss: 0.1599 - val_loss: 0.1667\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1598 - val_loss: 0.1666\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 53us/sample - loss: 0.1597 - val_loss: 0.1663\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 51us/sample - loss: 0.1596 - val_loss: 0.1666\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 60us/sample - loss: 0.1594 - val_loss: 0.1664\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 51us/sample - loss: 0.1595 - val_loss: 0.1666\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 53us/sample - loss: 0.1594 - val_loss: 0.1660\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 51us/sample - loss: 0.1593 - val_loss: 0.1657\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 51us/sample - loss: 0.1592 - val_loss: 0.1662\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 50us/sample - loss: 0.1593 - val_loss: 0.1661\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 67us/sample - loss: 0.1592 - val_loss: 0.1655\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1592 - val_loss: 0.1654\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 64us/sample - loss: 0.1591 - val_loss: 0.1654\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 66us/sample - loss: 0.1593 - val_loss: 0.1653\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1591 - val_loss: 0.1657\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 66us/sample - loss: 0.1591 - val_loss: 0.1656\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 63us/sample - loss: 0.1591 - val_loss: 0.1652\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1591 - val_loss: 0.1654\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 66us/sample - loss: 0.1590 - val_loss: 0.1662\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 67us/sample - loss: 0.1591 - val_loss: 0.1651\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 67us/sample - loss: 0.1589 - val_loss: 0.1660\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1589 - val_loss: 0.1652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 62us/sample - loss: 0.1591 - val_loss: 0.1651\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1590 - val_loss: 0.1655\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1590 - val_loss: 0.1653\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1590 - val_loss: 0.1650\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 52us/sample - loss: 0.1590 - val_loss: 0.1649\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 56us/sample - loss: 0.1591 - val_loss: 0.1654\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 51us/sample - loss: 0.1590 - val_loss: 0.1651\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 48us/sample - loss: 0.1590 - val_loss: 0.1652\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 48us/sample - loss: 0.1590 - val_loss: 0.1653\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 50us/sample - loss: 0.1590 - val_loss: 0.1654\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 55us/sample - loss: 0.1589 - val_loss: 0.1649\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 49us/sample - loss: 0.1591 - val_loss: 0.1649\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 48us/sample - loss: 0.1590 - val_loss: 0.1652\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1588 - val_loss: 0.1649\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 49us/sample - loss: 0.1589 - val_loss: 0.1658\n",
      "1823/1823 [==============================] - 0s 21us/sample - loss: 0.1586\n",
      "[CV] END learning_rate=0.003003562846529704, n_hidden=0, n_neurons=31; total time=  16.7s\n",
      "Train on 3646 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3646/3646 [==============================] - 1s 158us/sample - loss: 0.9368 - val_loss: 0.5019\n",
      "Epoch 2/100\n",
      "3646/3646 [==============================] - 0s 53us/sample - loss: 0.3868 - val_loss: 0.3262\n",
      "Epoch 3/100\n",
      "3646/3646 [==============================] - 1s 163us/sample - loss: 0.2829 - val_loss: 0.2681\n",
      "Epoch 4/100\n",
      "3646/3646 [==============================] - 1s 319us/sample - loss: 0.2428 - val_loss: 0.2409\n",
      "Epoch 5/100\n",
      "3646/3646 [==============================] - 0s 129us/sample - loss: 0.2216 - val_loss: 0.2232\n",
      "Epoch 6/100\n",
      "3646/3646 [==============================] - 1s 160us/sample - loss: 0.2076 - val_loss: 0.2112\n",
      "Epoch 7/100\n",
      "3646/3646 [==============================] - 1s 146us/sample - loss: 0.1979 - val_loss: 0.2024\n",
      "Epoch 8/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1905 - val_loss: 0.1958\n",
      "Epoch 9/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1849 - val_loss: 0.1911\n",
      "Epoch 10/100\n",
      "3646/3646 [==============================] - 0s 57us/sample - loss: 0.1807 - val_loss: 0.1860\n",
      "Epoch 11/100\n",
      "3646/3646 [==============================] - 0s 48us/sample - loss: 0.1773 - val_loss: 0.1831\n",
      "Epoch 12/100\n",
      "3646/3646 [==============================] - 0s 55us/sample - loss: 0.1747 - val_loss: 0.1804\n",
      "Epoch 13/100\n",
      "3646/3646 [==============================] - 0s 51us/sample - loss: 0.1725 - val_loss: 0.1778\n",
      "Epoch 14/100\n",
      "3646/3646 [==============================] - 0s 70us/sample - loss: 0.1707 - val_loss: 0.1765\n",
      "Epoch 15/100\n",
      "3646/3646 [==============================] - 0s 54us/sample - loss: 0.1694 - val_loss: 0.1748\n",
      "Epoch 16/100\n",
      "3646/3646 [==============================] - 0s 52us/sample - loss: 0.1680 - val_loss: 0.1730\n",
      "Epoch 17/100\n",
      "3646/3646 [==============================] - 0s 48us/sample - loss: 0.1672 - val_loss: 0.1722\n",
      "Epoch 18/100\n",
      "3646/3646 [==============================] - 0s 51us/sample - loss: 0.1665 - val_loss: 0.1711\n",
      "Epoch 19/100\n",
      "3646/3646 [==============================] - 0s 52us/sample - loss: 0.1658 - val_loss: 0.1703\n",
      "Epoch 20/100\n",
      "3646/3646 [==============================] - 0s 58us/sample - loss: 0.1651 - val_loss: 0.1696\n",
      "Epoch 21/100\n",
      "3646/3646 [==============================] - 0s 44us/sample - loss: 0.1646 - val_loss: 0.1692\n",
      "Epoch 22/100\n",
      "3646/3646 [==============================] - 0s 45us/sample - loss: 0.1644 - val_loss: 0.1686\n",
      "Epoch 23/100\n",
      "3646/3646 [==============================] - 0s 43us/sample - loss: 0.1642 - val_loss: 0.1682\n",
      "Epoch 24/100\n",
      "3646/3646 [==============================] - 0s 44us/sample - loss: 0.1638 - val_loss: 0.1680\n",
      "Epoch 25/100\n",
      "3646/3646 [==============================] - 0s 47us/sample - loss: 0.1634 - val_loss: 0.1675\n",
      "Epoch 26/100\n",
      "3646/3646 [==============================] - 0s 60us/sample - loss: 0.1633 - val_loss: 0.1673\n",
      "Epoch 27/100\n",
      "3646/3646 [==============================] - 0s 49us/sample - loss: 0.1632 - val_loss: 0.1669\n",
      "Epoch 28/100\n",
      "3646/3646 [==============================] - 0s 45us/sample - loss: 0.1630 - val_loss: 0.1667\n",
      "Epoch 29/100\n",
      "3646/3646 [==============================] - 0s 44us/sample - loss: 0.1629 - val_loss: 0.1666\n",
      "Epoch 30/100\n",
      "3646/3646 [==============================] - 0s 47us/sample - loss: 0.1627 - val_loss: 0.1669\n",
      "Epoch 31/100\n",
      "3646/3646 [==============================] - 0s 47us/sample - loss: 0.1627 - val_loss: 0.1668\n",
      "Epoch 32/100\n",
      "3646/3646 [==============================] - 0s 53us/sample - loss: 0.1626 - val_loss: 0.1661\n",
      "Epoch 33/100\n",
      "3646/3646 [==============================] - 0s 45us/sample - loss: 0.1624 - val_loss: 0.1660\n",
      "Epoch 34/100\n",
      "3646/3646 [==============================] - 0s 46us/sample - loss: 0.1623 - val_loss: 0.1660\n",
      "Epoch 35/100\n",
      "3646/3646 [==============================] - 0s 44us/sample - loss: 0.1623 - val_loss: 0.1657\n",
      "Epoch 36/100\n",
      "3646/3646 [==============================] - 0s 43us/sample - loss: 0.1623 - val_loss: 0.1662\n",
      "Epoch 37/100\n",
      "3646/3646 [==============================] - 0s 60us/sample - loss: 0.1623 - val_loss: 0.1659\n",
      "Epoch 38/100\n",
      "3646/3646 [==============================] - 0s 71us/sample - loss: 0.1621 - val_loss: 0.1655\n",
      "Epoch 39/100\n",
      "3646/3646 [==============================] - 0s 67us/sample - loss: 0.1621 - val_loss: 0.1654\n",
      "Epoch 40/100\n",
      "3646/3646 [==============================] - 0s 72us/sample - loss: 0.1623 - val_loss: 0.1654\n",
      "Epoch 41/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1622 - val_loss: 0.1656\n",
      "Epoch 42/100\n",
      "3646/3646 [==============================] - 0s 102us/sample - loss: 0.1621 - val_loss: 0.1652\n",
      "Epoch 43/100\n",
      "3646/3646 [==============================] - 1s 155us/sample - loss: 0.1621 - val_loss: 0.1659\n",
      "Epoch 44/100\n",
      "3646/3646 [==============================] - 0s 137us/sample - loss: 0.1620 - val_loss: 0.1651\n",
      "Epoch 45/100\n",
      "3646/3646 [==============================] - 0s 72us/sample - loss: 0.1622 - val_loss: 0.1652\n",
      "Epoch 46/100\n",
      "3646/3646 [==============================] - 0s 71us/sample - loss: 0.1621 - val_loss: 0.1654\n",
      "Epoch 47/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1620 - val_loss: 0.1660\n",
      "Epoch 48/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1621 - val_loss: 0.1650\n",
      "Epoch 49/100\n",
      "3646/3646 [==============================] - 0s 73us/sample - loss: 0.1621 - val_loss: 0.1651\n",
      "Epoch 50/100\n",
      "3646/3646 [==============================] - 0s 63us/sample - loss: 0.1620 - val_loss: 0.1650\n",
      "Epoch 51/100\n",
      "3646/3646 [==============================] - 0s 50us/sample - loss: 0.1621 - val_loss: 0.1651\n",
      "Epoch 52/100\n",
      "3646/3646 [==============================] - 0s 57us/sample - loss: 0.1620 - val_loss: 0.1652\n",
      "Epoch 53/100\n",
      "3646/3646 [==============================] - 0s 66us/sample - loss: 0.1619 - val_loss: 0.1655\n",
      "Epoch 54/100\n",
      "3646/3646 [==============================] - 0s 47us/sample - loss: 0.1620 - val_loss: 0.1651\n",
      "Epoch 55/100\n",
      "3646/3646 [==============================] - 0s 60us/sample - loss: 0.1618 - val_loss: 0.1654\n",
      "Epoch 56/100\n",
      "3646/3646 [==============================] - 0s 48us/sample - loss: 0.1620 - val_loss: 0.1650\n",
      "Epoch 57/100\n",
      "3646/3646 [==============================] - 0s 51us/sample - loss: 0.1621 - val_loss: 0.1653\n",
      "Epoch 58/100\n",
      "3646/3646 [==============================] - 0s 57us/sample - loss: 0.1620 - val_loss: 0.1649\n",
      "Epoch 59/100\n",
      "3646/3646 [==============================] - 0s 61us/sample - loss: 0.1620 - val_loss: 0.1656\n",
      "Epoch 60/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.1620 - val_loss: 0.1651\n",
      "Epoch 61/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1620 - val_loss: 0.1649\n",
      "Epoch 62/100\n",
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1621 - val_loss: 0.1652\n",
      "Epoch 63/100\n",
      "3646/3646 [==============================] - 1s 152us/sample - loss: 0.1621 - val_loss: 0.1650\n",
      "Epoch 64/100\n",
      "3646/3646 [==============================] - 0s 127us/sample - loss: 0.1619 - val_loss: 0.1655\n",
      "Epoch 65/100\n",
      "3646/3646 [==============================] - 0s 97us/sample - loss: 0.1620 - val_loss: 0.1654\n",
      "Epoch 66/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1620 - val_loss: 0.1654\n",
      "Epoch 67/100\n",
      "3646/3646 [==============================] - 0s 110us/sample - loss: 0.1620 - val_loss: 0.1648\n",
      "Epoch 68/100\n",
      "3646/3646 [==============================] - 0s 73us/sample - loss: 0.1620 - val_loss: 0.1652\n",
      "Epoch 69/100\n",
      "3646/3646 [==============================] - 0s 50us/sample - loss: 0.1621 - val_loss: 0.1653\n",
      "Epoch 70/100\n",
      "3646/3646 [==============================] - 0s 62us/sample - loss: 0.1620 - val_loss: 0.1652\n",
      "Epoch 71/100\n",
      "3646/3646 [==============================] - 0s 52us/sample - loss: 0.1620 - val_loss: 0.1654\n",
      "Epoch 72/100\n",
      "3646/3646 [==============================] - 0s 62us/sample - loss: 0.1620 - val_loss: 0.1651\n",
      "Epoch 73/100\n",
      "3646/3646 [==============================] - 0s 50us/sample - loss: 0.1620 - val_loss: 0.1648\n",
      "Epoch 74/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1620 - val_loss: 0.1652\n",
      "Epoch 75/100\n",
      "3646/3646 [==============================] - 0s 73us/sample - loss: 0.1620 - val_loss: 0.1650\n",
      "Epoch 76/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1620 - val_loss: 0.1647\n",
      "Epoch 77/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1621 - val_loss: 0.1648\n",
      "Epoch 78/100\n",
      "3646/3646 [==============================] - 0s 122us/sample - loss: 0.1621 - val_loss: 0.1651\n",
      "Epoch 79/100\n",
      "3646/3646 [==============================] - 0s 93us/sample - loss: 0.1621 - val_loss: 0.1650\n",
      "Epoch 80/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1620 - val_loss: 0.1655\n",
      "Epoch 81/100\n",
      "3646/3646 [==============================] - 0s 101us/sample - loss: 0.1620 - val_loss: 0.1657\n",
      "Epoch 82/100\n",
      "3646/3646 [==============================] - 0s 117us/sample - loss: 0.1620 - val_loss: 0.1648\n",
      "Epoch 83/100\n",
      "3646/3646 [==============================] - 0s 50us/sample - loss: 0.1620 - val_loss: 0.1651\n",
      "Epoch 84/100\n",
      "3646/3646 [==============================] - 0s 44us/sample - loss: 0.1620 - val_loss: 0.1649\n",
      "Epoch 85/100\n",
      "3646/3646 [==============================] - 0s 45us/sample - loss: 0.1620 - val_loss: 0.1648\n",
      "Epoch 86/100\n",
      "3646/3646 [==============================] - 0s 48us/sample - loss: 0.1620 - val_loss: 0.1648\n",
      "1822/1822 [==============================] - 0s 19us/sample - loss: 0.1528\n",
      "[CV] END learning_rate=0.003003562846529704, n_hidden=0, n_neurons=31; total time=  24.1s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 257us/sample - loss: 0.4298 - val_loss: 0.3216\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.3009 - val_loss: 0.2740\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.2604 - val_loss: 0.2471\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.2351 - val_loss: 0.2286\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.2174 - val_loss: 0.2152\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 132us/sample - loss: 0.2041 - val_loss: 0.2048\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1939 - val_loss: 0.1971\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 123us/sample - loss: 0.1861 - val_loss: 0.1909\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1803 - val_loss: 0.1865\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1759 - val_loss: 0.1828\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1726 - val_loss: 0.1803\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1700 - val_loss: 0.1782\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 126us/sample - loss: 0.1680 - val_loss: 0.1765\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1665 - val_loss: 0.1751\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1652 - val_loss: 0.1745\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1642 - val_loss: 0.1733\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1633 - val_loss: 0.1727\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1625 - val_loss: 0.1715\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 1s 176us/sample - loss: 0.1619 - val_loss: 0.1711\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 1s 146us/sample - loss: 0.1613 - val_loss: 0.1703\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1607 - val_loss: 0.1704\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1603 - val_loss: 0.1695\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1598 - val_loss: 0.1695\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1595 - val_loss: 0.1687\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 1s 138us/sample - loss: 0.1590 - val_loss: 0.1681\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 1s 219us/sample - loss: 0.1586 - val_loss: 0.1679\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1582 - val_loss: 0.1673\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1579 - val_loss: 0.1674\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1576 - val_loss: 0.1670\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1573 - val_loss: 0.1665\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1571 - val_loss: 0.1664\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1568 - val_loss: 0.1659\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 1s 148us/sample - loss: 0.1565 - val_loss: 0.1657\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 1s 150us/sample - loss: 0.1562 - val_loss: 0.1655\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1560 - val_loss: 0.1653\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1558 - val_loss: 0.1651\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1556 - val_loss: 0.1648\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1553 - val_loss: 0.1652\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1552 - val_loss: 0.1645\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 1s 178us/sample - loss: 0.1550 - val_loss: 0.1646\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1548 - val_loss: 0.1645\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1546 - val_loss: 0.1644\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1544 - val_loss: 0.1638\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1543 - val_loss: 0.1635\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1540 - val_loss: 0.1643\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1539 - val_loss: 0.1633\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 115us/sample - loss: 0.1538 - val_loss: 0.1632\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1537 - val_loss: 0.1633\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 120us/sample - loss: 0.1535 - val_loss: 0.1632\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1534 - val_loss: 0.1631\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1532 - val_loss: 0.1628\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.1531 - val_loss: 0.1630\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1530 - val_loss: 0.1627\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1528 - val_loss: 0.1625\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 115us/sample - loss: 0.1527 - val_loss: 0.1627\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1525 - val_loss: 0.1623\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1524 - val_loss: 0.1626\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1524 - val_loss: 0.1622\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1522 - val_loss: 0.1622\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 1s 158us/sample - loss: 0.1521 - val_loss: 0.1617\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1521 - val_loss: 0.1619\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1519 - val_loss: 0.1620\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1518 - val_loss: 0.1617\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1516 - val_loss: 0.1620\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1516 - val_loss: 0.1615\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1515 - val_loss: 0.1613\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1514 - val_loss: 0.1613\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1513 - val_loss: 0.1611\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1512 - val_loss: 0.1611\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 119us/sample - loss: 0.1511 - val_loss: 0.1610\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1509 - val_loss: 0.1608\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1508 - val_loss: 0.1607\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1508 - val_loss: 0.1608\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1506 - val_loss: 0.1609\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1505 - val_loss: 0.1606\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1504 - val_loss: 0.1607\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1503 - val_loss: 0.1603\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 126us/sample - loss: 0.1503 - val_loss: 0.1604\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1502 - val_loss: 0.1602\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 131us/sample - loss: 0.1500 - val_loss: 0.1602\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 1s 156us/sample - loss: 0.1499 - val_loss: 0.1603\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 124us/sample - loss: 0.1499 - val_loss: 0.1602\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1497 - val_loss: 0.1601\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1496 - val_loss: 0.1599\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 1s 142us/sample - loss: 0.1496 - val_loss: 0.1598\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 118us/sample - loss: 0.1495 - val_loss: 0.1599\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 120us/sample - loss: 0.1494 - val_loss: 0.1598\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 115us/sample - loss: 0.1493 - val_loss: 0.1597\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 130us/sample - loss: 0.1491 - val_loss: 0.1603\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1492 - val_loss: 0.1597\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1491 - val_loss: 0.1597\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1489 - val_loss: 0.1593\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 115us/sample - loss: 0.1489 - val_loss: 0.1594\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1488 - val_loss: 0.1592\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1488 - val_loss: 0.1594\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 119us/sample - loss: 0.1487 - val_loss: 0.1591\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1486 - val_loss: 0.1590\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 112us/sample - loss: 0.1485 - val_loss: 0.1593\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1483 - val_loss: 0.1588\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1484 - val_loss: 0.1592\n",
      "1823/1823 [==============================] - 0s 35us/sample - loss: 0.1596\n",
      "[CV] END learning_rate=0.0008265454655262932, n_hidden=3, n_neurons=57; total time=  40.2s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 305us/sample - loss: 0.2486 - val_loss: 0.2331\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 130us/sample - loss: 0.2136 - val_loss: 0.2162\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.2007 - val_loss: 0.2065\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1922 - val_loss: 0.1993\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1860 - val_loss: 0.1938\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 1s 144us/sample - loss: 0.1810 - val_loss: 0.1896\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 1s 235us/sample - loss: 0.1773 - val_loss: 0.1863\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1744 - val_loss: 0.1837\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1721 - val_loss: 0.1816\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1702 - val_loss: 0.1798\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1686 - val_loss: 0.1783\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 134us/sample - loss: 0.1673 - val_loss: 0.1771\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1661 - val_loss: 0.1759\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 119us/sample - loss: 0.1651 - val_loss: 0.1749\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1643 - val_loss: 0.1740\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1636 - val_loss: 0.1732\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1629 - val_loss: 0.1725\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1623 - val_loss: 0.1718\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1617 - val_loss: 0.1712\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 1s 261us/sample - loss: 0.1613 - val_loss: 0.1706\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 128us/sample - loss: 0.1608 - val_loss: 0.1701\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.1604 - val_loss: 0.1696\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 123us/sample - loss: 0.1600 - val_loss: 0.1691\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 119us/sample - loss: 0.1596 - val_loss: 0.1689\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1593 - val_loss: 0.1683\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1590 - val_loss: 0.1679\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 119us/sample - loss: 0.1586 - val_loss: 0.1675\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1584 - val_loss: 0.1672\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1581 - val_loss: 0.1669\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1577 - val_loss: 0.1667\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1575 - val_loss: 0.1662\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1573 - val_loss: 0.1659\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1570 - val_loss: 0.1657\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1568 - val_loss: 0.1655\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1566 - val_loss: 0.1653\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1564 - val_loss: 0.1650\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1561 - val_loss: 0.1649\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1560 - val_loss: 0.1646\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.1558 - val_loss: 0.1643\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 120us/sample - loss: 0.1556 - val_loss: 0.1641\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 115us/sample - loss: 0.1555 - val_loss: 0.1640\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1552 - val_loss: 0.1639\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1551 - val_loss: 0.1636\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1550 - val_loss: 0.1634\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1548 - val_loss: 0.1632\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1547 - val_loss: 0.1631\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1544 - val_loss: 0.1630\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1543 - val_loss: 0.1628\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1542 - val_loss: 0.1627\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1540 - val_loss: 0.1625\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1539 - val_loss: 0.1623\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1537 - val_loss: 0.1621\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1536 - val_loss: 0.1621\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1535 - val_loss: 0.1619\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1533 - val_loss: 0.1618\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1532 - val_loss: 0.1617\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1531 - val_loss: 0.1616\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 119us/sample - loss: 0.1530 - val_loss: 0.1613\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1529 - val_loss: 0.1613\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 115us/sample - loss: 0.1527 - val_loss: 0.1611\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1526 - val_loss: 0.1610\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 121us/sample - loss: 0.1525 - val_loss: 0.1609\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 1s 149us/sample - loss: 0.1524 - val_loss: 0.1608\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 132us/sample - loss: 0.1523 - val_loss: 0.1607\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 117us/sample - loss: 0.1522 - val_loss: 0.1606\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.1520 - val_loss: 0.1606\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 1s 236us/sample - loss: 0.1519 - val_loss: 0.1604\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 137us/sample - loss: 0.1518 - val_loss: 0.1605\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 1s 188us/sample - loss: 0.1517 - val_loss: 0.1602\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1516 - val_loss: 0.1602\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 131us/sample - loss: 0.1515 - val_loss: 0.1602\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1514 - val_loss: 0.1600\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1513 - val_loss: 0.1599\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 1s 208us/sample - loss: 0.1512 - val_loss: 0.1598\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 130us/sample - loss: 0.1511 - val_loss: 0.1597\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 115us/sample - loss: 0.1510 - val_loss: 0.1597\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1510 - val_loss: 0.1596\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.1508 - val_loss: 0.1596\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1508 - val_loss: 0.1594\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1507 - val_loss: 0.1594\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1506 - val_loss: 0.1592\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 126us/sample - loss: 0.1505 - val_loss: 0.1592\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1504 - val_loss: 0.1591\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 127us/sample - loss: 0.1504 - val_loss: 0.1590\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1503 - val_loss: 0.1589\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1502 - val_loss: 0.1589\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.1501 - val_loss: 0.1588\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1500 - val_loss: 0.1588\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1500 - val_loss: 0.1587\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1498 - val_loss: 0.1588\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1498 - val_loss: 0.1586\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1497 - val_loss: 0.1585\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1496 - val_loss: 0.1586\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1496 - val_loss: 0.1583\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1495 - val_loss: 0.1582\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1495 - val_loss: 0.1582\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1494 - val_loss: 0.1582\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1493 - val_loss: 0.1581\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1492 - val_loss: 0.1580\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1492 - val_loss: 0.1580\n",
      "1823/1823 [==============================] - 0s 32us/sample - loss: 0.1498\n",
      "[CV] END learning_rate=0.0008265454655262932, n_hidden=3, n_neurons=57; total time=  41.2s\n",
      "Train on 3646 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3646/3646 [==============================] - 1s 270us/sample - loss: 0.4064 - val_loss: 0.3213\n",
      "Epoch 2/100\n",
      "3646/3646 [==============================] - 0s 105us/sample - loss: 0.2896 - val_loss: 0.2713\n",
      "Epoch 3/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.2553 - val_loss: 0.2465\n",
      "Epoch 4/100\n",
      "3646/3646 [==============================] - 0s 93us/sample - loss: 0.2345 - val_loss: 0.2293\n",
      "Epoch 5/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.2193 - val_loss: 0.2165\n",
      "Epoch 6/100\n",
      "3646/3646 [==============================] - 0s 104us/sample - loss: 0.2078 - val_loss: 0.2068\n",
      "Epoch 7/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1990 - val_loss: 0.1994\n",
      "Epoch 8/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1923 - val_loss: 0.1938\n",
      "Epoch 9/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1871 - val_loss: 0.1895\n",
      "Epoch 10/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1831 - val_loss: 0.1861\n",
      "Epoch 11/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1800 - val_loss: 0.1836\n",
      "Epoch 12/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1776 - val_loss: 0.1815\n",
      "Epoch 13/100\n",
      "3646/3646 [==============================] - 0s 108us/sample - loss: 0.1756 - val_loss: 0.1799\n",
      "Epoch 14/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1740 - val_loss: 0.1784\n",
      "Epoch 15/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1727 - val_loss: 0.1772\n",
      "Epoch 16/100\n",
      "3646/3646 [==============================] - 0s 97us/sample - loss: 0.1715 - val_loss: 0.1761\n",
      "Epoch 17/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1705 - val_loss: 0.1751\n",
      "Epoch 18/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1697 - val_loss: 0.1743\n",
      "Epoch 19/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1689 - val_loss: 0.1737\n",
      "Epoch 20/100\n",
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1682 - val_loss: 0.1729\n",
      "Epoch 21/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1676 - val_loss: 0.1723\n",
      "Epoch 22/100\n",
      "3646/3646 [==============================] - 0s 101us/sample - loss: 0.1670 - val_loss: 0.1717\n",
      "Epoch 23/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1665 - val_loss: 0.1712\n",
      "Epoch 24/100\n",
      "3646/3646 [==============================] - 0s 104us/sample - loss: 0.1660 - val_loss: 0.1708\n",
      "Epoch 25/100\n",
      "3646/3646 [==============================] - 0s 116us/sample - loss: 0.1655 - val_loss: 0.1702\n",
      "Epoch 26/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.1650 - val_loss: 0.1699\n",
      "Epoch 27/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1646 - val_loss: 0.1695\n",
      "Epoch 28/100\n",
      "3646/3646 [==============================] - 0s 129us/sample - loss: 0.1642 - val_loss: 0.1689\n",
      "Epoch 29/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1638 - val_loss: 0.1686\n",
      "Epoch 30/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.1634 - val_loss: 0.1682\n",
      "Epoch 31/100\n",
      "3646/3646 [==============================] - 0s 105us/sample - loss: 0.1630 - val_loss: 0.1678\n",
      "Epoch 32/100\n",
      "3646/3646 [==============================] - 0s 107us/sample - loss: 0.1627 - val_loss: 0.1675\n",
      "Epoch 33/100\n",
      "3646/3646 [==============================] - 1s 145us/sample - loss: 0.1624 - val_loss: 0.1671\n",
      "Epoch 34/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1621 - val_loss: 0.1668\n",
      "Epoch 35/100\n",
      "3646/3646 [==============================] - 0s 107us/sample - loss: 0.1617 - val_loss: 0.1665\n",
      "Epoch 36/100\n",
      "3646/3646 [==============================] - 0s 135us/sample - loss: 0.1614 - val_loss: 0.1662\n",
      "Epoch 37/100\n",
      "3646/3646 [==============================] - 0s 93us/sample - loss: 0.1611 - val_loss: 0.1659\n",
      "Epoch 38/100\n",
      "3646/3646 [==============================] - 0s 90us/sample - loss: 0.1608 - val_loss: 0.1657\n",
      "Epoch 39/100\n",
      "3646/3646 [==============================] - 0s 90us/sample - loss: 0.1606 - val_loss: 0.1654\n",
      "Epoch 40/100\n",
      "3646/3646 [==============================] - 0s 109us/sample - loss: 0.1604 - val_loss: 0.1651\n",
      "Epoch 41/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1601 - val_loss: 0.1649\n",
      "Epoch 42/100\n",
      "3646/3646 [==============================] - 0s 101us/sample - loss: 0.1599 - val_loss: 0.1646\n",
      "Epoch 43/100\n",
      "3646/3646 [==============================] - 0s 103us/sample - loss: 0.1597 - val_loss: 0.1645\n",
      "Epoch 44/100\n",
      "3646/3646 [==============================] - 0s 133us/sample - loss: 0.1594 - val_loss: 0.1643\n",
      "Epoch 45/100\n",
      "3646/3646 [==============================] - 0s 117us/sample - loss: 0.1593 - val_loss: 0.1640\n",
      "Epoch 46/100\n",
      "3646/3646 [==============================] - 1s 208us/sample - loss: 0.1590 - val_loss: 0.1638\n",
      "Epoch 47/100\n",
      "3646/3646 [==============================] - 0s 130us/sample - loss: 0.1588 - val_loss: 0.1637\n",
      "Epoch 48/100\n",
      "3646/3646 [==============================] - 1s 142us/sample - loss: 0.1587 - val_loss: 0.1635\n",
      "Epoch 49/100\n",
      "3646/3646 [==============================] - 0s 134us/sample - loss: 0.1585 - val_loss: 0.1633\n",
      "Epoch 50/100\n",
      "3646/3646 [==============================] - 0s 114us/sample - loss: 0.1583 - val_loss: 0.1631\n",
      "Epoch 51/100\n",
      "3646/3646 [==============================] - 0s 121us/sample - loss: 0.1581 - val_loss: 0.1629\n",
      "Epoch 52/100\n",
      "3646/3646 [==============================] - 0s 120us/sample - loss: 0.1579 - val_loss: 0.1628\n",
      "Epoch 53/100\n",
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1578 - val_loss: 0.1626\n",
      "Epoch 54/100\n",
      "3646/3646 [==============================] - 1s 141us/sample - loss: 0.1576 - val_loss: 0.1625\n",
      "Epoch 55/100\n",
      "3646/3646 [==============================] - 1s 141us/sample - loss: 0.1574 - val_loss: 0.1624\n",
      "Epoch 56/100\n",
      "3646/3646 [==============================] - 1s 155us/sample - loss: 0.1572 - val_loss: 0.1621\n",
      "Epoch 57/100\n",
      "3646/3646 [==============================] - 0s 97us/sample - loss: 0.1571 - val_loss: 0.1620\n",
      "Epoch 58/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1570 - val_loss: 0.1618\n",
      "Epoch 59/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1568 - val_loss: 0.1618\n",
      "Epoch 60/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1567 - val_loss: 0.1616\n",
      "Epoch 61/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1565 - val_loss: 0.1616\n",
      "Epoch 62/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1564 - val_loss: 0.1614\n",
      "Epoch 63/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1562 - val_loss: 0.1612\n",
      "Epoch 64/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1561 - val_loss: 0.1611\n",
      "Epoch 65/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1559 - val_loss: 0.1610\n",
      "Epoch 66/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.1558 - val_loss: 0.1608\n",
      "Epoch 67/100\n",
      "3646/3646 [==============================] - 1s 139us/sample - loss: 0.1556 - val_loss: 0.1607\n",
      "Epoch 68/100\n",
      "3646/3646 [==============================] - 0s 124us/sample - loss: 0.1555 - val_loss: 0.1607\n",
      "Epoch 69/100\n",
      "3646/3646 [==============================] - 0s 103us/sample - loss: 0.1554 - val_loss: 0.1605\n",
      "Epoch 70/100\n",
      "3646/3646 [==============================] - 0s 129us/sample - loss: 0.1552 - val_loss: 0.1604\n",
      "Epoch 71/100\n",
      "3646/3646 [==============================] - 0s 124us/sample - loss: 0.1551 - val_loss: 0.1604\n",
      "Epoch 72/100\n",
      "3646/3646 [==============================] - 0s 113us/sample - loss: 0.1550 - val_loss: 0.1602\n",
      "Epoch 73/100\n",
      "3646/3646 [==============================] - 0s 102us/sample - loss: 0.1548 - val_loss: 0.1600\n",
      "Epoch 74/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1547 - val_loss: 0.1600\n",
      "Epoch 75/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1546 - val_loss: 0.1599\n",
      "Epoch 76/100\n",
      "3646/3646 [==============================] - 0s 102us/sample - loss: 0.1545 - val_loss: 0.1598\n",
      "Epoch 77/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1543 - val_loss: 0.1596\n",
      "Epoch 78/100\n",
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1542 - val_loss: 0.1595\n",
      "Epoch 79/100\n",
      "3646/3646 [==============================] - 0s 93us/sample - loss: 0.1541 - val_loss: 0.1595\n",
      "Epoch 80/100\n",
      "3646/3646 [==============================] - 0s 99us/sample - loss: 0.1540 - val_loss: 0.1594\n",
      "Epoch 81/100\n",
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1539 - val_loss: 0.1592\n",
      "Epoch 82/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.1538 - val_loss: 0.1591\n",
      "Epoch 83/100\n",
      "3646/3646 [==============================] - 0s 112us/sample - loss: 0.1536 - val_loss: 0.1590\n",
      "Epoch 84/100\n",
      "3646/3646 [==============================] - 0s 111us/sample - loss: 0.1535 - val_loss: 0.1591\n",
      "Epoch 85/100\n",
      "3646/3646 [==============================] - 0s 107us/sample - loss: 0.1534 - val_loss: 0.1588\n",
      "Epoch 86/100\n",
      "3646/3646 [==============================] - 0s 112us/sample - loss: 0.1533 - val_loss: 0.1588\n",
      "Epoch 87/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1532 - val_loss: 0.1588\n",
      "Epoch 88/100\n",
      "3646/3646 [==============================] - 0s 112us/sample - loss: 0.1531 - val_loss: 0.1586\n",
      "Epoch 89/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1530 - val_loss: 0.1585\n",
      "Epoch 90/100\n",
      "3646/3646 [==============================] - 0s 106us/sample - loss: 0.1529 - val_loss: 0.1584\n",
      "Epoch 91/100\n",
      "3646/3646 [==============================] - 0s 125us/sample - loss: 0.1528 - val_loss: 0.1583\n",
      "Epoch 92/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1527 - val_loss: 0.1582\n",
      "Epoch 93/100\n",
      "3646/3646 [==============================] - 0s 101us/sample - loss: 0.1526 - val_loss: 0.1582\n",
      "Epoch 94/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1525 - val_loss: 0.1581\n",
      "Epoch 95/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1524 - val_loss: 0.1579\n",
      "Epoch 96/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1523 - val_loss: 0.1580\n",
      "Epoch 97/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1522 - val_loss: 0.1578\n",
      "Epoch 98/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1521 - val_loss: 0.1579\n",
      "Epoch 99/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.1520 - val_loss: 0.1578\n",
      "Epoch 100/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1519 - val_loss: 0.1576\n",
      "1822/1822 [==============================] - 0s 180us/sample - loss: 0.1467\n",
      "[CV] END learning_rate=0.0008265454655262932, n_hidden=3, n_neurons=57; total time=  38.8s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 246us/sample - loss: 0.3428 - val_loss: 0.2289\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.2058 - val_loss: 0.2057\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 1s 156us/sample - loss: 0.1868 - val_loss: 0.1942\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 116us/sample - loss: 0.1771 - val_loss: 0.1884\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1716 - val_loss: 0.1836\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1679 - val_loss: 0.1806\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1652 - val_loss: 0.1784\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1634 - val_loss: 0.1768\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1620 - val_loss: 0.1752\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1607 - val_loss: 0.1738\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1597 - val_loss: 0.1726\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1589 - val_loss: 0.1718\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1582 - val_loss: 0.1710\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1575 - val_loss: 0.1703\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1570 - val_loss: 0.1696\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1565 - val_loss: 0.1691\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1559 - val_loss: 0.1687\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1555 - val_loss: 0.1683\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1551 - val_loss: 0.1677\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1547 - val_loss: 0.1678\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1543 - val_loss: 0.1674\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 1s 145us/sample - loss: 0.1541 - val_loss: 0.1669\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 1s 142us/sample - loss: 0.1538 - val_loss: 0.1668\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 121us/sample - loss: 0.1535 - val_loss: 0.1665\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 1s 224us/sample - loss: 0.1531 - val_loss: 0.1664\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 1s 144us/sample - loss: 0.1529 - val_loss: 0.1665\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1528 - val_loss: 0.1662\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1526 - val_loss: 0.1653\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1524 - val_loss: 0.1652\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1522 - val_loss: 0.1657\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1521 - val_loss: 0.1649\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1520 - val_loss: 0.1650\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1517 - val_loss: 0.1649\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1516 - val_loss: 0.1648\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1515 - val_loss: 0.1647\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1513 - val_loss: 0.1643\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1512 - val_loss: 0.1642\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1511 - val_loss: 0.1639\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1510 - val_loss: 0.1639\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1508 - val_loss: 0.1637\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1506 - val_loss: 0.1636\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1504 - val_loss: 0.1641\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1504 - val_loss: 0.1638\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1503 - val_loss: 0.1632\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1501 - val_loss: 0.1629\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1501 - val_loss: 0.1631\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1500 - val_loss: 0.1628\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1499 - val_loss: 0.1630\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1498 - val_loss: 0.1627\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1496 - val_loss: 0.1628\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1495 - val_loss: 0.1623\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1494 - val_loss: 0.1620\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1493 - val_loss: 0.1620\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1493 - val_loss: 0.1622\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1491 - val_loss: 0.1625\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1490 - val_loss: 0.1621\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1490 - val_loss: 0.1620\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1488 - val_loss: 0.1616\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1488 - val_loss: 0.1616\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1486 - val_loss: 0.1616\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1485 - val_loss: 0.1616\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1485 - val_loss: 0.1615\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1483 - val_loss: 0.1610\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1482 - val_loss: 0.1615\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1481 - val_loss: 0.1609\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1480 - val_loss: 0.1616\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 118us/sample - loss: 0.1479 - val_loss: 0.1608\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1479 - val_loss: 0.1608\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1479 - val_loss: 0.1607\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1478 - val_loss: 0.1608\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1477 - val_loss: 0.1607\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1477 - val_loss: 0.1607\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1477 - val_loss: 0.1608\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1475 - val_loss: 0.1607\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1475 - val_loss: 0.1604\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1473 - val_loss: 0.1603\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1474 - val_loss: 0.1605\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1473 - val_loss: 0.1610\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1472 - val_loss: 0.1605\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1471 - val_loss: 0.1608\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1472 - val_loss: 0.1604\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1470 - val_loss: 0.1603\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1470 - val_loss: 0.1607\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 118us/sample - loss: 0.1470 - val_loss: 0.1602\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 1s 151us/sample - loss: 0.1469 - val_loss: 0.1603\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1469 - val_loss: 0.1603\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1468 - val_loss: 0.1605\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1467 - val_loss: 0.1608\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1468 - val_loss: 0.1603\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1466 - val_loss: 0.1603\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1466 - val_loss: 0.1598\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 126us/sample - loss: 0.1467 - val_loss: 0.1600\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1465 - val_loss: 0.1597\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1465 - val_loss: 0.1603\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1465 - val_loss: 0.1598\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1465 - val_loss: 0.1600\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1464 - val_loss: 0.1597\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1464 - val_loss: 0.1599\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1463 - val_loss: 0.1596\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1462 - val_loss: 0.1597\n",
      "1823/1823 [==============================] - 0s 37us/sample - loss: 0.1598\n",
      "[CV] END learning_rate=0.0018323516696037243, n_hidden=2, n_neurons=21; total time=  33.8s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 280us/sample - loss: 0.2502 - val_loss: 0.2130\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.2008 - val_loss: 0.1986\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1902 - val_loss: 0.1916\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1846 - val_loss: 0.1871\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1802 - val_loss: 0.1833\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1770 - val_loss: 0.1809\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1738 - val_loss: 0.1781\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1714 - val_loss: 0.1756\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1691 - val_loss: 0.1739\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1673 - val_loss: 0.1724\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1656 - val_loss: 0.1708\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1643 - val_loss: 0.1704\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1633 - val_loss: 0.1692\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1625 - val_loss: 0.1681\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1615 - val_loss: 0.1685\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.1606 - val_loss: 0.1669\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1604 - val_loss: 0.1666\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1596 - val_loss: 0.1660\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1591 - val_loss: 0.1656\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1588 - val_loss: 0.1654\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1581 - val_loss: 0.1649\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 123us/sample - loss: 0.1579 - val_loss: 0.1647\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1574 - val_loss: 0.1644\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1571 - val_loss: 0.1641\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1568 - val_loss: 0.1638\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1564 - val_loss: 0.1643\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1561 - val_loss: 0.1634\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1555 - val_loss: 0.1634\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1555 - val_loss: 0.1631\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1550 - val_loss: 0.1628\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1549 - val_loss: 0.1630\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1547 - val_loss: 0.1626\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1545 - val_loss: 0.1627\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1543 - val_loss: 0.1622\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1541 - val_loss: 0.1621\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1538 - val_loss: 0.1619\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1537 - val_loss: 0.1618\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1534 - val_loss: 0.1617\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1534 - val_loss: 0.1615\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1531 - val_loss: 0.1618\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1529 - val_loss: 0.1613\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1528 - val_loss: 0.1616\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1526 - val_loss: 0.1611\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1523 - val_loss: 0.1612\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1524 - val_loss: 0.1610\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1520 - val_loss: 0.1610\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1517 - val_loss: 0.1608\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1517 - val_loss: 0.1603\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1517 - val_loss: 0.1601\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1515 - val_loss: 0.1600\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1515 - val_loss: 0.1600\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1512 - val_loss: 0.1598\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1510 - val_loss: 0.1599\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1508 - val_loss: 0.1596\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1508 - val_loss: 0.1595\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1505 - val_loss: 0.1595\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1504 - val_loss: 0.1593\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1503 - val_loss: 0.1591\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1503 - val_loss: 0.1592\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1501 - val_loss: 0.1590\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1500 - val_loss: 0.1591\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1500 - val_loss: 0.1594\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1498 - val_loss: 0.1587\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1497 - val_loss: 0.1587\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1496 - val_loss: 0.1587\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1496 - val_loss: 0.1584\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1494 - val_loss: 0.1584\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1492 - val_loss: 0.1584\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1491 - val_loss: 0.1582\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1490 - val_loss: 0.1586\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1491 - val_loss: 0.1585\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1486 - val_loss: 0.1594\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1490 - val_loss: 0.1579\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1487 - val_loss: 0.1578\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1488 - val_loss: 0.1578\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1486 - val_loss: 0.1579\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1485 - val_loss: 0.1582\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 115us/sample - loss: 0.1483 - val_loss: 0.1576\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1482 - val_loss: 0.1575\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1481 - val_loss: 0.1579\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1481 - val_loss: 0.1574\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1480 - val_loss: 0.1574\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1479 - val_loss: 0.1570\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1478 - val_loss: 0.1570\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1475 - val_loss: 0.1568\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1476 - val_loss: 0.1568\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1474 - val_loss: 0.1570\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1474 - val_loss: 0.1572\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1473 - val_loss: 0.1565\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1473 - val_loss: 0.1569\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1472 - val_loss: 0.1563\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1468 - val_loss: 0.1590\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1469 - val_loss: 0.1562\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1469 - val_loss: 0.1561\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1468 - val_loss: 0.1563\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1468 - val_loss: 0.1560\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1468 - val_loss: 0.1561\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1464 - val_loss: 0.1562\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1465 - val_loss: 0.1559\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1465 - val_loss: 0.1560\n",
      "1823/1823 [==============================] - 0s 36us/sample - loss: 0.1462\n",
      "[CV] END learning_rate=0.0018323516696037243, n_hidden=2, n_neurons=21; total time=  33.7s\n",
      "Train on 3646 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3646/3646 [==============================] - 1s 218us/sample - loss: 0.3107 - val_loss: 0.2850\n",
      "Epoch 2/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.2568 - val_loss: 0.2518\n",
      "Epoch 3/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.2301 - val_loss: 0.2314\n",
      "Epoch 4/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.2132 - val_loss: 0.2183\n",
      "Epoch 5/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.2021 - val_loss: 0.2091\n",
      "Epoch 6/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1943 - val_loss: 0.2020\n",
      "Epoch 7/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1885 - val_loss: 0.1968\n",
      "Epoch 8/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1843 - val_loss: 0.1932\n",
      "Epoch 9/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1810 - val_loss: 0.1899\n",
      "Epoch 10/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1787 - val_loss: 0.1876\n",
      "Epoch 11/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1764 - val_loss: 0.1853\n",
      "Epoch 12/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1747 - val_loss: 0.1836\n",
      "Epoch 13/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1733 - val_loss: 0.1824\n",
      "Epoch 14/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1719 - val_loss: 0.1810\n",
      "Epoch 15/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1709 - val_loss: 0.1802\n",
      "Epoch 16/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1699 - val_loss: 0.1785\n",
      "Epoch 17/100\n",
      "3646/3646 [==============================] - 0s 133us/sample - loss: 0.1690 - val_loss: 0.1775\n",
      "Epoch 18/100\n",
      "3646/3646 [==============================] - 1s 140us/sample - loss: 0.1682 - val_loss: 0.1768\n",
      "Epoch 19/100\n",
      "3646/3646 [==============================] - 0s 110us/sample - loss: 0.1676 - val_loss: 0.1760\n",
      "Epoch 20/100\n",
      "3646/3646 [==============================] - 0s 108us/sample - loss: 0.1668 - val_loss: 0.1755\n",
      "Epoch 21/100\n",
      "3646/3646 [==============================] - 0s 104us/sample - loss: 0.1661 - val_loss: 0.1747\n",
      "Epoch 22/100\n",
      "3646/3646 [==============================] - 0s 97us/sample - loss: 0.1657 - val_loss: 0.1743\n",
      "Epoch 23/100\n",
      "3646/3646 [==============================] - 0s 105us/sample - loss: 0.1653 - val_loss: 0.1737\n",
      "Epoch 24/100\n",
      "3646/3646 [==============================] - 0s 102us/sample - loss: 0.1647 - val_loss: 0.1736\n",
      "Epoch 25/100\n",
      "3646/3646 [==============================] - 0s 101us/sample - loss: 0.1642 - val_loss: 0.1728\n",
      "Epoch 26/100\n",
      "3646/3646 [==============================] - 0s 107us/sample - loss: 0.1637 - val_loss: 0.1721\n",
      "Epoch 27/100\n",
      "3646/3646 [==============================] - 0s 90us/sample - loss: 0.1634 - val_loss: 0.1719\n",
      "Epoch 28/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1629 - val_loss: 0.1716\n",
      "Epoch 29/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1626 - val_loss: 0.1708\n",
      "Epoch 30/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1622 - val_loss: 0.1708\n",
      "Epoch 31/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1620 - val_loss: 0.1704\n",
      "Epoch 32/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1615 - val_loss: 0.1706\n",
      "Epoch 33/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1612 - val_loss: 0.1696\n",
      "Epoch 34/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1611 - val_loss: 0.1697\n",
      "Epoch 35/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1609 - val_loss: 0.1690\n",
      "Epoch 36/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1606 - val_loss: 0.1689\n",
      "Epoch 37/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1604 - val_loss: 0.1690\n",
      "Epoch 38/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1602 - val_loss: 0.1684\n",
      "Epoch 39/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1601 - val_loss: 0.1681\n",
      "Epoch 40/100\n",
      "3646/3646 [==============================] - 0s 98us/sample - loss: 0.1597 - val_loss: 0.1681\n",
      "Epoch 41/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1595 - val_loss: 0.1675\n",
      "Epoch 42/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1593 - val_loss: 0.1677\n",
      "Epoch 43/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1591 - val_loss: 0.1672\n",
      "Epoch 44/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1587 - val_loss: 0.1683\n",
      "Epoch 45/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1588 - val_loss: 0.1668\n",
      "Epoch 46/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1585 - val_loss: 0.1672\n",
      "Epoch 47/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1583 - val_loss: 0.1664\n",
      "Epoch 48/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1582 - val_loss: 0.1664\n",
      "Epoch 49/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1580 - val_loss: 0.1661\n",
      "Epoch 50/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1579 - val_loss: 0.1660\n",
      "Epoch 51/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1578 - val_loss: 0.1663\n",
      "Epoch 52/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1575 - val_loss: 0.1656\n",
      "Epoch 53/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1574 - val_loss: 0.1654\n",
      "Epoch 54/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1572 - val_loss: 0.1653\n",
      "Epoch 55/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1571 - val_loss: 0.1653\n",
      "Epoch 56/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1568 - val_loss: 0.1654\n",
      "Epoch 57/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1567 - val_loss: 0.1651\n",
      "Epoch 58/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1566 - val_loss: 0.1648\n",
      "Epoch 59/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1565 - val_loss: 0.1647\n",
      "Epoch 60/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1561 - val_loss: 0.1643\n",
      "Epoch 61/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1559 - val_loss: 0.1643\n",
      "Epoch 62/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1561 - val_loss: 0.1641\n",
      "Epoch 63/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1558 - val_loss: 0.1643\n",
      "Epoch 64/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1555 - val_loss: 0.1641\n",
      "Epoch 65/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1556 - val_loss: 0.1638\n",
      "Epoch 66/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1554 - val_loss: 0.1638\n",
      "Epoch 67/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1551 - val_loss: 0.1634\n",
      "Epoch 68/100\n",
      "3646/3646 [==============================] - 0s 117us/sample - loss: 0.1551 - val_loss: 0.1636\n",
      "Epoch 69/100\n",
      "3646/3646 [==============================] - 0s 101us/sample - loss: 0.1549 - val_loss: 0.1636\n",
      "Epoch 70/100\n",
      "3646/3646 [==============================] - 0s 112us/sample - loss: 0.1548 - val_loss: 0.1632\n",
      "Epoch 71/100\n",
      "3646/3646 [==============================] - 0s 104us/sample - loss: 0.1547 - val_loss: 0.1632\n",
      "Epoch 72/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1547 - val_loss: 0.1631\n",
      "Epoch 73/100\n",
      "3646/3646 [==============================] - 0s 98us/sample - loss: 0.1545 - val_loss: 0.1633\n",
      "Epoch 74/100\n",
      "3646/3646 [==============================] - 0s 108us/sample - loss: 0.1543 - val_loss: 0.1633\n",
      "Epoch 75/100\n",
      "3646/3646 [==============================] - 0s 105us/sample - loss: 0.1542 - val_loss: 0.1629\n",
      "Epoch 76/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1541 - val_loss: 0.1633\n",
      "Epoch 77/100\n",
      "3646/3646 [==============================] - 0s 90us/sample - loss: 0.1540 - val_loss: 0.1625\n",
      "Epoch 78/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1539 - val_loss: 0.1631\n",
      "Epoch 79/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.1539 - val_loss: 0.1626\n",
      "Epoch 80/100\n",
      "3646/3646 [==============================] - 0s 103us/sample - loss: 0.1537 - val_loss: 0.1624\n",
      "Epoch 81/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1536 - val_loss: 0.1621\n",
      "Epoch 82/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1534 - val_loss: 0.1621\n",
      "Epoch 83/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1534 - val_loss: 0.1625\n",
      "Epoch 84/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1533 - val_loss: 0.1622\n",
      "Epoch 85/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1532 - val_loss: 0.1628\n",
      "Epoch 86/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1530 - val_loss: 0.1619\n",
      "Epoch 87/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1532 - val_loss: 0.1618\n",
      "Epoch 88/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1529 - val_loss: 0.1616\n",
      "Epoch 89/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1529 - val_loss: 0.1619\n",
      "Epoch 90/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1530 - val_loss: 0.1618\n",
      "Epoch 91/100\n",
      "3646/3646 [==============================] - 0s 107us/sample - loss: 0.1528 - val_loss: 0.1615\n",
      "Epoch 92/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1526 - val_loss: 0.1619\n",
      "Epoch 93/100\n",
      "3646/3646 [==============================] - 0s 93us/sample - loss: 0.1526 - val_loss: 0.1614\n",
      "Epoch 94/100\n",
      "3646/3646 [==============================] - 0s 113us/sample - loss: 0.1525 - val_loss: 0.1622\n",
      "Epoch 95/100\n",
      "3646/3646 [==============================] - 0s 90us/sample - loss: 0.1525 - val_loss: 0.1612\n",
      "Epoch 96/100\n",
      "3646/3646 [==============================] - 0s 125us/sample - loss: 0.1524 - val_loss: 0.1611\n",
      "Epoch 97/100\n",
      "3646/3646 [==============================] - 1s 138us/sample - loss: 0.1522 - val_loss: 0.1611\n",
      "Epoch 98/100\n",
      "3646/3646 [==============================] - 0s 115us/sample - loss: 0.1522 - val_loss: 0.1617\n",
      "Epoch 99/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.1521 - val_loss: 0.1621\n",
      "Epoch 100/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1521 - val_loss: 0.1617\n",
      "1822/1822 [==============================] - 0s 27us/sample - loss: 0.1509\n",
      "[CV] END learning_rate=0.0018323516696037243, n_hidden=2, n_neurons=21; total time=  33.4s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 198us/sample - loss: 0.1970 - val_loss: 0.1782\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1673 - val_loss: 0.1721\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1609 - val_loss: 0.1684\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 1s 179us/sample - loss: 0.1582 - val_loss: 0.1669\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 1s 405us/sample - loss: 0.1552 - val_loss: 0.1661\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 1s 197us/sample - loss: 0.1533 - val_loss: 0.1641\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 1s 173us/sample - loss: 0.1522 - val_loss: 0.1661\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 1s 164us/sample - loss: 0.1508 - val_loss: 0.1614\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 126us/sample - loss: 0.1505 - val_loss: 0.1610\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - ETA: 0s - loss: 0.149 - 0s 121us/sample - loss: 0.1493 - val_loss: 0.1601\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 1s 159us/sample - loss: 0.1487 - val_loss: 0.1606\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1483 - val_loss: 0.1589\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1479 - val_loss: 0.1599\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1479 - val_loss: 0.1585\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 120us/sample - loss: 0.1465 - val_loss: 0.1608\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1464 - val_loss: 0.1577\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 125us/sample - loss: 0.1460 - val_loss: 0.1605\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 123us/sample - loss: 0.1459 - val_loss: 0.1624\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1460 - val_loss: 0.1603\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1452 - val_loss: 0.1577\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1447 - val_loss: 0.1661\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1445 - val_loss: 0.1583\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 112us/sample - loss: 0.1444 - val_loss: 0.1558\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1440 - val_loss: 0.1557\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1438 - val_loss: 0.1571\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1437 - val_loss: 0.1556\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 99us/sample - loss: 0.1433 - val_loss: 0.1563\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1436 - val_loss: 0.1559\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1433 - val_loss: 0.1565\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1428 - val_loss: 0.1567\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1422 - val_loss: 0.1549\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1421 - val_loss: 0.1554\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1426 - val_loss: 0.1544\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1418 - val_loss: 0.1574\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1421 - val_loss: 0.1555\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1417 - val_loss: 0.1565\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1417 - val_loss: 0.1552\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1416 - val_loss: 0.1567\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1413 - val_loss: 0.1538\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1411 - val_loss: 0.1539\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1405 - val_loss: 0.1535\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1399 - val_loss: 0.1583\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1410 - val_loss: 0.1645\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1405 - val_loss: 0.1583\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1402 - val_loss: 0.1528\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1399 - val_loss: 0.1534\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1395 - val_loss: 0.1575\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1405 - val_loss: 0.1554\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1401 - val_loss: 0.1544\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1392 - val_loss: 0.1594\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1402 - val_loss: 0.1533\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 112us/sample - loss: 0.1394 - val_loss: 0.1530\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1392 - val_loss: 0.1521\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1392 - val_loss: 0.1550\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 117us/sample - loss: 0.1387 - val_loss: 0.1528\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1383 - val_loss: 0.1553\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1388 - val_loss: 0.1534\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1384 - val_loss: 0.1518\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1381 - val_loss: 0.1519\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 113us/sample - loss: 0.1376 - val_loss: 0.1561\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1376 - val_loss: 0.1516\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1379 - val_loss: 0.1514\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1375 - val_loss: 0.1537\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1375 - val_loss: 0.1551\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1375 - val_loss: 0.1512\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1367 - val_loss: 0.1510\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1372 - val_loss: 0.1527\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1370 - val_loss: 0.1531\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1362 - val_loss: 0.1513\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1362 - val_loss: 0.1531\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1366 - val_loss: 0.1517\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1364 - val_loss: 0.1498\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1357 - val_loss: 0.1519\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1362 - val_loss: 0.1507\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1360 - val_loss: 0.1502\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1356 - val_loss: 0.1506\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1360 - val_loss: 0.1497\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1352 - val_loss: 0.1502\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 134us/sample - loss: 0.1353 - val_loss: 0.1496\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1353 - val_loss: 0.1494\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1346 - val_loss: 0.1499\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1351 - val_loss: 0.1501\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1347 - val_loss: 0.1512\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1354 - val_loss: 0.1484\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1348 - val_loss: 0.1492\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1345 - val_loss: 0.1486\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1345 - val_loss: 0.1488\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1337 - val_loss: 0.1509\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1344 - val_loss: 0.1481\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1339 - val_loss: 0.1477\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1343 - val_loss: 0.1476\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1338 - val_loss: 0.1487\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1332 - val_loss: 0.1485\n",
      "Epoch 94/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1333 - val_loss: 0.1514\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 94us/sample - loss: 0.1342 - val_loss: 0.1485\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1336 - val_loss: 0.1478\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1330 - val_loss: 0.1552\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1333 - val_loss: 0.1475\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1331 - val_loss: 0.1476\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1325 - val_loss: 0.1470\n",
      "1823/1823 [==============================] - 0s 38us/sample - loss: 0.1461\n",
      "[CV] END learning_rate=0.011826619302953725, n_hidden=1, n_neurons=68; total time=  36.3s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 287us/sample - loss: 0.1859 - val_loss: 0.1790\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 107us/sample - loss: 0.1652 - val_loss: 0.1718\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1608 - val_loss: 0.1679\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1590 - val_loss: 0.1680\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1574 - val_loss: 0.1659\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1562 - val_loss: 0.1656\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1551 - val_loss: 0.1632\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1541 - val_loss: 0.1625\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1534 - val_loss: 0.1637\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1527 - val_loss: 0.1619\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1520 - val_loss: 0.1611\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1519 - val_loss: 0.1618\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1513 - val_loss: 0.1616\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 66us/sample - loss: 0.1507 - val_loss: 0.1610\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1509 - val_loss: 0.1623\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1501 - val_loss: 0.1591\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1498 - val_loss: 0.1608\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1491 - val_loss: 0.1593\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1494 - val_loss: 0.1580\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1486 - val_loss: 0.1600\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1481 - val_loss: 0.1581\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1479 - val_loss: 0.1606\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1472 - val_loss: 0.1607\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1486 - val_loss: 0.1602\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1470 - val_loss: 0.1576\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 74us/sample - loss: 0.1471 - val_loss: 0.1606\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1465 - val_loss: 0.1569\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1462 - val_loss: 0.1618\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1466 - val_loss: 0.1588\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1461 - val_loss: 0.1557\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1459 - val_loss: 0.1576\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1453 - val_loss: 0.1584\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1452 - val_loss: 0.1551\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1450 - val_loss: 0.1565\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1446 - val_loss: 0.1545\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 67us/sample - loss: 0.1447 - val_loss: 0.1590\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1445 - val_loss: 0.1547\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1441 - val_loss: 0.1587\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1444 - val_loss: 0.1539\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1434 - val_loss: 0.1534\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1436 - val_loss: 0.1540\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 1s 145us/sample - loss: 0.1428 - val_loss: 0.1547\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 97us/sample - loss: 0.1431 - val_loss: 0.1527\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 119us/sample - loss: 0.1430 - val_loss: 0.1525\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.1423 - val_loss: 0.1530\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1426 - val_loss: 0.1543\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1421 - val_loss: 0.1573\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1422 - val_loss: 0.1517\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1417 - val_loss: 0.1566\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 100us/sample - loss: 0.1416 - val_loss: 0.1516\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1417 - val_loss: 0.1519\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 92us/sample - loss: 0.1412 - val_loss: 0.1527\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1414 - val_loss: 0.1507\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1406 - val_loss: 0.1519\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1406 - val_loss: 0.1505\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 122us/sample - loss: 0.1406 - val_loss: 0.1515\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1402 - val_loss: 0.1506\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1405 - val_loss: 0.1507\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1397 - val_loss: 0.1495\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1394 - val_loss: 0.1501\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1398 - val_loss: 0.1502\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1394 - val_loss: 0.1497\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1394 - val_loss: 0.1496\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1387 - val_loss: 0.1504\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1390 - val_loss: 0.1575\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1389 - val_loss: 0.1483\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 89us/sample - loss: 0.1383 - val_loss: 0.1480\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1389 - val_loss: 0.1485\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1383 - val_loss: 0.1493\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1380 - val_loss: 0.1479\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1378 - val_loss: 0.1487\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1381 - val_loss: 0.1477\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1377 - val_loss: 0.1477\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1375 - val_loss: 0.1486\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1373 - val_loss: 0.1476\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1370 - val_loss: 0.1466\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 86us/sample - loss: 0.1367 - val_loss: 0.1474\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1367 - val_loss: 0.1483\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1365 - val_loss: 0.1475\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1357 - val_loss: 0.1479\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1360 - val_loss: 0.1502\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1359 - val_loss: 0.1470\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1356 - val_loss: 0.1462\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1363 - val_loss: 0.1467\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1360 - val_loss: 0.1465\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1354 - val_loss: 0.1499\n",
      "Epoch 87/100\n",
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1352 - val_loss: 0.1463\n",
      "Epoch 88/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1351 - val_loss: 0.1463\n",
      "Epoch 89/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1353 - val_loss: 0.1523\n",
      "Epoch 90/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1348 - val_loss: 0.1446\n",
      "Epoch 91/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1348 - val_loss: 0.1450\n",
      "Epoch 92/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1348 - val_loss: 0.1456\n",
      "Epoch 93/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1347 - val_loss: 0.1455\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 82us/sample - loss: 0.1342 - val_loss: 0.1450\n",
      "Epoch 95/100\n",
      "3645/3645 [==============================] - 0s 87us/sample - loss: 0.1344 - val_loss: 0.1459\n",
      "Epoch 96/100\n",
      "3645/3645 [==============================] - 0s 76us/sample - loss: 0.1341 - val_loss: 0.1468\n",
      "Epoch 97/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1337 - val_loss: 0.1471\n",
      "Epoch 98/100\n",
      "3645/3645 [==============================] - 0s 96us/sample - loss: 0.1335 - val_loss: 0.1445\n",
      "Epoch 99/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1337 - val_loss: 0.1439\n",
      "Epoch 100/100\n",
      "3645/3645 [==============================] - 0s 91us/sample - loss: 0.1336 - val_loss: 0.1437\n",
      "1823/1823 [==============================] - 0s 36us/sample - loss: 0.1357\n",
      "[CV] END learning_rate=0.011826619302953725, n_hidden=1, n_neurons=68; total time=  32.8s\n",
      "Train on 3646 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3646/3646 [==============================] - 1s 264us/sample - loss: 0.2195 - val_loss: 0.1863\n",
      "Epoch 2/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1750 - val_loss: 0.1762\n",
      "Epoch 3/100\n",
      "3646/3646 [==============================] - 0s 96us/sample - loss: 0.1674 - val_loss: 0.1707\n",
      "Epoch 4/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1637 - val_loss: 0.1655\n",
      "Epoch 5/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1604 - val_loss: 0.1641\n",
      "Epoch 6/100\n",
      "3646/3646 [==============================] - 0s 88us/sample - loss: 0.1586 - val_loss: 0.1632\n",
      "Epoch 7/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1569 - val_loss: 0.1606\n",
      "Epoch 8/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1554 - val_loss: 0.1605\n",
      "Epoch 9/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1545 - val_loss: 0.1626\n",
      "Epoch 10/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1531 - val_loss: 0.1619\n",
      "Epoch 11/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1525 - val_loss: 0.1600\n",
      "Epoch 12/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.1517 - val_loss: 0.1596\n",
      "Epoch 13/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1510 - val_loss: 0.1578\n",
      "Epoch 14/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1507 - val_loss: 0.1574\n",
      "Epoch 15/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1500 - val_loss: 0.1571\n",
      "Epoch 16/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1500 - val_loss: 0.1565\n",
      "Epoch 17/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1499 - val_loss: 0.1566\n",
      "Epoch 18/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1492 - val_loss: 0.1557\n",
      "Epoch 19/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1490 - val_loss: 0.1550\n",
      "Epoch 20/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1481 - val_loss: 0.1547\n",
      "Epoch 21/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1477 - val_loss: 0.1540\n",
      "Epoch 22/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1478 - val_loss: 0.1542\n",
      "Epoch 23/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1471 - val_loss: 0.1551\n",
      "Epoch 24/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1469 - val_loss: 0.1543\n",
      "Epoch 25/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1463 - val_loss: 0.1532\n",
      "Epoch 26/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1461 - val_loss: 0.1526\n",
      "Epoch 27/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1456 - val_loss: 0.1534\n",
      "Epoch 28/100\n",
      "3646/3646 [==============================] - 0s 91us/sample - loss: 0.1451 - val_loss: 0.1542\n",
      "Epoch 29/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1457 - val_loss: 0.1517\n",
      "Epoch 30/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1452 - val_loss: 0.1522\n",
      "Epoch 31/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1448 - val_loss: 0.1521\n",
      "Epoch 32/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1448 - val_loss: 0.1519\n",
      "Epoch 33/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1445 - val_loss: 0.1508\n",
      "Epoch 34/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1441 - val_loss: 0.1514\n",
      "Epoch 35/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1437 - val_loss: 0.1534\n",
      "Epoch 36/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1439 - val_loss: 0.1509\n",
      "Epoch 37/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1430 - val_loss: 0.1502\n",
      "Epoch 38/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1433 - val_loss: 0.1504\n",
      "Epoch 39/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1431 - val_loss: 0.1495\n",
      "Epoch 40/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1428 - val_loss: 0.1497\n",
      "Epoch 41/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1422 - val_loss: 0.1501\n",
      "Epoch 42/100\n",
      "3646/3646 [==============================] - 0s 83us/sample - loss: 0.1418 - val_loss: 0.1499\n",
      "Epoch 43/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1423 - val_loss: 0.1518\n",
      "Epoch 44/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.1417 - val_loss: 0.1510\n",
      "Epoch 45/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1416 - val_loss: 0.1511\n",
      "Epoch 46/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1411 - val_loss: 0.1528\n",
      "Epoch 47/100\n",
      "3646/3646 [==============================] - 0s 94us/sample - loss: 0.1417 - val_loss: 0.1486\n",
      "Epoch 48/100\n",
      "3646/3646 [==============================] - 0s 97us/sample - loss: 0.1412 - val_loss: 0.1486\n",
      "Epoch 49/100\n",
      "3646/3646 [==============================] - 0s 101us/sample - loss: 0.1411 - val_loss: 0.1485\n",
      "Epoch 50/100\n",
      "3646/3646 [==============================] - 0s 110us/sample - loss: 0.1412 - val_loss: 0.1490\n",
      "Epoch 51/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1405 - val_loss: 0.1505\n",
      "Epoch 52/100\n",
      "3646/3646 [==============================] - 0s 128us/sample - loss: 0.1404 - val_loss: 0.1497\n",
      "Epoch 53/100\n",
      "3646/3646 [==============================] - 0s 112us/sample - loss: 0.1407 - val_loss: 0.1489\n",
      "Epoch 54/100\n",
      "3646/3646 [==============================] - 0s 126us/sample - loss: 0.1397 - val_loss: 0.1484\n",
      "Epoch 55/100\n",
      "3646/3646 [==============================] - 0s 120us/sample - loss: 0.1399 - val_loss: 0.1477\n",
      "Epoch 56/100\n",
      "3646/3646 [==============================] - 0s 126us/sample - loss: 0.1396 - val_loss: 0.1486\n",
      "Epoch 57/100\n",
      "3646/3646 [==============================] - 0s 129us/sample - loss: 0.1396 - val_loss: 0.1487\n",
      "Epoch 58/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1392 - val_loss: 0.1474\n",
      "Epoch 59/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1395 - val_loss: 0.1473\n",
      "Epoch 60/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1394 - val_loss: 0.1470\n",
      "Epoch 61/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1390 - val_loss: 0.1482\n",
      "Epoch 62/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1386 - val_loss: 0.1514\n",
      "Epoch 63/100\n",
      "3646/3646 [==============================] - 0s 89us/sample - loss: 0.1386 - val_loss: 0.1478\n",
      "Epoch 64/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1386 - val_loss: 0.1476\n",
      "Epoch 65/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1382 - val_loss: 0.1465\n",
      "Epoch 66/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1375 - val_loss: 0.1527\n",
      "Epoch 67/100\n",
      "3646/3646 [==============================] - 0s 100us/sample - loss: 0.1381 - val_loss: 0.1476\n",
      "Epoch 68/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1378 - val_loss: 0.1459\n",
      "Epoch 69/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1375 - val_loss: 0.1474\n",
      "Epoch 70/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1373 - val_loss: 0.1479\n",
      "Epoch 71/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1375 - val_loss: 0.1463\n",
      "Epoch 72/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1372 - val_loss: 0.1462\n",
      "Epoch 73/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1375 - val_loss: 0.1452\n",
      "Epoch 74/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1374 - val_loss: 0.1458\n",
      "Epoch 75/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1374 - val_loss: 0.1459\n",
      "Epoch 76/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1367 - val_loss: 0.1453\n",
      "Epoch 77/100\n",
      "3646/3646 [==============================] - 0s 99us/sample - loss: 0.1365 - val_loss: 0.1463\n",
      "Epoch 78/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1364 - val_loss: 0.1479\n",
      "Epoch 79/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1360 - val_loss: 0.1446\n",
      "Epoch 80/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.1360 - val_loss: 0.1452\n",
      "Epoch 81/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1360 - val_loss: 0.1445\n",
      "Epoch 82/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1357 - val_loss: 0.1437\n",
      "Epoch 83/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1355 - val_loss: 0.1442\n",
      "Epoch 84/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1349 - val_loss: 0.1436\n",
      "Epoch 85/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1357 - val_loss: 0.1446\n",
      "Epoch 86/100\n",
      "3646/3646 [==============================] - 0s 75us/sample - loss: 0.1347 - val_loss: 0.1461\n",
      "Epoch 87/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1349 - val_loss: 0.1442\n",
      "Epoch 88/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1350 - val_loss: 0.1437\n",
      "Epoch 89/100\n",
      "3646/3646 [==============================] - 0s 77us/sample - loss: 0.1347 - val_loss: 0.1468\n",
      "Epoch 90/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1342 - val_loss: 0.1451\n",
      "Epoch 91/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1344 - val_loss: 0.1435\n",
      "Epoch 92/100\n",
      "3646/3646 [==============================] - 0s 84us/sample - loss: 0.1343 - val_loss: 0.1436\n",
      "Epoch 93/100\n",
      "3646/3646 [==============================] - 0s 80us/sample - loss: 0.1341 - val_loss: 0.1435\n",
      "Epoch 94/100\n",
      "3646/3646 [==============================] - 0s 82us/sample - loss: 0.1344 - val_loss: 0.1425\n",
      "Epoch 95/100\n",
      "3646/3646 [==============================] - 0s 92us/sample - loss: 0.1338 - val_loss: 0.1440\n",
      "Epoch 96/100\n",
      "3646/3646 [==============================] - 0s 103us/sample - loss: 0.1341 - val_loss: 0.1442\n",
      "Epoch 97/100\n",
      "3646/3646 [==============================] - 0s 98us/sample - loss: 0.1342 - val_loss: 0.1426\n",
      "Epoch 98/100\n",
      "3646/3646 [==============================] - 0s 95us/sample - loss: 0.1340 - val_loss: 0.1441\n",
      "Epoch 99/100\n",
      "3646/3646 [==============================] - 0s 107us/sample - loss: 0.1335 - val_loss: 0.1470\n",
      "Epoch 100/100\n",
      "3646/3646 [==============================] - 0s 108us/sample - loss: 0.1333 - val_loss: 0.1432\n",
      "1822/1822 [==============================] - 0s 42us/sample - loss: 0.1336\n",
      "[CV] END learning_rate=0.011826619302953725, n_hidden=1, n_neurons=68; total time=  32.6s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 307us/sample - loss: 0.4354 - val_loss: 0.2743\n",
      "Epoch 2/100\n",
      "3645/3645 [==============================] - 0s 63us/sample - loss: 0.2345 - val_loss: 0.2310\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 60us/sample - loss: 0.2060 - val_loss: 0.2097\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 60us/sample - loss: 0.1905 - val_loss: 0.1974\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 55us/sample - loss: 0.1808 - val_loss: 0.1897\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1743 - val_loss: 0.1839\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 56us/sample - loss: 0.1697 - val_loss: 0.1789\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 62us/sample - loss: 0.1662 - val_loss: 0.1760\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.1638 - val_loss: 0.1734\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.1620 - val_loss: 0.1720\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1606 - val_loss: 0.1704\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.1595 - val_loss: 0.1693\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.1586 - val_loss: 0.1684\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.1579 - val_loss: 0.1687\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1575 - val_loss: 0.1683\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 67us/sample - loss: 0.1571 - val_loss: 0.1669\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 63us/sample - loss: 0.1567 - val_loss: 0.1667\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 61us/sample - loss: 0.1565 - val_loss: 0.1669\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 60us/sample - loss: 0.1562 - val_loss: 0.1660\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 67us/sample - loss: 0.1560 - val_loss: 0.1658\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 62us/sample - loss: 0.1560 - val_loss: 0.1657\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 62us/sample - loss: 0.1558 - val_loss: 0.1657\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 60us/sample - loss: 0.1557 - val_loss: 0.1657\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 62us/sample - loss: 0.1558 - val_loss: 0.1651\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1556 - val_loss: 0.1654\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 58us/sample - loss: 0.1556 - val_loss: 0.1653\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 61us/sample - loss: 0.1555 - val_loss: 0.1650\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 64us/sample - loss: 0.1554 - val_loss: 0.1648\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1555 - val_loss: 0.1652\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1556 - val_loss: 0.1652\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 58us/sample - loss: 0.1555 - val_loss: 0.1649\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 57us/sample - loss: 0.1554 - val_loss: 0.1649\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 63us/sample - loss: 0.1554 - val_loss: 0.1651\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 62us/sample - loss: 0.1553 - val_loss: 0.1654\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1554 - val_loss: 0.1652\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 109us/sample - loss: 0.1553 - val_loss: 0.1652\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1553 - val_loss: 0.1659\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 66us/sample - loss: 0.1554 - val_loss: 0.1653\n",
      "1823/1823 [==============================] - 0s 32us/sample - loss: 0.1659\n",
      "[CV] END learning_rate=0.003586716970965761, n_hidden=0, n_neurons=80; total time=  10.0s\n",
      "Train on 3645 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3645/3645 [==============================] - 1s 159us/sample - loss: 0.7524 - val_loss: 0.3973\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.3085 - val_loss: 0.2767\n",
      "Epoch 3/100\n",
      "3645/3645 [==============================] - 0s 55us/sample - loss: 0.2418 - val_loss: 0.2415\n",
      "Epoch 4/100\n",
      "3645/3645 [==============================] - 0s 57us/sample - loss: 0.2159 - val_loss: 0.2226\n",
      "Epoch 5/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.2009 - val_loss: 0.2096\n",
      "Epoch 6/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.1906 - val_loss: 0.2005\n",
      "Epoch 7/100\n",
      "3645/3645 [==============================] - 0s 67us/sample - loss: 0.1834 - val_loss: 0.1937\n",
      "Epoch 8/100\n",
      "3645/3645 [==============================] - 0s 77us/sample - loss: 0.1782 - val_loss: 0.1885\n",
      "Epoch 9/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1743 - val_loss: 0.1845\n",
      "Epoch 10/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.1715 - val_loss: 0.1813\n",
      "Epoch 11/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1692 - val_loss: 0.1792\n",
      "Epoch 12/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.1673 - val_loss: 0.1770\n",
      "Epoch 13/100\n",
      "3645/3645 [==============================] - 0s 58us/sample - loss: 0.1659 - val_loss: 0.1755\n",
      "Epoch 14/100\n",
      "3645/3645 [==============================] - 0s 55us/sample - loss: 0.1649 - val_loss: 0.1737\n",
      "Epoch 15/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1639 - val_loss: 0.1727\n",
      "Epoch 16/100\n",
      "3645/3645 [==============================] - 0s 84us/sample - loss: 0.1632 - val_loss: 0.1718\n",
      "Epoch 17/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1626 - val_loss: 0.1710\n",
      "Epoch 18/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1621 - val_loss: 0.1701\n",
      "Epoch 19/100\n",
      "3645/3645 [==============================] - 0s 72us/sample - loss: 0.1614 - val_loss: 0.1703\n",
      "Epoch 20/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1611 - val_loss: 0.1689\n",
      "Epoch 21/100\n",
      "3645/3645 [==============================] - 0s 73us/sample - loss: 0.1609 - val_loss: 0.1683\n",
      "Epoch 22/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1607 - val_loss: 0.1681\n",
      "Epoch 23/100\n",
      "3645/3645 [==============================] - 0s 69us/sample - loss: 0.1604 - val_loss: 0.1676\n",
      "Epoch 24/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1601 - val_loss: 0.1675\n",
      "Epoch 25/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1601 - val_loss: 0.1671\n",
      "Epoch 26/100\n",
      "3645/3645 [==============================] - 0s 88us/sample - loss: 0.1599 - val_loss: 0.1668\n",
      "Epoch 27/100\n",
      "3645/3645 [==============================] - 0s 54us/sample - loss: 0.1598 - val_loss: 0.1666\n",
      "Epoch 28/100\n",
      "3645/3645 [==============================] - 0s 64us/sample - loss: 0.1596 - val_loss: 0.1665\n",
      "Epoch 29/100\n",
      "3645/3645 [==============================] - 0s 57us/sample - loss: 0.1597 - val_loss: 0.1663\n",
      "Epoch 30/100\n",
      "3645/3645 [==============================] - 0s 65us/sample - loss: 0.1594 - val_loss: 0.1664\n",
      "Epoch 31/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1595 - val_loss: 0.1660\n",
      "Epoch 32/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1590 - val_loss: 0.1668\n",
      "Epoch 33/100\n",
      "3645/3645 [==============================] - 0s 61us/sample - loss: 0.1593 - val_loss: 0.1657\n",
      "Epoch 34/100\n",
      "3645/3645 [==============================] - 0s 61us/sample - loss: 0.1592 - val_loss: 0.1662\n",
      "Epoch 35/100\n",
      "3645/3645 [==============================] - 0s 93us/sample - loss: 0.1591 - val_loss: 0.1659\n",
      "Epoch 36/100\n",
      "3645/3645 [==============================] - 0s 85us/sample - loss: 0.1591 - val_loss: 0.1660\n",
      "Epoch 37/100\n",
      "3645/3645 [==============================] - 0s 103us/sample - loss: 0.1592 - val_loss: 0.1654\n",
      "Epoch 38/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1592 - val_loss: 0.1654\n",
      "Epoch 39/100\n",
      "3645/3645 [==============================] - 0s 106us/sample - loss: 0.1591 - val_loss: 0.1653\n",
      "Epoch 40/100\n",
      "3645/3645 [==============================] - 0s 90us/sample - loss: 0.1590 - val_loss: 0.1653\n",
      "Epoch 41/100\n",
      "3645/3645 [==============================] - 0s 64us/sample - loss: 0.1591 - val_loss: 0.1653\n",
      "Epoch 42/100\n",
      "3645/3645 [==============================] - 0s 59us/sample - loss: 0.1592 - val_loss: 0.1652\n",
      "Epoch 43/100\n",
      "3645/3645 [==============================] - 0s 66us/sample - loss: 0.1590 - val_loss: 0.1652\n",
      "Epoch 44/100\n",
      "3645/3645 [==============================] - 0s 64us/sample - loss: 0.1591 - val_loss: 0.1653\n",
      "Epoch 45/100\n",
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1590 - val_loss: 0.1652\n",
      "Epoch 46/100\n",
      "3645/3645 [==============================] - 0s 54us/sample - loss: 0.1591 - val_loss: 0.1654\n",
      "Epoch 47/100\n",
      "3645/3645 [==============================] - 0s 48us/sample - loss: 0.1591 - val_loss: 0.1650\n",
      "Epoch 48/100\n",
      "3645/3645 [==============================] - 0s 63us/sample - loss: 0.1590 - val_loss: 0.1652\n",
      "Epoch 49/100\n",
      "3645/3645 [==============================] - 0s 63us/sample - loss: 0.1590 - val_loss: 0.1649\n",
      "Epoch 50/100\n",
      "3645/3645 [==============================] - 0s 102us/sample - loss: 0.1591 - val_loss: 0.1652\n",
      "Epoch 51/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1590 - val_loss: 0.1651\n",
      "Epoch 52/100\n",
      "3645/3645 [==============================] - 0s 110us/sample - loss: 0.1590 - val_loss: 0.1651\n",
      "Epoch 53/100\n",
      "3645/3645 [==============================] - 0s 57us/sample - loss: 0.1590 - val_loss: 0.1649\n",
      "Epoch 54/100\n",
      "3645/3645 [==============================] - 0s 79us/sample - loss: 0.1590 - val_loss: 0.1650\n",
      "Epoch 55/100\n",
      "3645/3645 [==============================] - 0s 64us/sample - loss: 0.1590 - val_loss: 0.1652\n",
      "Epoch 56/100\n",
      "3645/3645 [==============================] - 0s 70us/sample - loss: 0.1591 - val_loss: 0.1649\n",
      "Epoch 57/100\n",
      "3645/3645 [==============================] - 0s 108us/sample - loss: 0.1590 - val_loss: 0.1649\n",
      "Epoch 58/100\n",
      "3645/3645 [==============================] - 0s 53us/sample - loss: 0.1590 - val_loss: 0.1659\n",
      "Epoch 59/100\n",
      "3645/3645 [==============================] - 0s 54us/sample - loss: 0.1588 - val_loss: 0.1649\n",
      "Epoch 60/100\n",
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1590 - val_loss: 0.1654\n",
      "Epoch 61/100\n",
      "3645/3645 [==============================] - 0s 104us/sample - loss: 0.1591 - val_loss: 0.1649\n",
      "Epoch 62/100\n",
      "3645/3645 [==============================] - 0s 68us/sample - loss: 0.1591 - val_loss: 0.1650\n",
      "Epoch 63/100\n",
      "3645/3645 [==============================] - 0s 78us/sample - loss: 0.1588 - val_loss: 0.1656\n",
      "Epoch 64/100\n",
      "3645/3645 [==============================] - 0s 81us/sample - loss: 0.1590 - val_loss: 0.1648\n",
      "Epoch 65/100\n",
      "3645/3645 [==============================] - 0s 52us/sample - loss: 0.1590 - val_loss: 0.1651\n",
      "Epoch 66/100\n",
      "3645/3645 [==============================] - 0s 49us/sample - loss: 0.1590 - val_loss: 0.1649\n",
      "Epoch 67/100\n",
      "3645/3645 [==============================] - 0s 52us/sample - loss: 0.1590 - val_loss: 0.1658\n",
      "Epoch 68/100\n",
      "3645/3645 [==============================] - 0s 55us/sample - loss: 0.1590 - val_loss: 0.1651\n",
      "Epoch 69/100\n",
      "3645/3645 [==============================] - 0s 101us/sample - loss: 0.1590 - val_loss: 0.1648\n",
      "Epoch 70/100\n",
      "3645/3645 [==============================] - 0s 134us/sample - loss: 0.1590 - val_loss: 0.1649\n",
      "Epoch 71/100\n",
      "3645/3645 [==============================] - 0s 132us/sample - loss: 0.1590 - val_loss: 0.1655\n",
      "Epoch 72/100\n",
      "3645/3645 [==============================] - 0s 98us/sample - loss: 0.1588 - val_loss: 0.1648\n",
      "Epoch 73/100\n",
      "3645/3645 [==============================] - 1s 159us/sample - loss: 0.1590 - val_loss: 0.1652\n",
      "Epoch 74/100\n",
      "3645/3645 [==============================] - 0s 114us/sample - loss: 0.1591 - val_loss: 0.1652\n",
      "Epoch 75/100\n",
      "3645/3645 [==============================] - 0s 95us/sample - loss: 0.1590 - val_loss: 0.1651\n",
      "Epoch 76/100\n",
      "3645/3645 [==============================] - 0s 105us/sample - loss: 0.1590 - val_loss: 0.1648\n",
      "Epoch 77/100\n",
      "3645/3645 [==============================] - 0s 118us/sample - loss: 0.1591 - val_loss: 0.1649\n",
      "Epoch 78/100\n",
      "3645/3645 [==============================] - 0s 112us/sample - loss: 0.1590 - val_loss: 0.1652\n",
      "Epoch 79/100\n",
      "3645/3645 [==============================] - 1s 151us/sample - loss: 0.1590 - val_loss: 0.1657\n",
      "Epoch 80/100\n",
      "3645/3645 [==============================] - 1s 147us/sample - loss: 0.1590 - val_loss: 0.1657\n",
      "Epoch 81/100\n",
      "3645/3645 [==============================] - 0s 111us/sample - loss: 0.1590 - val_loss: 0.1658\n",
      "Epoch 82/100\n",
      "3645/3645 [==============================] - 0s 75us/sample - loss: 0.1590 - val_loss: 0.1651\n",
      "Epoch 83/100\n",
      "3645/3645 [==============================] - 0s 80us/sample - loss: 0.1590 - val_loss: 0.1650\n",
      "Epoch 84/100\n",
      "3645/3645 [==============================] - 0s 83us/sample - loss: 0.1590 - val_loss: 0.1650\n",
      "Epoch 85/100\n",
      "3645/3645 [==============================] - 0s 71us/sample - loss: 0.1590 - val_loss: 0.1651\n",
      "Epoch 86/100\n",
      "3645/3645 [==============================] - 0s 64us/sample - loss: 0.1591 - val_loss: 0.1650\n",
      "1823/1823 [==============================] - 0s 50us/sample - loss: 0.1583\n",
      "[CV] END learning_rate=0.003586716970965761, n_hidden=0, n_neurons=80; total time=  25.4s\n",
      "Train on 3646 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "3646/3646 [==============================] - 1s 197us/sample - loss: 1.8425 - val_loss: 0.5930\n",
      "Epoch 2/100\n",
      "3646/3646 [==============================] - 0s 72us/sample - loss: 0.4283 - val_loss: 0.3241\n",
      "Epoch 3/100\n",
      "3646/3646 [==============================] - 0s 85us/sample - loss: 0.2712 - val_loss: 0.2477\n",
      "Epoch 4/100\n",
      "3646/3646 [==============================] - 0s 69us/sample - loss: 0.2229 - val_loss: 0.2202\n",
      "Epoch 5/100\n",
      "3646/3646 [==============================] - 0s 70us/sample - loss: 0.2044 - val_loss: 0.2083\n",
      "Epoch 6/100\n",
      "3646/3646 [==============================] - 0s 63us/sample - loss: 0.1949 - val_loss: 0.1988\n",
      "Epoch 7/100\n",
      "3646/3646 [==============================] - 0s 69us/sample - loss: 0.1888 - val_loss: 0.1930\n",
      "Epoch 8/100\n",
      "3646/3646 [==============================] - 0s 56us/sample - loss: 0.1843 - val_loss: 0.1890\n",
      "Epoch 9/100\n",
      "3646/3646 [==============================] - 0s 62us/sample - loss: 0.1807 - val_loss: 0.1848\n",
      "Epoch 10/100\n",
      "3646/3646 [==============================] - 0s 67us/sample - loss: 0.1776 - val_loss: 0.1829\n",
      "Epoch 11/100\n",
      "3646/3646 [==============================] - 0s 56us/sample - loss: 0.1755 - val_loss: 0.1794\n",
      "Epoch 12/100\n",
      "3646/3646 [==============================] - 0s 56us/sample - loss: 0.1734 - val_loss: 0.1773\n",
      "Epoch 13/100\n",
      "3646/3646 [==============================] - 0s 59us/sample - loss: 0.1720 - val_loss: 0.1751\n",
      "Epoch 14/100\n",
      "3646/3646 [==============================] - 0s 64us/sample - loss: 0.1705 - val_loss: 0.1745\n",
      "Epoch 15/100\n",
      "3646/3646 [==============================] - 0s 56us/sample - loss: 0.1693 - val_loss: 0.1720\n",
      "Epoch 16/100\n",
      "3646/3646 [==============================] - 0s 56us/sample - loss: 0.1683 - val_loss: 0.1709\n",
      "Epoch 17/100\n",
      "3646/3646 [==============================] - 0s 54us/sample - loss: 0.1675 - val_loss: 0.1700\n",
      "Epoch 18/100\n",
      "3646/3646 [==============================] - 0s 56us/sample - loss: 0.1666 - val_loss: 0.1691\n",
      "Epoch 19/100\n",
      "3646/3646 [==============================] - 0s 64us/sample - loss: 0.1660 - val_loss: 0.1690\n",
      "Epoch 20/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1655 - val_loss: 0.1679\n",
      "Epoch 21/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1649 - val_loss: 0.1680\n",
      "Epoch 22/100\n",
      "3646/3646 [==============================] - 0s 90us/sample - loss: 0.1646 - val_loss: 0.1682\n",
      "Epoch 23/100\n",
      "3646/3646 [==============================] - 0s 97us/sample - loss: 0.1644 - val_loss: 0.1671\n",
      "Epoch 24/100\n",
      "3646/3646 [==============================] - 0s 67us/sample - loss: 0.1640 - val_loss: 0.1666\n",
      "Epoch 25/100\n",
      "3646/3646 [==============================] - 0s 61us/sample - loss: 0.1635 - val_loss: 0.1661\n",
      "Epoch 26/100\n",
      "3646/3646 [==============================] - 0s 55us/sample - loss: 0.1635 - val_loss: 0.1664\n",
      "Epoch 27/100\n",
      "3646/3646 [==============================] - 0s 61us/sample - loss: 0.1634 - val_loss: 0.1659\n",
      "Epoch 28/100\n",
      "3646/3646 [==============================] - 0s 55us/sample - loss: 0.1632 - val_loss: 0.1657\n",
      "Epoch 29/100\n",
      "3646/3646 [==============================] - 0s 78us/sample - loss: 0.1630 - val_loss: 0.1658\n",
      "Epoch 30/100\n",
      "3646/3646 [==============================] - 0s 63us/sample - loss: 0.1628 - val_loss: 0.1654\n",
      "Epoch 31/100\n",
      "3646/3646 [==============================] - 0s 53us/sample - loss: 0.1627 - val_loss: 0.1652\n",
      "Epoch 32/100\n",
      "3646/3646 [==============================] - 0s 63us/sample - loss: 0.1627 - val_loss: 0.1652\n",
      "Epoch 33/100\n",
      "3646/3646 [==============================] - 0s 52us/sample - loss: 0.1626 - val_loss: 0.1652\n",
      "Epoch 34/100\n",
      "3646/3646 [==============================] - 0s 57us/sample - loss: 0.1625 - val_loss: 0.1651\n",
      "Epoch 35/100\n",
      "3646/3646 [==============================] - 0s 52us/sample - loss: 0.1624 - val_loss: 0.1653\n",
      "Epoch 36/100\n",
      "3646/3646 [==============================] - 0s 57us/sample - loss: 0.1624 - val_loss: 0.1652\n",
      "Epoch 37/100\n",
      "3646/3646 [==============================] - 0s 60us/sample - loss: 0.1623 - val_loss: 0.1653\n",
      "Epoch 38/100\n",
      "3646/3646 [==============================] - 0s 55us/sample - loss: 0.1623 - val_loss: 0.1653\n",
      "Epoch 39/100\n",
      "3646/3646 [==============================] - 0s 50us/sample - loss: 0.1624 - val_loss: 0.1648\n",
      "Epoch 40/100\n",
      "3646/3646 [==============================] - 0s 58us/sample - loss: 0.1623 - val_loss: 0.1647\n",
      "Epoch 41/100\n",
      "3646/3646 [==============================] - 0s 49us/sample - loss: 0.1622 - val_loss: 0.1647\n",
      "Epoch 42/100\n",
      "3646/3646 [==============================] - 0s 74us/sample - loss: 0.1621 - val_loss: 0.1649\n",
      "Epoch 43/100\n",
      "3646/3646 [==============================] - 0s 72us/sample - loss: 0.1621 - val_loss: 0.1647\n",
      "Epoch 44/100\n",
      "3646/3646 [==============================] - 0s 71us/sample - loss: 0.1621 - val_loss: 0.1647\n",
      "Epoch 45/100\n",
      "3646/3646 [==============================] - 0s 70us/sample - loss: 0.1621 - val_loss: 0.1647\n",
      "Epoch 46/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1621 - val_loss: 0.1649\n",
      "Epoch 47/100\n",
      "3646/3646 [==============================] - 0s 86us/sample - loss: 0.1620 - val_loss: 0.1657\n",
      "Epoch 48/100\n",
      "3646/3646 [==============================] - 0s 68us/sample - loss: 0.1621 - val_loss: 0.1653\n",
      "Epoch 49/100\n",
      "3646/3646 [==============================] - 0s 87us/sample - loss: 0.1621 - val_loss: 0.1649\n",
      "Epoch 50/100\n",
      "3646/3646 [==============================] - 0s 79us/sample - loss: 0.1621 - val_loss: 0.1650\n",
      "Epoch 51/100\n",
      "3646/3646 [==============================] - 0s 70us/sample - loss: 0.1621 - val_loss: 0.1647\n",
      "Epoch 52/100\n",
      "3646/3646 [==============================] - 0s 73us/sample - loss: 0.1621 - val_loss: 0.1651\n",
      "Epoch 53/100\n",
      "3646/3646 [==============================] - 0s 81us/sample - loss: 0.1622 - val_loss: 0.1647\n",
      "Epoch 54/100\n",
      "3646/3646 [==============================] - 0s 76us/sample - loss: 0.1621 - val_loss: 0.1648\n",
      "1822/1822 [==============================] - 0s 29us/sample - loss: 0.1524\n",
      "[CV] END learning_rate=0.003586716970965761, n_hidden=0, n_neurons=80; total time=  13.7s\n",
      "Train on 5468 samples, validate on 1823 samples\n",
      "Epoch 1/100\n",
      "5468/5468 [==============================] - 1s 195us/sample - loss: 0.1824 - val_loss: 0.1654\n",
      "Epoch 2/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1572 - val_loss: 0.1603\n",
      "Epoch 3/100\n",
      "5468/5468 [==============================] - 1s 97us/sample - loss: 0.1524 - val_loss: 0.1604\n",
      "Epoch 4/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1496 - val_loss: 0.1545\n",
      "Epoch 5/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1468 - val_loss: 0.1538\n",
      "Epoch 6/100\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1451 - val_loss: 0.1520\n",
      "Epoch 7/100\n",
      "5468/5468 [==============================] - 1s 119us/sample - loss: 0.1438 - val_loss: 0.1508\n",
      "Epoch 8/100\n",
      "5468/5468 [==============================] - 1s 113us/sample - loss: 0.1422 - val_loss: 0.1512\n",
      "Epoch 9/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1412 - val_loss: 0.1496\n",
      "Epoch 10/100\n",
      "5468/5468 [==============================] - 1s 96us/sample - loss: 0.1401 - val_loss: 0.1484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "5468/5468 [==============================] - 1s 108us/sample - loss: 0.1391 - val_loss: 0.1522\n",
      "Epoch 12/100\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1383 - val_loss: 0.1470\n",
      "Epoch 13/100\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1370 - val_loss: 0.1484\n",
      "Epoch 14/100\n",
      "5468/5468 [==============================] - 1s 109us/sample - loss: 0.1365 - val_loss: 0.1460\n",
      "Epoch 15/100\n",
      "5468/5468 [==============================] - 1s 97us/sample - loss: 0.1349 - val_loss: 0.1488\n",
      "Epoch 16/100\n",
      "5468/5468 [==============================] - 0s 88us/sample - loss: 0.1342 - val_loss: 0.1438\n",
      "Epoch 17/100\n",
      "5468/5468 [==============================] - 0s 88us/sample - loss: 0.1335 - val_loss: 0.1423\n",
      "Epoch 18/100\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.1321 - val_loss: 0.1449\n",
      "Epoch 19/100\n",
      "5468/5468 [==============================] - 1s 93us/sample - loss: 0.1320 - val_loss: 0.1426\n",
      "Epoch 20/100\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1303 - val_loss: 0.1398\n",
      "Epoch 21/100\n",
      "5468/5468 [==============================] - 1s 95us/sample - loss: 0.1304 - val_loss: 0.1438\n",
      "Epoch 22/100\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1290 - val_loss: 0.1398\n",
      "Epoch 23/100\n",
      "5468/5468 [==============================] - 1s 112us/sample - loss: 0.1279 - val_loss: 0.1367\n",
      "Epoch 24/100\n",
      "5468/5468 [==============================] - 1s 109us/sample - loss: 0.1264 - val_loss: 0.1395\n",
      "Epoch 25/100\n",
      "5468/5468 [==============================] - 1s 112us/sample - loss: 0.1254 - val_loss: 0.1393\n",
      "Epoch 26/100\n",
      "5468/5468 [==============================] - 1s 102us/sample - loss: 0.1251 - val_loss: 0.1337\n",
      "Epoch 27/100\n",
      "5468/5468 [==============================] - 1s 147us/sample - loss: 0.1255 - val_loss: 0.1370\n",
      "Epoch 28/100\n",
      "5468/5468 [==============================] - 1s 123us/sample - loss: 0.1243 - val_loss: 0.1329\n",
      "Epoch 29/100\n",
      "5468/5468 [==============================] - 1s 131us/sample - loss: 0.1231 - val_loss: 0.1332\n",
      "Epoch 30/100\n",
      "5468/5468 [==============================] - 1s 159us/sample - loss: 0.1219 - val_loss: 0.1457\n",
      "Epoch 31/100\n",
      "5468/5468 [==============================] - 1s 106us/sample - loss: 0.1213 - val_loss: 0.1365\n",
      "Epoch 32/100\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.1198 - val_loss: 0.1393\n",
      "Epoch 33/100\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1201 - val_loss: 0.1287\n",
      "Epoch 34/100\n",
      "5468/5468 [==============================] - 1s 103us/sample - loss: 0.1192 - val_loss: 0.1296\n",
      "Epoch 35/100\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1174 - val_loss: 0.1263\n",
      "Epoch 36/100\n",
      "5468/5468 [==============================] - 1s 117us/sample - loss: 0.1172 - val_loss: 0.1283\n",
      "Epoch 37/100\n",
      "5468/5468 [==============================] - 1s 99us/sample - loss: 0.1160 - val_loss: 0.1256\n",
      "Epoch 38/100\n",
      "5468/5468 [==============================] - 1s 101us/sample - loss: 0.1148 - val_loss: 0.1325\n",
      "Epoch 39/100\n",
      "5468/5468 [==============================] - 1s 113us/sample - loss: 0.1163 - val_loss: 0.1264\n",
      "Epoch 40/100\n",
      "5468/5468 [==============================] - 1s 106us/sample - loss: 0.1151 - val_loss: 0.1237\n",
      "Epoch 41/100\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1122 - val_loss: 0.1303\n",
      "Epoch 42/100\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1132 - val_loss: 0.1232\n",
      "Epoch 43/100\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.1117 - val_loss: 0.1228\n",
      "Epoch 44/100\n",
      "5468/5468 [==============================] - 0s 89us/sample - loss: 0.1116 - val_loss: 0.1434\n",
      "Epoch 45/100\n",
      "5468/5468 [==============================] - 0s 83us/sample - loss: 0.1101 - val_loss: 0.1182\n",
      "Epoch 46/100\n",
      "5468/5468 [==============================] - 1s 110us/sample - loss: 0.1094 - val_loss: 0.1211\n",
      "Epoch 47/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.1099 - val_loss: 0.1320\n",
      "Epoch 48/100\n",
      "5468/5468 [==============================] - 1s 95us/sample - loss: 0.1071 - val_loss: 0.1200\n",
      "Epoch 49/100\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1063 - val_loss: 0.1193\n",
      "Epoch 50/100\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.1070 - val_loss: 0.1445\n",
      "Epoch 51/100\n",
      "5468/5468 [==============================] - 1s 99us/sample - loss: 0.1053 - val_loss: 0.1144\n",
      "Epoch 52/100\n",
      "5468/5468 [==============================] - 1s 127us/sample - loss: 0.1053 - val_loss: 0.1241\n",
      "Epoch 53/100\n",
      "5468/5468 [==============================] - 1s 122us/sample - loss: 0.1048 - val_loss: 0.1181\n",
      "Epoch 54/100\n",
      "5468/5468 [==============================] - 1s 116us/sample - loss: 0.1043 - val_loss: 0.1205\n",
      "Epoch 55/100\n",
      "5468/5468 [==============================] - 1s 96us/sample - loss: 0.1024 - val_loss: 0.1154\n",
      "Epoch 56/100\n",
      "5468/5468 [==============================] - 1s 101us/sample - loss: 0.1043 - val_loss: 0.1130\n",
      "Epoch 57/100\n",
      "5468/5468 [==============================] - 1s 120us/sample - loss: 0.0998 - val_loss: 0.1105\n",
      "Epoch 58/100\n",
      "5468/5468 [==============================] - 1s 92us/sample - loss: 0.1008 - val_loss: 0.1365\n",
      "Epoch 59/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.0983 - val_loss: 0.1162\n",
      "Epoch 60/100\n",
      "5468/5468 [==============================] - 1s 99us/sample - loss: 0.1010 - val_loss: 0.1118\n",
      "Epoch 61/100\n",
      "5468/5468 [==============================] - 0s 82us/sample - loss: 0.0996 - val_loss: 0.1192\n",
      "Epoch 62/100\n",
      "5468/5468 [==============================] - 1s 106us/sample - loss: 0.0987 - val_loss: 0.1068\n",
      "Epoch 63/100\n",
      "5468/5468 [==============================] - 1s 96us/sample - loss: 0.0993 - val_loss: 0.1107\n",
      "Epoch 64/100\n",
      "5468/5468 [==============================] - 1s 106us/sample - loss: 0.0964 - val_loss: 0.1082\n",
      "Epoch 65/100\n",
      "5468/5468 [==============================] - 1s 119us/sample - loss: 0.0955 - val_loss: 0.1093\n",
      "Epoch 66/100\n",
      "5468/5468 [==============================] - 0s 78us/sample - loss: 0.0969 - val_loss: 0.1057\n",
      "Epoch 67/100\n",
      "5468/5468 [==============================] - 1s 98us/sample - loss: 0.0958 - val_loss: 0.1085\n",
      "Epoch 68/100\n",
      "5468/5468 [==============================] - 0s 81us/sample - loss: 0.0921 - val_loss: 0.1282\n",
      "Epoch 69/100\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.0926 - val_loss: 0.1141\n",
      "Epoch 70/100\n",
      "5468/5468 [==============================] - 1s 93us/sample - loss: 0.0930 - val_loss: 0.1096\n",
      "Epoch 71/100\n",
      "5468/5468 [==============================] - 1s 107us/sample - loss: 0.0946 - val_loss: 0.1170\n",
      "Epoch 72/100\n",
      "5468/5468 [==============================] - 1s 103us/sample - loss: 0.0917 - val_loss: 0.1054\n",
      "Epoch 73/100\n",
      "5468/5468 [==============================] - 1s 115us/sample - loss: 0.0903 - val_loss: 0.1009\n",
      "Epoch 74/100\n",
      "5468/5468 [==============================] - 1s 142us/sample - loss: 0.0890 - val_loss: 0.1039\n",
      "Epoch 75/100\n",
      "5468/5468 [==============================] - 1s 94us/sample - loss: 0.0923 - val_loss: 0.1005\n",
      "Epoch 76/100\n",
      "5468/5468 [==============================] - 1s 109us/sample - loss: 0.0881 - val_loss: 0.1024\n",
      "Epoch 77/100\n",
      "5468/5468 [==============================] - 1s 129us/sample - loss: 0.0882 - val_loss: 0.0988\n",
      "Epoch 78/100\n",
      "5468/5468 [==============================] - 1s 128us/sample - loss: 0.0875 - val_loss: 0.0985\n",
      "Epoch 79/100\n",
      "5468/5468 [==============================] - 1s 160us/sample - loss: 0.0857 - val_loss: 0.1273\n",
      "Epoch 80/100\n",
      "5468/5468 [==============================] - 1s 141us/sample - loss: 0.0859 - val_loss: 0.0983\n",
      "Epoch 81/100\n",
      "5468/5468 [==============================] - 1s 105us/sample - loss: 0.0850 - val_loss: 0.1074\n",
      "Epoch 82/100\n",
      "5468/5468 [==============================] - 1s 101us/sample - loss: 0.0863 - val_loss: 0.0946\n",
      "Epoch 83/100\n",
      "5468/5468 [==============================] - 1s 154us/sample - loss: 0.0850 - val_loss: 0.0954\n",
      "Epoch 84/100\n",
      "5468/5468 [==============================] - 1s 135us/sample - loss: 0.0862 - val_loss: 0.0945\n",
      "Epoch 85/100\n",
      "5468/5468 [==============================] - 1s 134us/sample - loss: 0.0844 - val_loss: 0.1332\n",
      "Epoch 86/100\n",
      "5468/5468 [==============================] - 1s 108us/sample - loss: 0.0842 - val_loss: 0.1048\n",
      "Epoch 87/100\n",
      "5468/5468 [==============================] - 1s 107us/sample - loss: 0.0850 - val_loss: 0.0919\n",
      "Epoch 88/100\n",
      "5468/5468 [==============================] - 1s 113us/sample - loss: 0.0814 - val_loss: 0.0937\n",
      "Epoch 89/100\n",
      "5468/5468 [==============================] - 1s 113us/sample - loss: 0.0829 - val_loss: 0.0936\n",
      "Epoch 90/100\n",
      "5468/5468 [==============================] - 1s 104us/sample - loss: 0.0811 - val_loss: 0.0904\n",
      "Epoch 91/100\n",
      "5468/5468 [==============================] - 0s 91us/sample - loss: 0.0802 - val_loss: 0.1059\n",
      "Epoch 92/100\n",
      "5468/5468 [==============================] - 1s 129us/sample - loss: 0.0804 - val_loss: 0.0934\n",
      "Epoch 93/100\n",
      "5468/5468 [==============================] - 0s 88us/sample - loss: 0.0819 - val_loss: 0.1217\n",
      "Epoch 94/100\n",
      "5468/5468 [==============================] - 1s 107us/sample - loss: 0.0790 - val_loss: 0.0912\n",
      "Epoch 95/100\n",
      "5468/5468 [==============================] - 0s 86us/sample - loss: 0.0812 - val_loss: 0.1001\n",
      "Epoch 96/100\n",
      "5468/5468 [==============================] - 0s 90us/sample - loss: 0.0792 - val_loss: 0.0887\n",
      "Epoch 97/100\n",
      "5468/5468 [==============================] - 0s 85us/sample - loss: 0.0812 - val_loss: 0.0991\n",
      "Epoch 98/100\n",
      "5468/5468 [==============================] - 1s 108us/sample - loss: 0.0766 - val_loss: 0.1118\n",
      "Epoch 99/100\n",
      "5468/5468 [==============================] - 1s 103us/sample - loss: 0.0774 - val_loss: 0.1218\n",
      "Epoch 100/100\n",
      "5468/5468 [==============================] - 1s 187us/sample - loss: 0.0749 - val_loss: 0.1080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000021DF5680BA8>,\n",
       "                   param_distributions={'learning_rate': [0.01245116684194342,\n",
       "                                                          0.0003977593352422101,\n",
       "                                                          0.0004974241525136969,\n",
       "                                                          0.00034691756530475556,\n",
       "                                                          0.022674128446224233,\n",
       "                                                          0.0005220921004947262,\n",
       "                                                          0.0036491210271799215,\n",
       "                                                          0.018975890989256252,\n",
       "                                                          0.00634129747346...\n",
       "                                                          0.0014777789176957427,\n",
       "                                                          0.0010544175984679,\n",
       "                                                          0.02811202517058381,\n",
       "                                                          0.0026778919942630013,\n",
       "                                                          0.020777809934719615,\n",
       "                                                          0.005473312467077458,\n",
       "                                                          0.005334929973510342,\n",
       "                                                          0.02051379406740248,\n",
       "                                                          0.001335719401222011,\n",
       "                                                          0.011682606788081789,\n",
       "                                                          0.02790333055911195, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b04453c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 99, 'n_hidden': 3, 'learning_rate': 0.017926272076224836}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11bf28e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11013533873275105"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a78b91bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "60d84f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 72us/sample - loss: 0.1060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10597545393071808"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d5f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
